WEBVTT FILE

1
00:00:00.180 --> 00:00:03.360
Hi, this is Scott. I
really appreciate our sponsors because

2
00:00:03.360 --> 00:00:06.300
they make the show possible.
Today's show is sponsored by

3
00:00:06.300 --> 00:00:10.500
developer express, become a UI
superhero with dev express controls

4
00:00:10.500 --> 00:00:15.030
and libraries. Deliver elegant.net solutions
that address customer needs today

5
00:00:15.420 --> 00:00:19.500
by leveraging your existing knowledge,
you can build next generation

6
00:00:19.500 --> 00:00:23.610
touch enabled solutions for tomorrow,
you can download your free

7
00:00:23.700 --> 00:00:45.140
30 day trial@dxdothanselminutes.com. That's dx.hanselminutes.com.
<inaudible>. Hi, this is Scott

8
00:00:45.140 --> 00:00:47.810
Hanselman. This is another episode
of Hansel minutes today. I'm

9
00:00:47.810 --> 00:00:50.330
talking with Sarah Koons. She
is the founder and CEO

10
00:00:50.330 --> 00:00:53.000
at pro day and a
long time investor and venture

11
00:00:53.000 --> 00:00:56.180
capitalist. How are you? I'm
great. How are you? I'm

12
00:00:56.210 --> 00:00:59.630
very well. So you're at
pro day is pretty amazing.

13
00:01:00.140 --> 00:01:03.800
I've been checking out the
website@proday.co and it basically lets

14
00:01:03.800 --> 00:01:07.160
you work out with, you
know, your favorite professional athletes

15
00:01:07.160 --> 00:01:10.190
and work alongside them. It's
pretty a pretty clever idea,

16
00:01:10.220 --> 00:01:14.210
but this is not your
first foray into, into business

17
00:01:14.210 --> 00:01:16.460
and companies. You've been doing
startups and tech for a

18
00:01:16.460 --> 00:01:19.400
very long time. I have
yeah, pretty much my entire

19
00:01:19.400 --> 00:01:21.950
career. And one of the
things that you said to

20
00:01:21.950 --> 00:01:25.460
me that I wanted to
talk about today was how

21
00:01:25.670 --> 00:01:30.050
empathy matters in, in software
development. But then I thought

22
00:01:30.050 --> 00:01:31.700
you were gonna go in
a certain direction. I thought

23
00:01:31.700 --> 00:01:33.740
you were going to talk
about, you know, the importance

24
00:01:33.740 --> 00:01:38.030
of empathy for empathy's sake,
but you said, no, this

25
00:01:38.030 --> 00:01:40.160
is about shipping cool stuff.
And this is about making

26
00:01:40.160 --> 00:01:43.490
money. Oh yeah, absolutely. I
mean, I think it's important

27
00:01:43.730 --> 00:01:46.100
to be a good person
because we live in a

28
00:01:46.100 --> 00:01:48.410
world that's very hard to
live in. If everyone's not,

29
00:01:48.680 --> 00:01:51.770
I'm a good person, but,
but it's really, there's a

30
00:01:51.770 --> 00:01:54.260
business imperative too. And I
think that sometimes that gets

31
00:01:54.260 --> 00:01:56.540
a little bit lost and
we feel like when we

32
00:01:56.540 --> 00:01:59.750
talk about things like empathy
in design or in tech,

33
00:01:59.960 --> 00:02:02.060
it's sort of for the
fuzzy reasons and, and it

34
00:02:02.060 --> 00:02:04.760
is, but there's also a
lot of cold, hard cash

35
00:02:04.760 --> 00:02:07.700
reasons too. So I'm excited
to talk about that. Yeah.

36
00:02:08.090 --> 00:02:11.510
And when, when, when did
you start developing this perspective?

37
00:02:12.390 --> 00:02:16.790
You know, I think for
me, I remember in, in,

38
00:02:16.790 --> 00:02:18.470
in either high school or
college, I was in a

39
00:02:18.470 --> 00:02:23.200
class learning about automobile design
I'm from Michigan. And so,

40
00:02:23.200 --> 00:02:26.330
so the big three auto
makers are weigh heavy on

41
00:02:26.330 --> 00:02:28.610
all of our, our minds
there. And they were talking

42
00:02:28.610 --> 00:02:31.640
about how I think in
the sixties, women had started

43
00:02:31.640 --> 00:02:34.190
to drive a lot more.
And so they wanted to

44
00:02:34.520 --> 00:02:36.770
do better, a better job
of selling cars to women

45
00:02:37.370 --> 00:02:40.250
or at least to the,
if you have a car

46
00:02:40.250 --> 00:02:42.710
that a woman hates and
there's another car that the

47
00:02:42.710 --> 00:02:45.170
woman hates less, the odds
are that, you know, the,

48
00:02:45.170 --> 00:02:47.120
the husband, even if he's
the one making the purchase

49
00:02:47.120 --> 00:02:49.070
decision and it's in his
name is going to buy

50
00:02:49.070 --> 00:02:51.170
the car that the woman
hates less. So they were

51
00:02:51.170 --> 00:02:55.370
working on this idea and
they got all the engineers.

52
00:02:55.370 --> 00:02:57.050
Cause all the engineers were
men. They made them all

53
00:02:57.050 --> 00:03:00.010
come to work one day
and they put in skirts

54
00:03:00.070 --> 00:03:03.130
and heels and purses and
give them lipstick and all

55
00:03:03.130 --> 00:03:06.610
of this stuff. Right? Perfume,
like everything that women, you

56
00:03:06.610 --> 00:03:08.740
know, at the time were
probably going to be wearing

57
00:03:08.740 --> 00:03:11.320
as they were in a
car and they made them,

58
00:03:11.380 --> 00:03:14.890
you know, do all of
these tests dressed as women

59
00:03:14.890 --> 00:03:17.440
and immediately the guys were
like, Oh my God, we

60
00:03:17.440 --> 00:03:19.570
need a place to put
the purse. Like if you

61
00:03:19.570 --> 00:03:21.700
have all your stuff in
this purse, you don't want

62
00:03:21.700 --> 00:03:23.680
it like in the backseat
or flying around in the

63
00:03:23.680 --> 00:03:25.420
seat next to you, you
step on the brakes and

64
00:03:25.420 --> 00:03:27.280
it goes flying. Like, do
we need a place for

65
00:03:27.280 --> 00:03:29.800
the purse? Or they'd realize
that if you were wearing

66
00:03:29.800 --> 00:03:32.320
like a tighter skirt and
you're trying to get into

67
00:03:32.320 --> 00:03:35.890
the car, you, you really
struggle because you can't sort

68
00:03:35.890 --> 00:03:37.960
of like hike one leg
up and then sit and

69
00:03:37.960 --> 00:03:40.630
then the other. And so
they just realize all of

70
00:03:40.630 --> 00:03:43.690
these things in like this
two hour sort of test

71
00:03:43.690 --> 00:03:46.450
period, that completely changed the
way they thought about building

72
00:03:46.450 --> 00:03:49.660
cars, right. And it wasn't
or designing the interior of

73
00:03:49.660 --> 00:03:53.710
a car. And it wasn't
that, that they were doing

74
00:03:53.710 --> 00:03:57.100
it because you know, these
auto workers were secretly feminist,

75
00:03:57.100 --> 00:03:59.830
right? They were doing it
because they needed to be

76
00:03:59.830 --> 00:04:03.460
able to more effectively sell
cars to half the population.

77
00:04:04.830 --> 00:04:08.130
Interestingly, they were presented a
problem. The problem was here.

78
00:04:08.130 --> 00:04:09.810
Now you wearing a skirt
and you have a purse

79
00:04:10.170 --> 00:04:15.780
make a very comfortable car.
And that's the problem. Interesting.

80
00:04:15.780 --> 00:04:19.020
I don't understand why walking
in someone else's shoes. Isn't

81
00:04:19.170 --> 00:04:22.140
so obvious why we aren't
starting our design from that,

82
00:04:22.440 --> 00:04:26.610
that route. Yeah. And it's
even little things, right? Like

83
00:04:26.640 --> 00:04:29.220
I'm African American, but a
lot of my friends are

84
00:04:29.220 --> 00:04:32.280
not. And so I started
making sure that I have

85
00:04:32.280 --> 00:04:35.850
some screen because I would
feel really bad when I

86
00:04:35.850 --> 00:04:39.030
would be, you know, friends
would come over during the

87
00:04:39.030 --> 00:04:41.940
summer and you know, they'd
be like, Oh my God,

88
00:04:41.940 --> 00:04:43.710
like, we're going to go
for this hike or whatever.

89
00:04:44.160 --> 00:04:46.620
Do you have sunscreen? I'm
like, no, sorry. And then

90
00:04:46.620 --> 00:04:50.010
they get these crazy sunburns.
And to be fair, I've

91
00:04:50.010 --> 00:04:52.260
only gotten one sunburn in
my life. And it was,

92
00:04:52.260 --> 00:04:54.090
I was on a medication
that made my skin photo

93
00:04:54.090 --> 00:04:57.810
sensitive. I had no idea
what it felt like, because

94
00:04:57.810 --> 00:05:00.210
like, try to imagine if
you just never had a

95
00:05:00.210 --> 00:05:03.060
sunburn and you get a
sunburn as an adult and

96
00:05:03.060 --> 00:05:05.310
you didn't realize you got
a sunburn. Like I thought

97
00:05:05.310 --> 00:05:08.730
I was dying. I thought
that I had had some

98
00:05:08.730 --> 00:05:12.810
sort of chemical burn or
something over my entire body.

99
00:05:12.810 --> 00:05:14.460
I didn't know what it
could be. I thought I

100
00:05:14.460 --> 00:05:16.440
was going to die and
I was explaining it to

101
00:05:16.440 --> 00:05:18.420
friends and they were so
worried about me. And finally,

102
00:05:18.420 --> 00:05:20.700
one of them looked at
me and said, Sarah, you

103
00:05:20.700 --> 00:05:23.790
have a sunburn, but I
had no idea. And ever

104
00:05:23.790 --> 00:05:25.530
since then, I'm like, okay,
I'm going to keep sunscreen

105
00:05:25.530 --> 00:05:28.140
on hand because I had
no idea that this was

106
00:05:28.140 --> 00:05:30.570
what was happening to my
friends. And so it is

107
00:05:30.570 --> 00:05:33.570
obvious. But I think often
we need a catalyst, either

108
00:05:33.570 --> 00:05:37.560
a business imperative or a
personal experience that makes us

109
00:05:37.560 --> 00:05:43.080
go, Oh wait, I need
to, to purposely think about

110
00:05:43.080 --> 00:05:48.480
other people's perspectives to make
sure that they are happy

111
00:05:48.480 --> 00:05:51.510
or comfortable or lucrative or
whatever your goal is. Hmm.

112
00:05:51.900 --> 00:05:54.270
One of the phrases that
I'm not a big fan

113
00:05:54.270 --> 00:05:57.440
of in, in the news
right now is this as

114
00:05:57.440 --> 00:06:00.620
a father of daughters, comma,
and then the whole thing.

115
00:06:01.160 --> 00:06:04.880
Why is it that something
big has to happen to

116
00:06:04.910 --> 00:06:07.790
cause someone to be a
catalyst for change? Why are

117
00:06:07.790 --> 00:06:11.120
we not taught that empathy
for others right off the

118
00:06:11.120 --> 00:06:13.810
bat? I think that we
are taught empathy in a

119
00:06:13.810 --> 00:06:17.890
broad strokes sense, right? Like
if anyone tells you, sorry,

120
00:06:17.890 --> 00:06:20.710
my mother just died. We
have a knee jerk empathy.

121
00:06:20.710 --> 00:06:23.320
Right. So I think that
we're taught that for big

122
00:06:23.350 --> 00:06:27.040
things or, or sort of
really universal themes. I don't

123
00:06:27.040 --> 00:06:31.210
think that we are taught.
I think that there's something

124
00:06:31.210 --> 00:06:34.810
that we do that was,
is very well-intended, but is

125
00:06:34.810 --> 00:06:37.300
not well executed. Right. This
idea of sort of, I

126
00:06:37.300 --> 00:06:39.070
don't see gender, I don't
see race. I don't see

127
00:06:39.070 --> 00:06:43.390
whatever which is, is yes.
Like we understand right. The

128
00:06:43.390 --> 00:06:45.400
same way that a baby
doesn't really see gender or

129
00:06:45.400 --> 00:06:47.170
race. And that's good. You
want a baby to love

130
00:06:47.170 --> 00:06:49.480
everyone, but I mean, babies
also have to wear diapers

131
00:06:49.480 --> 00:06:51.580
cause they can't control their
bowel movements. Like as we

132
00:06:51.580 --> 00:06:54.310
grow up, we have to
have more nuance around these

133
00:06:54.310 --> 00:06:56.980
things. And I think we
have to say, you know,

134
00:06:57.490 --> 00:07:00.130
Hey, what is it like
if you, you know, another

135
00:07:00.130 --> 00:07:02.350
favorite example of mine is
my dad is a foot

136
00:07:02.350 --> 00:07:06.730
taller than my mom. And
so he was, he hung

137
00:07:06.730 --> 00:07:10.660
a mirror once in their
bathroom. And my mom couldn't

138
00:07:10.660 --> 00:07:14.290
see in it because it
was so incredibly tall because

139
00:07:14.290 --> 00:07:16.120
he just held it up
at his head length and

140
00:07:16.120 --> 00:07:17.890
hung it because that's how
you hang a mirror, right.

141
00:07:17.890 --> 00:07:19.690
If you want to use
it to do your hair.

142
00:07:20.410 --> 00:07:22.600
And so it was just
this really funny and small

143
00:07:22.600 --> 00:07:25.450
saying where, you know, my
parents have been very happily

144
00:07:25.450 --> 00:07:30.790
married for 35 years. And
even that doesn't mean that

145
00:07:30.790 --> 00:07:33.790
you're going to always have
that sort of knee-jerk empathetic

146
00:07:33.820 --> 00:07:40.750
thought because it's not, it
is not, it's hard to

147
00:07:40.810 --> 00:07:45.100
think about always, Hey, how
is this affecting the other

148
00:07:45.310 --> 00:07:47.890
people around me who need
this product or who use

149
00:07:47.890 --> 00:07:50.590
this product? And so I
do think that there is,

150
00:07:50.650 --> 00:07:53.740
especially in engineering, a piece
of it that needs to

151
00:07:53.740 --> 00:07:56.410
go into, you know, really
the spec, right? When you're

152
00:07:56.410 --> 00:07:58.150
specking out a product, when
you're thinking about what you're

153
00:07:58.150 --> 00:08:01.060
going to build, who are
the stakeholders and then how

154
00:08:01.060 --> 00:08:04.090
are the stakeholders different from
each other? I think is

155
00:08:04.090 --> 00:08:07.210
a, a piece of it
that we sometimes miss. And

156
00:08:07.210 --> 00:08:09.370
we just sort of build
a product for ourselves and

157
00:08:09.370 --> 00:08:11.890
figure, Hey, I'm a person.
So if I like it,

158
00:08:11.890 --> 00:08:14.800
other people will like it.
And that's not always the

159
00:08:14.800 --> 00:08:18.310
way it works. It feels
like that. There's a sweet

160
00:08:18.310 --> 00:08:22.870
spot between understanding the person's
perspective as well as just

161
00:08:22.870 --> 00:08:26.590
objective, objectively speaking as an
outsider. So there's value in

162
00:08:26.590 --> 00:08:30.130
being deeply empathetic, but there's
also value in being detached.

163
00:08:31.090 --> 00:08:32.650
Yeah. And, and I think
that's part of it. I

164
00:08:32.650 --> 00:08:35.830
think that there's, I think
you really do need to

165
00:08:35.830 --> 00:08:38.740
do both, right? You need
to think about, Hey, what

166
00:08:38.740 --> 00:08:41.050
do I want? Because I
do think it's hard to

167
00:08:41.050 --> 00:08:45.190
build products that you're completely
divorced from just because it's

168
00:08:45.190 --> 00:08:47.710
sort of a, an more
of an antiseptic process. So

169
00:08:47.710 --> 00:08:49.390
you do need to think
like I'm a human and

170
00:08:49.390 --> 00:08:51.910
I represent to some extent
the human experience, right? What

171
00:08:51.910 --> 00:08:53.920
do I think want to
need, but then also think

172
00:08:53.920 --> 00:08:58.170
about who are the other
and, and almost treat them

173
00:08:58.170 --> 00:09:01.380
all equally, right? I think
that's a detachment piece where

174
00:09:01.380 --> 00:09:04.320
you don't say, well, this
is what I want. And

175
00:09:04.320 --> 00:09:06.690
30% of the audience will
want what I want. So

176
00:09:06.690 --> 00:09:09.510
we should prioritize that because
I'm the one building it.

177
00:09:10.110 --> 00:09:13.920
But instead sort of treat
every stakeholder is kind of

178
00:09:14.010 --> 00:09:16.590
equal and say, how do
we build this in a

179
00:09:16.590 --> 00:09:21.180
way that will work for
everyone? There used to be

180
00:09:21.180 --> 00:09:23.910
complaints about like the, really
the, the older I-phones that

181
00:09:23.910 --> 00:09:26.670
they were too small. Right.
Guys would say that. So

182
00:09:26.670 --> 00:09:28.770
tiny. I feel like, you
know, I want a bigger

183
00:09:28.770 --> 00:09:31.560
phone. And then now you
have these massive, massive, massive

184
00:09:31.650 --> 00:09:35.850
iPhones and granted Apple sort
of, they, they, they decided

185
00:09:35.850 --> 00:09:37.410
not to go straight down
the middle. Right. They made

186
00:09:37.410 --> 00:09:40.500
the really, really big phones
and the, and then now

187
00:09:40.500 --> 00:09:43.080
they continue to make the
smaller phones instead of just

188
00:09:43.080 --> 00:09:45.750
picking one. But if you
give, you know, a five

189
00:09:45.750 --> 00:09:48.270
foot tall woman, one of
the massive phones, she's like,

190
00:09:48.270 --> 00:09:50.340
I can't hold this. This
is terrible. Like, it's like

191
00:09:50.340 --> 00:09:52.800
a, basically an iPad. If
you give a seven foot

192
00:09:52.800 --> 00:09:55.770
tall NBA player, one of
the little phones they're like,

193
00:09:55.830 --> 00:09:57.960
I can't hold this. This
is a phone for ants,

194
00:09:58.170 --> 00:10:01.020
you know? So it, it,
it's important. I think, to

195
00:10:01.440 --> 00:10:04.470
think about those practical things
and then decide, do we

196
00:10:04.470 --> 00:10:06.810
build two products? Is there
a happy, medium, like, how

197
00:10:06.810 --> 00:10:10.080
do we meet these people's
needs? But I do think

198
00:10:10.080 --> 00:10:12.270
a lot of it is
even just having that moment

199
00:10:12.270 --> 00:10:14.490
of thinking about it. I
think a lot of interesting

200
00:10:14.490 --> 00:10:18.170
solutions come from there. How
far do you go though?

201
00:10:18.170 --> 00:10:21.380
I think that people on
the naysayers side would say

202
00:10:21.380 --> 00:10:24.380
that in some ways we're
being, they use the word

203
00:10:24.380 --> 00:10:27.560
politically, correct? I would just
say overly inclusive. Like you

204
00:10:27.560 --> 00:10:30.140
can't hit a hundred percent
because you could spend all

205
00:10:30.140 --> 00:10:33.590
of your time on that
last 2%. I mean, nobody,

206
00:10:33.590 --> 00:10:37.430
nobody. So one engineer's love
spending all their time on

207
00:10:37.430 --> 00:10:42.230
the last 2%, right? Let's
be honest, prying a product

208
00:10:42.230 --> 00:10:44.660
out of an engineer's hand
to push it into development.

209
00:10:44.660 --> 00:10:46.700
When there's one tiny thing
that could be fixed if

210
00:10:46.700 --> 00:10:50.120
we only had seven more
weeks, is, is every a,

211
00:10:50.130 --> 00:10:54.560
is every product managers, biggest,
biggest job. So one, you

212
00:10:54.560 --> 00:10:56.480
know, I certainly, I think
that engineers out of, out

213
00:10:56.480 --> 00:10:59.510
of anybody have a unique
skill set and interest in

214
00:10:59.510 --> 00:11:02.900
this sort of perfection. I
don't think it's politically correct.

215
00:11:02.900 --> 00:11:06.740
Again, it's about money, right?
And if you are an

216
00:11:06.740 --> 00:11:08.690
engineer and you run a
company or you work at

217
00:11:08.690 --> 00:11:11.150
a company, you really want
your company to make money

218
00:11:11.150 --> 00:11:13.910
so that you can keep
getting a paycheck and eventually

219
00:11:13.910 --> 00:11:16.100
sell for billions of dollars.
Right? So, so are your

220
00:11:16.100 --> 00:11:18.650
stock price goes up and
your equity's worth more. So,

221
00:11:19.310 --> 00:11:22.280
you know, the business case
is we live in a

222
00:11:22.790 --> 00:11:26.810
capitalist economy in America and
lots of other places around

223
00:11:26.810 --> 00:11:30.170
the world and money makes
the world go round, fortunately,

224
00:11:30.170 --> 00:11:33.350
or unfortunately. So if you're
talking about doing something that

225
00:11:33.350 --> 00:11:36.650
cuts out half of the
population, there is a famous

226
00:11:36.650 --> 00:11:39.860
example, again, of Apple, they
released their Apple health tracker

227
00:11:40.100 --> 00:11:41.780
and they didn't just start
to say, Oh yeah, here's

228
00:11:41.780 --> 00:11:44.360
Apple health tracker. They said,
this is the most comprehensive

229
00:11:44.570 --> 00:11:47.120
health tracker in the history
of the world. And this

230
00:11:47.120 --> 00:11:49.880
is the best health tracker
ever. Guess what they did

231
00:11:49.880 --> 00:11:55.060
not do at all. They
did not track women's administration.

232
00:11:55.240 --> 00:11:59.380
So 50% of the world,
right. And I would say

233
00:11:59.380 --> 00:12:04.510
probably a solid, assuming that
the average Apple iPhone user

234
00:12:04.720 --> 00:12:08.710
is, is North of 12
and South of, you know,

235
00:12:08.710 --> 00:12:13.840
let's say 65, right? 80,
90% of, of the population

236
00:12:13.930 --> 00:12:18.910
of, of women using iPhones
could track their periods. They

237
00:12:18.910 --> 00:12:21.520
have periods and this was
not built in. And again,

238
00:12:21.520 --> 00:12:23.320
it's fine if you say,
Oh, it's a basic health

239
00:12:23.320 --> 00:12:25.720
tracker. If you tell me
it's the most comprehensive health

240
00:12:25.720 --> 00:12:29.800
tracker and you are not
tracking something that happens to

241
00:12:29.800 --> 00:12:32.890
literally every single woman for
a solid 30 to 40

242
00:12:32.890 --> 00:12:35.680
years of her life, at
least it's hard to believe

243
00:12:35.680 --> 00:12:38.290
that it's the most comprehensive
health tracker, right? And so

244
00:12:38.290 --> 00:12:40.960
things like that. And, and
they got a lot of

245
00:12:40.960 --> 00:12:43.810
backlash for it. And, you
know, they also missed out

246
00:12:43.810 --> 00:12:47.290
on market share because in,
in that whole, a lot

247
00:12:47.290 --> 00:12:50.770
of other health apps popped
up. And even now, anytime

248
00:12:50.770 --> 00:12:53.530
you download a health app
on the Apple, Apple's begging

249
00:12:53.530 --> 00:12:56.320
you to, to use Apple
health and let you write

250
00:12:56.320 --> 00:12:58.600
to it. But the reason
in large part that you're

251
00:12:58.600 --> 00:13:01.210
downloading these other apps in
the first place is because

252
00:13:01.210 --> 00:13:05.260
they're super comprehensive app. Wasn't
so comprehensive after all. So,

253
00:13:05.290 --> 00:13:08.140
you know, those kinds of
business cases I think are,

254
00:13:08.410 --> 00:13:12.100
are beyond obvious. And I
certainly would, would be hard

255
00:13:12.100 --> 00:13:14.770
pressed to say that worrying
about 50% of your user

256
00:13:14.770 --> 00:13:20.170
base is, is political correctness
or overly inclusive. Right. That's

257
00:13:20.170 --> 00:13:24.280
sort of just boilerplate. So,
you know, I think that

258
00:13:24.280 --> 00:13:27.100
that, yes, there's always things
on the margins, but, but

259
00:13:27.100 --> 00:13:29.680
a lot of what we're
talking about are basic block

260
00:13:29.680 --> 00:13:33.450
and tackle things that just
haven't happened. I found an

261
00:13:33.450 --> 00:13:38.070
interesting article on your website
on pro day.co under fitness

262
00:13:38.520 --> 00:13:44.520
about the Nike pro hijab.
And again, it's something that

263
00:13:44.520 --> 00:13:46.710
kind of the average person
that looks like me might

264
00:13:46.710 --> 00:13:49.530
think, well, that's kind of
obscure, but when you look

265
00:13:49.530 --> 00:13:52.080
at the article, it's really
quite interesting because it was,

266
00:13:52.440 --> 00:13:55.350
it all started with a
female weightlifter who was discovering

267
00:13:55.350 --> 00:13:58.920
that the one job she
had that was competition appropriate

268
00:13:59.460 --> 00:14:01.950
had issues with weight. It
would shift while she was

269
00:14:01.950 --> 00:14:07.260
moving. It caused breathability issues.
As I was reading about

270
00:14:07.260 --> 00:14:10.770
this, I would have to
say my thoughts and opinions

271
00:14:10.770 --> 00:14:12.450
about whether or not that's
a good product or not

272
00:14:12.630 --> 00:14:15.750
turned into engineering questions. I
started to think about it

273
00:14:15.750 --> 00:14:17.820
in terms of engineering, okay,
this is a problem we're

274
00:14:17.820 --> 00:14:20.640
going to solve this problem.
Apparently they worked very hard

275
00:14:20.640 --> 00:14:23.370
on this to come up
with a, a, an athletic

276
00:14:24.120 --> 00:14:27.000
hijab. Yeah, absolutely. I mean,
when you think about it,

277
00:14:27.000 --> 00:14:30.120
right in America, we don't
see this, but, but around

278
00:14:30.120 --> 00:14:33.630
the world, something, I mean
being Muslim, that's, it's the

279
00:14:33.630 --> 00:14:36.420
largest, and it's basically a
religion that's neck and neck

280
00:14:36.690 --> 00:14:39.810
in terms of with Christianity
in terms of penetration around

281
00:14:39.810 --> 00:14:43.320
the world. Right? And on
top of that, there's a

282
00:14:43.320 --> 00:14:48.180
disproportionate amount of Muslim people
in emerging markets. And, and

283
00:14:48.180 --> 00:14:51.650
as we all know, right,
emerging markets are where a

284
00:14:51.650 --> 00:14:54.110
lot of explosive growth is
going to come from, right.

285
00:14:54.380 --> 00:14:57.290
Everybody in America who wants
to buy a piece of

286
00:14:57.290 --> 00:15:00.470
Nike workout gear, right, has
a piece of Nike workout

287
00:15:00.470 --> 00:15:02.780
gear. You might want more
pieces. They might come up

288
00:15:02.780 --> 00:15:05.480
with a fun, new color
or technology, but we all

289
00:15:05.480 --> 00:15:10.370
have, you know, more, more
basketball shorts and leggings. And

290
00:15:10.370 --> 00:15:12.260
t-shirts right. Then we know
what to do with, for

291
00:15:12.260 --> 00:15:15.410
the most part in this
country and in similar, right.

292
00:15:15.440 --> 00:15:17.210
In, in most of Europe.
But then you look at

293
00:15:17.210 --> 00:15:21.260
places like Indonesia, places like
India, places where a lot

294
00:15:21.320 --> 00:15:25.130
of this, this, you know,
sort of organized sports are

295
00:15:25.130 --> 00:15:28.700
just starting to take off
in terms of, of worldwide

296
00:15:28.700 --> 00:15:33.020
competition, right. And there is
a massive opportunity to sell

297
00:15:33.020 --> 00:15:37.130
products to those people, right.
And so of course, you're

298
00:15:37.130 --> 00:15:41.750
going to optimize for, Hey,
there's a massive emerging market

299
00:15:41.750 --> 00:15:44.120
that we're desperate to get
a piece of. And not

300
00:15:44.120 --> 00:15:46.220
only do we want a
piece of it in general,

301
00:15:46.220 --> 00:15:48.050
we also, you know, a
lot of times what will

302
00:15:48.050 --> 00:15:50.360
happen in an emerging market,
we've certainly seen this in

303
00:15:50.360 --> 00:15:54.290
India over the years is
that they don't necessarily want

304
00:15:54.650 --> 00:15:58.160
American products, right. Or European
products. They want a brand

305
00:15:58.190 --> 00:16:02.300
that that is sort of
from, from where they're from

306
00:16:02.300 --> 00:16:04.790
and speaks to them more
directly. And so then when

307
00:16:04.790 --> 00:16:07.190
you start to look at
that, you go, Oh, wait

308
00:16:07.190 --> 00:16:12.560
a minute. If, if they,
if, if, if we don't

309
00:16:12.560 --> 00:16:15.010
necessarily just get to go
in, it's not like in,

310
00:16:15.010 --> 00:16:19.130
in China or Russia, where
when American brands came to

311
00:16:19.130 --> 00:16:22.130
those countries, there was a
massive pent up demand and

312
00:16:22.130 --> 00:16:24.770
excitement for them right there,
American brands, aren't always the

313
00:16:24.770 --> 00:16:28.820
most desirable always now. And
so instead of somebody launching

314
00:16:28.820 --> 00:16:31.970
their own, you know, Nike
in these regions, right, Nike

315
00:16:31.970 --> 00:16:34.700
for Muslim people, Nike has
to be in front of

316
00:16:34.700 --> 00:16:36.710
the business case and say,
we really don't want to

317
00:16:36.710 --> 00:16:40.070
lose this customer. Right. This
customer doesn't own any Nike

318
00:16:40.070 --> 00:16:42.350
gear. And they could buy
a lot of Nike gear.

319
00:16:42.560 --> 00:16:44.810
So how do we get
in front of them and,

320
00:16:44.810 --> 00:16:48.710
and build that relationship. And
it is using their engineering

321
00:16:48.710 --> 00:16:51.620
resources. It is using, you
know, their marketing resources, but

322
00:16:51.620 --> 00:16:55.280
it's also just having that
empathy in, in the engineering

323
00:16:55.280 --> 00:16:59.090
and design to build what
makes sense for that customer.

324
00:17:00.370 --> 00:17:02.290
One of the things that
I've been excited about, and

325
00:17:02.290 --> 00:17:04.240
I've started to realize in
looking at the products and

326
00:17:04.240 --> 00:17:07.660
things that I, I use
myself, is that a lot

327
00:17:07.660 --> 00:17:09.700
of them are built by
smaller companies. You know, with

328
00:17:09.700 --> 00:17:12.970
the rise of Etsy, we're
getting design thinking and empathy

329
00:17:13.270 --> 00:17:15.910
from products that people are
building in their garages. You

330
00:17:15.910 --> 00:17:17.830
know, there's no reason that
Nike needs to own that

331
00:17:17.830 --> 00:17:20.980
market. The other people could.
Exactly. And, and the, the

332
00:17:20.980 --> 00:17:23.710
good part about that, right?
The internet sort of making

333
00:17:23.710 --> 00:17:28.240
that super flat and accessible
and you see people, you

334
00:17:28.240 --> 00:17:31.690
know, I don't know if
you're familiar with, with Yeti

335
00:17:31.690 --> 00:17:34.090
coolers, they're a brand, I
think out of Austin, Texas,

336
00:17:34.090 --> 00:17:37.060
or somewhere down South, and
they've grown into this billion

337
00:17:37.060 --> 00:17:40.540
dollar behemoth because they realize
that there is a massive

338
00:17:40.540 --> 00:17:46.330
need for, you know, well-designed
and attractive, super, super, super

339
00:17:46.330 --> 00:17:50.370
durable coolers. And it wasn't
being met. And that's something

340
00:17:50.370 --> 00:17:54.030
that, you know, Amazon can
have a billion, different coolers

341
00:17:54.030 --> 00:17:57.600
that they're selling, but they're
sort of optimizing for what's

342
00:17:57.600 --> 00:18:00.120
the cheapest, what's the, whatever,
you know, and this was

343
00:18:00.120 --> 00:18:02.820
a brand that somebody built
it to solve their own

344
00:18:02.820 --> 00:18:05.340
problems. And I think that,
that, that's sort of the,

345
00:18:05.370 --> 00:18:06.930
sort of the opposite of
what I was saying, but

346
00:18:06.930 --> 00:18:10.590
also a continuation of it
when you, if everyone, at

347
00:18:10.590 --> 00:18:14.070
some extent, is engineering things
to solve their own problems,

348
00:18:14.580 --> 00:18:17.070
or you're always biased towards
solving your own problems first,

349
00:18:17.340 --> 00:18:20.100
then I don't believe really
in trying to fight human

350
00:18:20.100 --> 00:18:22.200
nature on things. So if
that was the way humans

351
00:18:22.200 --> 00:18:25.860
are okay, so then if
everyone looks the same as

352
00:18:25.860 --> 00:18:28.770
from the same university lives
in the same town, then

353
00:18:28.920 --> 00:18:31.290
their problems are going to
be much more similar. If

354
00:18:31.290 --> 00:18:36.600
we have a much broader
range of backgrounds, experiences, you

355
00:18:36.600 --> 00:18:40.920
know, and, and perspectives in,
in, in engineering pod, right.

356
00:18:40.920 --> 00:18:44.640
Then we can actually solve
our own problems, but we're

357
00:18:44.640 --> 00:18:47.760
going to do it in
a much more empathetic way

358
00:18:48.000 --> 00:18:50.250
because we're bringing a lot
of different perspectives to the

359
00:18:50.250 --> 00:18:54.770
table, Just as a bit
of an anecdote. I think

360
00:18:54.770 --> 00:18:56.570
I've talked to you before
that I'm a type one

361
00:18:56.570 --> 00:19:00.680
diabetic, and I wear an
insulin pump, even though I've

362
00:19:00.680 --> 00:19:03.620
been doing this for 25
years. And one could argue

363
00:19:03.620 --> 00:19:06.140
that I'm one of the
most empathetic diabetics out there

364
00:19:06.140 --> 00:19:11.150
about diabetes stuff. I was
talking with a lady at

365
00:19:11.150 --> 00:19:13.640
my kid's school who is
also a diabetic, and she

366
00:19:13.640 --> 00:19:16.130
was complaining about how she
had nowhere to put her

367
00:19:16.970 --> 00:19:19.670
insulin pump. And I didn't
understand why it wasn't in

368
00:19:19.670 --> 00:19:23.750
her pocket. Her clothes have
pockets. There there's so many

369
00:19:23.750 --> 00:19:26.030
clothes for when they have
no pockets. She has a

370
00:19:26.060 --> 00:19:29.990
custom bra with an insulin
pump pocket. There is actually

371
00:19:30.140 --> 00:19:33.680
some pump bra market. Absolutely.
And that's the type of

372
00:19:33.680 --> 00:19:35.300
thing, right? That you would
just, as soon as you

373
00:19:35.300 --> 00:19:37.280
said that I knew exactly
what you were talking about

374
00:19:37.280 --> 00:19:40.250
because yeah. You know, beat
a woman, you, you constantly,

375
00:19:40.250 --> 00:19:42.830
I actually, you know, I,
I work out a lot.

376
00:19:42.830 --> 00:19:46.400
And so it's so hard,
guys. You it's really hard

377
00:19:46.400 --> 00:19:48.950
to find gym shorts that
don't have pockets, right. But

378
00:19:48.950 --> 00:19:51.140
you almost never see girls
in the gym and like

379
00:19:51.140 --> 00:19:54.980
basketball shorts, right. Leggings almost
never have pockets because of

380
00:19:54.980 --> 00:19:57.170
the way they're designed. And
it's such a pain. Like,

381
00:19:57.200 --> 00:19:59.420
I can't tell you how
many times my phone has

382
00:19:59.420 --> 00:20:02.180
gone flying during the middle
of a workout because it's

383
00:20:02.180 --> 00:20:04.940
not in a pocket. And
so recently I've started only

384
00:20:04.940 --> 00:20:07.250
buying, you know, leggings and
workout clothes and stuff that

385
00:20:07.250 --> 00:20:09.740
have pockets in them. Because
before that, I would have

386
00:20:09.740 --> 00:20:13.160
to wear a coat to
the gym strictly because I

387
00:20:13.160 --> 00:20:16.040
needed a place to put
my phone while I was

388
00:20:16.040 --> 00:20:18.230
working out. You can do
the arm bands, but they

389
00:20:18.230 --> 00:20:20.780
were pain. So it's, it's
so interesting how something like

390
00:20:20.780 --> 00:20:23.030
that to half the population
is obvious and to the

391
00:20:23.030 --> 00:20:25.400
other half, it's not, and
it has nothing to do

392
00:20:25.400 --> 00:20:28.280
with, you know, your preferences
or biases or anything. It's

393
00:20:28.280 --> 00:20:30.590
just, you go into the
store and you buy pants

394
00:20:30.590 --> 00:20:32.180
and she goes into the
store and she buys pants.

395
00:20:32.330 --> 00:20:34.250
Your pants will have pockets
a hundred percent of the

396
00:20:34.250 --> 00:20:37.730
time. Women's pants, love pockets
that actually work and are

397
00:20:37.730 --> 00:20:41.000
big enough for an insulin
pump. Maybe 30% of the

398
00:20:41.000 --> 00:20:43.700
time. You know, it's pretty
crazy what a difference that

399
00:20:43.700 --> 00:20:47.320
makes It really does. So
how are you applying of

400
00:20:47.320 --> 00:20:51.820
these concepts around design thinking
and empathy into the products

401
00:20:51.820 --> 00:20:54.600
that you make? Like products?
Yeah. So, so, you know,

402
00:20:54.660 --> 00:20:58.140
especially on mobile phones, it's,
it is interesting when you

403
00:20:58.140 --> 00:21:00.690
are working on a platform
that has so many constraints

404
00:21:00.690 --> 00:21:03.750
that are completely above your
pay grade, right? So anybody

405
00:21:03.750 --> 00:21:06.510
who's built apps for Apple
or products on Apple, you

406
00:21:06.510 --> 00:21:08.880
know, you can't just say,
Oh, well I think this

407
00:21:08.880 --> 00:21:11.490
should happen. Apple says, no,
this is the way that

408
00:21:11.490 --> 00:21:14.700
you can play within our
walled garden. Right. And so

409
00:21:14.700 --> 00:21:18.330
that is always an interesting
challenge. And, and we have

410
00:21:18.330 --> 00:21:21.780
a lot of conversations about
fringe cases. I know that

411
00:21:21.960 --> 00:21:24.870
that a lot of times
those can feel more like

412
00:21:24.870 --> 00:21:27.840
thought experiments and to be
totally honest, sometimes they are

413
00:21:27.840 --> 00:21:31.230
thought experiments. But I, what
I've found is that by

414
00:21:31.230 --> 00:21:36.960
having those discussions, right, it
makes, when you have those

415
00:21:36.960 --> 00:21:40.800
discussions, it means that it's
at least on your radar,

416
00:21:40.800 --> 00:21:44.130
right. So we might say,
Oh, you know, should we

417
00:21:44.130 --> 00:21:48.000
have a logging tool? Or
should we have a, you

418
00:21:48.000 --> 00:21:50.610
know, a way to read
the website that is super

419
00:21:50.610 --> 00:21:53.940
easy to use if you,
you know, with disabilities. And

420
00:21:53.940 --> 00:21:55.950
then we say, honestly, we
don't have disabilities. We don't

421
00:21:55.950 --> 00:21:58.050
know what that looks like.
So then we'll go, we

422
00:21:58.050 --> 00:22:01.200
might start with, you know,
Googling and finding like a

423
00:22:01.200 --> 00:22:05.040
medium article or something about
developer who, you know, has

424
00:22:05.100 --> 00:22:08.010
low hearing or, or poor
vision and how they, how

425
00:22:08.010 --> 00:22:11.160
they, what their top things
to think about. Right. When

426
00:22:11.160 --> 00:22:14.160
building an app for those
populations, we might look into

427
00:22:14.160 --> 00:22:17.490
Apple's documentation itself and say,
okay, what does Apple do?

428
00:22:17.520 --> 00:22:20.100
Right. Are there solutions, sometimes
you want to build a

429
00:22:20.100 --> 00:22:22.830
solution, then you find out,
Oh, no, Apple actually, you

430
00:22:22.830 --> 00:22:24.960
know, has a disability mode
that does X, Y, Z

431
00:22:24.960 --> 00:22:27.930
already. And, and so it's
not always, and I think

432
00:22:27.930 --> 00:22:29.460
this is a big part
of it. When you set

433
00:22:29.460 --> 00:22:32.760
out to engineer with empathy,
it's not always that you

434
00:22:32.760 --> 00:22:37.500
end up building fundamentally different
solutions. It's it, to some

435
00:22:37.500 --> 00:22:39.810
extent you're just taking this
sort of surprise out of

436
00:22:39.810 --> 00:22:42.090
it, right? It's like the
QA process. Sometimes you go

437
00:22:42.090 --> 00:22:45.390
through QA and you find
huge, giant bugs that you

438
00:22:45.390 --> 00:22:48.030
have to fix. Other times
you go through QA and

439
00:22:48.030 --> 00:22:49.890
you've done everything perfectly and
it works and it can

440
00:22:49.890 --> 00:22:53.010
ship. Right. It doesn't mean
that you, if you do

441
00:22:53.010 --> 00:22:56.100
QA and there are no
bugs, you wouldn't say, okay,

442
00:22:56.100 --> 00:22:58.620
I'm done, right. Like I'm
never doing QA again. I've

443
00:22:58.620 --> 00:23:02.460
clearly imperfect and it'll never
be wrong again. It's still

444
00:23:02.460 --> 00:23:05.580
a needed kind of thought
experiment to go through. And

445
00:23:05.580 --> 00:23:09.840
so, you know, it, that
I think is an important

446
00:23:09.840 --> 00:23:13.950
thing to remember that you
don't want to say, Oh,

447
00:23:13.980 --> 00:23:17.430
well, it was all, you
know, I don't understand what

448
00:23:17.430 --> 00:23:19.140
we would need to change,
or there was nothing to

449
00:23:19.140 --> 00:23:23.670
change. So, you know, don't
worry about it is, is

450
00:23:23.670 --> 00:23:27.090
really not the way to
go. You really do need

451
00:23:27.090 --> 00:23:31.740
to say every time, okay.
You know, it, it worked

452
00:23:31.740 --> 00:23:35.100
this time, but we're still
gonna keep investigating it. And

453
00:23:35.100 --> 00:23:37.920
I think when you keep
that mindset, really interesting things

454
00:23:37.920 --> 00:23:40.170
pop up. And the other
cool thing about engineering is

455
00:23:40.170 --> 00:23:43.920
you never know when, by
being more empathetic, you're going

456
00:23:43.920 --> 00:23:47.180
to stumble onto a massive
market that you would have

457
00:23:47.180 --> 00:23:50.120
not seen otherwise. And so
I think that there's a

458
00:23:50.120 --> 00:23:53.060
huge business case for it.
And, and it's also kind

459
00:23:53.060 --> 00:23:56.060
of fun, you know, it
being in that stage of

460
00:23:56.060 --> 00:23:59.210
learning and just thinking about
new problems and new ways

461
00:23:59.210 --> 00:24:01.990
is, is one of the
best parts of engineering. Yeah.

462
00:24:02.170 --> 00:24:05.620
It's interesting because I'm sitting
here thinking about how, what

463
00:24:05.620 --> 00:24:08.140
we used to think of
as niches. There are no

464
00:24:08.140 --> 00:24:10.180
niches. If it, if it's
1% of the world, it's

465
00:24:10.180 --> 00:24:12.250
still a massive market. So
what you're just, what you're

466
00:24:12.250 --> 00:24:14.140
saying is absolutely true. You
could build a billion dollar

467
00:24:14.140 --> 00:24:20.080
company on a niche. Absolutely
Interesting. So when do you

468
00:24:20.080 --> 00:24:22.000
think we need to learn,
teach this in schools as,

469
00:24:22.000 --> 00:24:25.060
as empathy and design and
empathy in software development, something

470
00:24:25.060 --> 00:24:27.820
that needs to be taught
and see us one-on-one Yeah.

471
00:24:27.970 --> 00:24:31.360
I mean, I think that
it is a, I think

472
00:24:31.360 --> 00:24:34.750
in every part of product
development, right? So from thinking

473
00:24:34.750 --> 00:24:36.970
about why are you building
a product in the first

474
00:24:36.970 --> 00:24:41.170
place to, you know, design,
to engineering? It's an, it's

475
00:24:41.170 --> 00:24:43.630
an integral part of it.
Right. And I think it's

476
00:24:43.630 --> 00:24:47.440
especially in engineering because so
often engineers are the ones,

477
00:24:47.440 --> 00:24:49.390
you know, the designer might
say, Hey, this is what

478
00:24:49.390 --> 00:24:52.840
I want. But often if
it comes down to pushback

479
00:24:52.840 --> 00:24:56.800
from the engineers, right, that
they're going to win out

480
00:24:56.800 --> 00:24:59.680
because they're the ones actually
building it. Right. So engineers

481
00:24:59.710 --> 00:25:03.100
understand why this empathy matters.
They might see something in

482
00:25:03.100 --> 00:25:06.670
the design or in the
product spec that doesn't seem

483
00:25:06.670 --> 00:25:10.000
intuitive to them or doesn't
seem useful or needed. And

484
00:25:10.000 --> 00:25:13.090
I think that having that,
that grounded, that grounding and

485
00:25:13.090 --> 00:25:15.880
understanding, and Hey, here's the
business case and the innovation

486
00:25:15.880 --> 00:25:19.750
case for why we care
about empathy is super helpful.

487
00:25:19.750 --> 00:25:21.940
And I do think the
earlier you start the better,

488
00:25:21.940 --> 00:25:24.100
right? If you've ever spent
time on college campuses with

489
00:25:24.100 --> 00:25:27.760
engineers, they always, you know,
typically at that stage in

490
00:25:27.760 --> 00:25:30.430
your life, you know, you
don't have a ton of

491
00:25:30.430 --> 00:25:34.060
experience in life because, you
know, you've, you've never had

492
00:25:34.060 --> 00:25:36.370
to buy a car by
yourself maybe, or have a

493
00:25:36.370 --> 00:25:39.040
mortgage or had kids. And
so a lot of times

494
00:25:39.040 --> 00:25:42.310
you'll see that college engineers
sort of always want to

495
00:25:42.310 --> 00:25:45.250
build the same tools, right?
Every college is like, Oh,

496
00:25:45.250 --> 00:25:47.770
there's not enough parking on
campus. Or there's, we need

497
00:25:47.770 --> 00:25:49.690
to build an app for
parking, or there's not, you

498
00:25:49.690 --> 00:25:51.640
know, we need something to,
we can play video games

499
00:25:51.640 --> 00:25:54.070
with other friends, easier. We
don't want to use Twitch.

500
00:25:54.220 --> 00:25:57.100
It's slightly better than Twitch.
And, and we've, we've taught

501
00:25:57.100 --> 00:26:01.030
engineers to kind of think
their way through the sort

502
00:26:01.030 --> 00:26:03.280
of startup roadmap of does
that make sense? Is that

503
00:26:03.280 --> 00:26:05.050
good? Is that what we
want to do? And we've

504
00:26:05.050 --> 00:26:07.150
done a good job of
getting them to think through

505
00:26:07.150 --> 00:26:11.620
that. I think that the
space that we are missing

506
00:26:11.890 --> 00:26:15.910
is how do we get
them to think through some

507
00:26:15.910 --> 00:26:19.600
of these empathy challenges in
the same way, right. And,

508
00:26:19.630 --> 00:26:23.950
and it's not hard. It's
just another piece of, of

509
00:26:23.980 --> 00:26:26.980
good engineering and good design
and good product development that

510
00:26:26.980 --> 00:26:30.730
we need to teach early.
Hmm. It's so interesting that

511
00:26:30.760 --> 00:26:33.130
now we seem to find
these things. If we don't

512
00:26:33.130 --> 00:26:35.080
teach them upfront, we end
up finding them in user

513
00:26:35.080 --> 00:26:41.230
testing, like the, the now
legendary faucet detector that can't

514
00:26:41.230 --> 00:26:46.620
see black hands exactly. Or,
You know, in, in China,

515
00:26:46.890 --> 00:26:50.130
the face unlock is, is
being unlocked by other people.

516
00:26:50.370 --> 00:26:53.160
And you know, it's certainly
not it. These are, you

517
00:26:53.160 --> 00:26:54.990
know, when you get to
things like AI and machine

518
00:26:54.990 --> 00:26:57.510
learning, right. Which is, is
largely with the face lock

519
00:26:57.540 --> 00:27:02.190
is it's not at that
point, you know, a human,

520
00:27:03.200 --> 00:27:05.580
when we teach machines, right.
Machine learning means that we're

521
00:27:05.580 --> 00:27:10.140
teaching machines, basically everything that
they can learn from us,

522
00:27:10.140 --> 00:27:13.080
depending on how wide those
parameters are. And so if

523
00:27:13.080 --> 00:27:16.080
you teach them how to
tell Asian faces apart, they

524
00:27:16.080 --> 00:27:18.120
can tell Asian faces apart.
If you don't, then they

525
00:27:18.120 --> 00:27:23.430
can't. Right. And so there's,
it's so as technology sort

526
00:27:23.430 --> 00:27:29.220
of gets exponentially better, the,
the fallout or the risk

527
00:27:29.220 --> 00:27:33.060
of making the wrong decisions
or not being empathetic enough

528
00:27:33.090 --> 00:27:36.900
early on get bigger. Right.
One thing that I thought

529
00:27:36.900 --> 00:27:39.840
was really interesting about the,
the, the soap dispensers that

530
00:27:39.840 --> 00:27:42.990
can't see black hands is
there is a question, you

531
00:27:42.990 --> 00:27:45.690
know, that I, that I
saw on Twitter that said,

532
00:27:46.080 --> 00:27:48.270
what happens if self driving
cars have the same problem.

533
00:27:49.140 --> 00:27:54.270
Right. And it's a massive
thing to think about. And

534
00:27:54.270 --> 00:27:55.860
it's, you know, and, and
we see that in simple

535
00:27:55.860 --> 00:28:00.060
machinery, right? Five-year-olds, can't sit
in the front seat because

536
00:28:00.090 --> 00:28:03.540
they're not heavy enough generally
for the airbag detector to

537
00:28:03.540 --> 00:28:06.900
go off. Right. It's not
that the car companies want

538
00:28:06.900 --> 00:28:10.200
to kill your kindergartener. It's
just that the way that

539
00:28:10.200 --> 00:28:13.080
that product is engineered. And
I think it's also the

540
00:28:13.080 --> 00:28:14.820
way the seatbelts are, but
you know, the way that

541
00:28:14.820 --> 00:28:19.200
that product is engineered is,
is unsafe for certain populations.

542
00:28:19.200 --> 00:28:22.020
And we know that, and
we accept that. But with

543
00:28:22.020 --> 00:28:25.230
technology, sometimes we think, Oh,
well it works equally. It's

544
00:28:25.230 --> 00:28:28.110
technology. It can't be racist.
It can't be sexist, it

545
00:28:28.110 --> 00:28:31.380
just works, but that's not
always the way it does.

546
00:28:31.380 --> 00:28:33.360
And so there's some big
questions that we have to

547
00:28:33.360 --> 00:28:36.570
grapple with. And, and quite
frankly, not only would it

548
00:28:36.570 --> 00:28:39.720
be terrifying if self driving
cars couldn't see black people

549
00:28:39.720 --> 00:28:42.240
and started running them over,
it would also be a

550
00:28:42.240 --> 00:28:46.470
public relations and financial nightmare
for these companies that they

551
00:28:46.470 --> 00:28:50.010
very well might not survive.
So from an empathy perspective

552
00:28:50.010 --> 00:28:52.260
and from a business perspective,
like these things have to

553
00:28:52.260 --> 00:28:55.520
be solved. Yeah. I think
that, that point though, that

554
00:28:55.560 --> 00:28:57.530
the root point that really
hit me, what you just

555
00:28:57.530 --> 00:29:00.320
said was you can't say,
Oh, it's just technology. It

556
00:29:00.320 --> 00:29:02.750
just works. As it was
made by people, it was

557
00:29:02.750 --> 00:29:05.810
coded by people. It was
designed by people for people.

558
00:29:06.140 --> 00:29:09.440
So the idea that people
think that technology can't be

559
00:29:10.400 --> 00:29:14.060
by its definition, excluding that's
just wrong. You know, an

560
00:29:14.060 --> 00:29:16.970
interesting story that you might
be interested in. My, my

561
00:29:17.000 --> 00:29:20.180
family came over from South Africa
and they were shocked at

562
00:29:20.180 --> 00:29:23.060
how many ramps there were.
They could not get there.

563
00:29:23.060 --> 00:29:26.600
They were just like, there's
ramps everywhere. And they were

564
00:29:26.600 --> 00:29:27.920
freaking out. I was like,
well, yeah, there was a

565
00:29:27.920 --> 00:29:31.610
law, like, you know, 40
years ago called the Americans

566
00:29:31.610 --> 00:29:33.440
with disabilities act. We have
to have ramps so people

567
00:29:33.440 --> 00:29:36.290
can get up. And then
they started realizing that stairs

568
00:29:36.680 --> 00:29:40.730
are exclusive excluding, and that
they thought that everyone needs

569
00:29:40.730 --> 00:29:42.790
to have that. We should
have ramps for everybody. I

570
00:29:42.790 --> 00:29:45.280
thought that was so interesting
that they came from a

571
00:29:45.280 --> 00:29:49.080
town that just didn't have
ramps. Yeah. Isn't that crazy.

572
00:29:49.980 --> 00:29:52.200
It is. And for, and
then for me to go

573
00:29:52.200 --> 00:29:55.020
into, It makes complete sense,
right? Like, why wouldn't you

574
00:29:55.020 --> 00:29:57.720
at ramps everywhere, but, but
we do sort of take

575
00:29:57.720 --> 00:30:00.840
it for granted. Yeah. It's
interesting how, and, and you

576
00:30:00.840 --> 00:30:02.220
know that, and we didn't
touch on that and we're

577
00:30:02.220 --> 00:30:04.440
running out of time, but
that the reason that America

578
00:30:04.440 --> 00:30:06.750
has so many ramps, right.
And elevators and everything else

579
00:30:06.750 --> 00:30:11.610
is because of actually legislation,
because it wasn't apparent and

580
00:30:11.610 --> 00:30:14.820
obvious to anyone until a
group of people got together

581
00:30:14.820 --> 00:30:16.920
and advocated for it. And
it, and it became a

582
00:30:16.920 --> 00:30:20.520
law, you know? And so
I think most engineers and

583
00:30:20.520 --> 00:30:23.130
most people in technology, we
like to solve our own

584
00:30:23.130 --> 00:30:26.340
problems before and not get
to the point where government

585
00:30:26.370 --> 00:30:28.950
feels like they should step
in and regulate. But, but

586
00:30:28.950 --> 00:30:31.560
then that becomes an issue
of self regulation, right? If

587
00:30:31.800 --> 00:30:34.530
you are, you know, in
a wheelchair, or if you

588
00:30:34.530 --> 00:30:37.170
just broke your leg, you
shouldn't not be able to

589
00:30:37.170 --> 00:30:41.160
get into buildings for, you
know, any building ever like

590
00:30:41.160 --> 00:30:43.950
that. That's an insane way
to live. And so it

591
00:30:43.950 --> 00:30:46.770
was changed. And hopefully with
some of these technology questions,

592
00:30:47.460 --> 00:30:50.520
we can take ownership of
these issues and, and, and

593
00:30:50.520 --> 00:30:53.280
make the world a more
empathetic place ourselves. So that

594
00:30:53.280 --> 00:30:56.190
we don't end up, you
know, with, with government regulators

595
00:30:56.190 --> 00:30:58.740
coming in and saying, Hey,
you know, you guys have

596
00:30:58.740 --> 00:31:00.870
to build ramps. This can't
just be a stairway world.

597
00:31:01.440 --> 00:31:04.080
Exactly. Well, thank you so
much for sharing your thoughts

598
00:31:04.080 --> 00:31:09.630
with us today. Sarah Koons,
you can check out sarah@pro.co

599
00:31:09.660 --> 00:31:13.080
and on Twitter. This has
been another episode of Hansel

600
00:31:13.080 --> 00:31:15.000
minutes, and we'll see you
again next week.

