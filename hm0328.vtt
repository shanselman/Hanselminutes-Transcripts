WEBVTT FILE

1
00:00:04.920 --> 00:00:17.060
<inaudible> Hanselminutes.com. It's Hansel minutes,
a weekly discussion with web

2
00:00:17.060 --> 00:00:21.650
developer and technologists. Scott Hanselman.
This is Lawrence Ryan announcing show

3
00:00:21.650 --> 00:00:27.770
number three 30 recorded live
Thursday, July 26th, 2012. Support for Hanselman.

4
00:00:27.770 --> 00:00:30.980
This is provided by teller.
Offering the best in developer

5
00:00:30.980 --> 00:00:40.520
tools and support online@telerikdotcomandbyfranklins.net training
developers to work smarter and

6
00:00:40.520 --> 00:00:44.180
now offering gesture pack a
powerful gesture, recording and recognition

7
00:00:44.180 --> 00:00:48.620
system for Microsoft connect for
windows developers. details' at gesture

8
00:00:48.620 --> 00:00:53.180
PA k.com. In this episode,
Scott talks with Microsoft Azure

9
00:00:53.180 --> 00:00:59.930
product team member and author.
Hi, this is Scott Hanselman.

10
00:00:59.930 --> 00:01:01.700
This is another episode of
Hansel minutes. And today I'm

11
00:01:01.700 --> 00:01:04.490
sitting in building one Oh
nine on the Redmond campus

12
00:01:04.490 --> 00:01:07.970
of Microsoft with the one
and only Mark Russinovich. How

13
00:01:07.970 --> 00:01:10.400
are you, sir? Hi Scott.
I'm doing well to a

14
00:01:10.400 --> 00:01:12.350
pretty string. Pretty good, because
I just finished your book.

15
00:01:12.650 --> 00:01:15.260
Yeah, I saw you tweet
about it. Yeah. I tweeted

16
00:01:15.260 --> 00:01:17.150
directly from my Kindle. I've
gotten in the habit of

17
00:01:17.150 --> 00:01:20.240
finishing books on my Kindle
and then tweeting directly from

18
00:01:20.240 --> 00:01:22.520
the Kindle and, and doing
it. And the best part

19
00:01:22.520 --> 00:01:26.300
about it was that after
I finished the Amazon Kindle

20
00:01:26.300 --> 00:01:28.910
said the next book is
coming out. I just told

21
00:01:28.910 --> 00:01:30.590
you that. Yeah. So it's
like, there's two in the

22
00:01:30.590 --> 00:01:33.560
series. Someone has added that
metadata. That's pretty cool. I

23
00:01:33.560 --> 00:01:35.510
didn't realize that it did
that. I read books off

24
00:01:35.510 --> 00:01:38.360
Kendall too. And the Kindle
app. So somehow they're pulling

25
00:01:38.360 --> 00:01:40.760
that from some metadata Wikipedia.
And now that it knows

26
00:01:40.760 --> 00:01:43.490
that there's the second one
in the series. So the

27
00:01:43.490 --> 00:01:47.270
book was called zero day
and I don't know why,

28
00:01:47.270 --> 00:01:49.070
but I think I thought
when I started it, that

29
00:01:49.070 --> 00:01:53.360
it would be focused at
like me the nerd, but

30
00:01:53.360 --> 00:01:56.270
it really bridges two worlds.
I mean, you can read

31
00:01:56.270 --> 00:01:58.790
it and go, wow, that's
technically correct. And that's technically

32
00:01:58.790 --> 00:02:00.770
correct, but at the same
time, it is a mainstream

33
00:02:00.770 --> 00:02:02.930
novel. I mean, you want
regular people to read this

34
00:02:02.930 --> 00:02:04.970
too, right? Yep. I definitely,
when I set out to

35
00:02:04.970 --> 00:02:07.520
write the book, I wanted
to appeal to technical people

36
00:02:07.520 --> 00:02:10.160
and I wanted somebody like
you to sit down and

37
00:02:10.160 --> 00:02:13.040
read it and not go
cringe and cover your eyes

38
00:02:13.040 --> 00:02:15.770
and go, that's just ridiculous
or, or hot from point

39
00:02:15.770 --> 00:02:17.690
a to point B with
magic in the middle, which

40
00:02:17.690 --> 00:02:20.450
I can't stand in books.
I like, if everything in

41
00:02:20.450 --> 00:02:22.370
the book, I think I
hope you notice this, but

42
00:02:22.700 --> 00:02:24.830
I try to make it
clear how things got from

43
00:02:25.010 --> 00:02:28.280
point a to point B
I don't at least so

44
00:02:28.280 --> 00:02:29.960
that you can figure out
how things got point from

45
00:02:29.960 --> 00:02:32.690
point a to point B
and not that magic happened

46
00:02:32.690 --> 00:02:37.610
or, you know, unexplained circumstances
got us the plot moving

47
00:02:37.610 --> 00:02:40.520
forward kind of thing. But
I also wanted to appeal

48
00:02:40.520 --> 00:02:42.680
to the mainstream audience to
educate them about what is

49
00:02:42.680 --> 00:02:46.400
computer security and what's this
world that really everybody's living

50
00:02:46.400 --> 00:02:49.280
in whether they realize it
or not. Would you say

51
00:02:49.280 --> 00:02:51.470
that the essence of the
book was to scare or

52
00:02:51.470 --> 00:02:53.180
to educate or a little
of both? It was a

53
00:02:53.180 --> 00:02:56.630
little of both. Actually. I
think that this threat that

54
00:02:56.630 --> 00:02:58.460
I portray in the book
is absolutely one that I

55
00:02:58.460 --> 00:03:02.260
consider very realistic and I'm
surprised that it hasn't been

56
00:03:02.560 --> 00:03:05.920
taken up. But up to
this point, I figured that

57
00:03:06.010 --> 00:03:09.520
we would already pass the
book in reality some time

58
00:03:09.520 --> 00:03:11.350
ago. And I was concerned,
actually it took so long

59
00:03:11.350 --> 00:03:13.030
to get the book published
that it would be obsolete

60
00:03:13.030 --> 00:03:14.950
by the time it came
out, it'd be viewed as

61
00:03:14.950 --> 00:03:18.610
historical fiction. So in that
sense, I was lucky, but

62
00:03:18.940 --> 00:03:21.100
I do think that it's
just a matter of time

63
00:03:21.100 --> 00:03:27.370
before somebody that just nefariously
or maliciously just mischievously goes

64
00:03:27.370 --> 00:03:30.880
out to cause destruction just
because they can, through this

65
00:03:31.210 --> 00:03:36.870
means of using cyber weapons
malware to do so. Everyone

66
00:03:36.870 --> 00:03:39.360
thought that everything was going
to fall apart at the,

67
00:03:39.360 --> 00:03:43.920
in Y2K. And it didn't
not because the problem wasn't

68
00:03:43.920 --> 00:03:46.170
pervasive. Cause it was, and
not because lots of things

69
00:03:46.170 --> 00:03:48.720
didn't break cause they did,
but we did fall back

70
00:03:49.140 --> 00:03:51.900
onto existing things and nothing
major broke. I mean, I

71
00:03:51.900 --> 00:03:54.390
don't think any dams fell
over because of Y2K. Yeah.

72
00:03:55.110 --> 00:03:57.720
Was it because of the
media overblow it or was

73
00:03:57.720 --> 00:04:00.480
it because maybe computers aren't
as pervasive as we think,

74
00:04:00.480 --> 00:04:02.610
and they aren't as important
as we think that they

75
00:04:02.610 --> 00:04:05.250
are? Well, I think In
Y two K if you,

76
00:04:05.250 --> 00:04:08.130
if you think computers were
pervasively used in around the

77
00:04:08.130 --> 00:04:12.510
year 2000 it's orders of
magnitude more pervasive now just

78
00:04:12.510 --> 00:04:15.540
literally last week, Obama published
an editorial in the wall

79
00:04:15.540 --> 00:04:18.870
street journal, which starts out.
I was just called in

80
00:04:18.870 --> 00:04:22.500
my top security advisors. The
water supply in major cities

81
00:04:22.500 --> 00:04:27.150
had been polluted. The trains
had been derailed and yeah,

82
00:04:27.160 --> 00:04:29.100
there was a simulation, it
was a simulation of a

83
00:04:29.100 --> 00:04:32.850
cyber attack on our critical
infrastructure. And the reason that

84
00:04:32.850 --> 00:04:37.080
he did that, that editorial
list up helped promote legislation.

85
00:04:37.080 --> 00:04:40.500
That's trying to get its
way through Congress, to require

86
00:04:40.740 --> 00:04:43.080
companies in the private sector
that are responsible for our

87
00:04:43.080 --> 00:04:46.880
critical infrastructure, like water and
gas and electricity to AFT

88
00:04:46.880 --> 00:04:50.040
to adhere to certain cyber
security guidelines that they don't

89
00:04:50.040 --> 00:04:52.050
have to today, basically everybody's
on their own to do

90
00:04:52.050 --> 00:04:54.270
whatever they want to, which
leaves us incredibly vulnerable to

91
00:04:54.270 --> 00:04:57.300
this kind of stuff. You
know how, when you're out

92
00:04:57.300 --> 00:05:00.540
in the world, you see,
you know, blue screens, but

93
00:05:00.540 --> 00:05:04.530
not, not recent ones. And
for running Alaska airlines as

94
00:05:04.530 --> 00:05:08.550
kiosks, or as you travel,
you spot these things. It

95
00:05:08.550 --> 00:05:11.460
seems like a lot of
our security and a lot

96
00:05:11.460 --> 00:05:14.070
of our infrastructure is running
on incredibly old operating systems.

97
00:05:14.280 --> 00:05:18.030
Yeah. And even that's even
more so for the SCADA

98
00:05:18.040 --> 00:05:22.110
type systems that scan it,
the supervisory control and data

99
00:05:22.110 --> 00:05:25.680
acquisition systems that are used
to run like power plants

100
00:05:25.680 --> 00:05:29.040
and generators and even centrifuges
like the ones used in

101
00:05:29.040 --> 00:05:33.060
the Iranian nuclear program. Those
are both old and even

102
00:05:33.060 --> 00:05:35.160
the new ones, they're just
not designed for an environment

103
00:05:35.160 --> 00:05:39.870
where they're exposed to hostile
threats. They're really designed for,

104
00:05:39.870 --> 00:05:42.540
Hey, you're putting this thing
into a controlled environment where

105
00:05:42.990 --> 00:05:45.840
only trusted people in code
is accessing it. And so

106
00:05:45.840 --> 00:05:48.000
we don't need to be
really rigorous about security. And

107
00:05:48.000 --> 00:05:49.920
the fact is that that's
no longer the case. This

108
00:05:49.920 --> 00:05:53.010
stuff is all basically exposed
to the internet either directly

109
00:05:53.010 --> 00:05:56.040
or indirectly. As we saw
on the Iran, Iranian the

110
00:05:56.040 --> 00:05:59.300
Stuxnet attack through USB keys
that came, walked into the

111
00:05:59.300 --> 00:06:03.530
facility. And then the SCADA
systems are basically indirectly exposed

112
00:06:03.530 --> 00:06:09.860
to CIA operatives sitting in
Virginia. And the, the fact

113
00:06:09.860 --> 00:06:11.540
is that the system is
being used in this way.

114
00:06:11.570 --> 00:06:14.210
Not they're not designed for
is part of that, a

115
00:06:14.210 --> 00:06:17.530
weakness that we've got now
at this point. It's, but

116
00:06:17.530 --> 00:06:19.780
it's the problem of technological
one or a social one

117
00:06:19.780 --> 00:06:22.150
because you use the example
of USB keys. And I

118
00:06:22.150 --> 00:06:25.210
always thought it was funny
that the real attack would

119
00:06:25.210 --> 00:06:28.180
come when someone flew over
and dropped USB keys and

120
00:06:28.180 --> 00:06:31.210
like any major corporations parking
lot, just picked them up,

121
00:06:31.210 --> 00:06:33.760
you know, free, free DVDs
or whatever it put it

122
00:06:33.760 --> 00:06:36.490
in. And boom, you're in,
I mean, that's USB keys

123
00:06:36.490 --> 00:06:40.420
or associate. They are a
social problem. And actually well

124
00:06:40.420 --> 00:06:42.790
doing a mass attack with
USB keys. I think people

125
00:06:42.790 --> 00:06:45.010
would start to figure that
out, but you drop a

126
00:06:45.010 --> 00:06:46.990
few in a parking lot
and actually anybody that's in

127
00:06:46.990 --> 00:06:50.830
the penetration testing business knows
best way into the front

128
00:06:50.830 --> 00:06:52.900
door of a business is
just dropping USB key in

129
00:06:52.900 --> 00:06:55.840
the parking lot or a
few. Right. And then they're

130
00:06:55.840 --> 00:06:57.820
going to show up on
the entrance in internal network

131
00:06:57.820 --> 00:07:00.520
there. And, and if somebody's
going to click on a

132
00:07:00.760 --> 00:07:03.610
whatever's on it to see
what's going on and that's,

133
00:07:03.640 --> 00:07:06.580
they're inside the network at
that point. So that's a

134
00:07:06.580 --> 00:07:08.410
social problem though. But I
mean, as we had it,

135
00:07:08.410 --> 00:07:10.510
we can train people not
to do that. It's an

136
00:07:10.510 --> 00:07:12.910
easy thing to get the
word out. We can change

137
00:07:12.910 --> 00:07:16.840
the operating systems to do
different things around autoplay. And

138
00:07:16.840 --> 00:07:18.520
I know that windows has
done that. And then the

139
00:07:18.850 --> 00:07:22.630
culture of automatically doing something
upon user action is, is

140
00:07:22.630 --> 00:07:24.700
changing. But what do we
have to do to the

141
00:07:24.700 --> 00:07:27.310
operating systems to make these
things more secure? I mean,

142
00:07:27.340 --> 00:07:31.120
these scatter systems were designed
10, 15, 20 years ago

143
00:07:31.150 --> 00:07:34.150
or longer in a world
where there was a kinder,

144
00:07:34.150 --> 00:07:36.910
gentler internet or no internet
at all. They're never going

145
00:07:36.910 --> 00:07:40.360
to upgrade the people who
wrote those are retired. Yeah.

146
00:07:40.390 --> 00:07:43.990
Well I think we either,
we face a hard problem

147
00:07:43.990 --> 00:07:45.760
there. We've got to upgrade
them or we're going to

148
00:07:45.760 --> 00:07:48.790
be left to insecurity because
part of the part of

149
00:07:48.790 --> 00:07:51.520
it, like you said, is
social aspect of it. But

150
00:07:51.520 --> 00:07:54.820
even if you train people,
the software still has vulnerabilities.

151
00:07:54.820 --> 00:07:58.780
That can be exploited. So
I worked my way into

152
00:07:58.780 --> 00:08:01.630
your network through some software
vulnerability. Now I'm in your

153
00:08:01.630 --> 00:08:04.180
network. And then I get
into the SCADA system, which

154
00:08:04.240 --> 00:08:07.390
has its own vulnerabilities. So
what we need is multiple

155
00:08:07.390 --> 00:08:11.680
layers of defense. You need
best security practices at each

156
00:08:11.680 --> 00:08:13.600
layer in the system is
certainly as you get more

157
00:08:13.600 --> 00:08:17.230
towards the hardcore center, you
need, of course the training

158
00:08:17.230 --> 00:08:19.330
that goes with that too,
for people to be secure,

159
00:08:19.330 --> 00:08:24.460
but where you can, I
think technological solutions where people

160
00:08:24.460 --> 00:08:27.820
don't have to remember to
be secure are the best

161
00:08:27.820 --> 00:08:30.760
ones. And you see this
a trend towards creating these

162
00:08:30.760 --> 00:08:33.130
kinds of technological solutions to
make our systems more secure

163
00:08:33.130 --> 00:08:36.160
in the mobile space. If
you look at what Apple's

164
00:08:36.160 --> 00:08:39.700
done with the app store,
basically that's white listing curated

165
00:08:39.700 --> 00:08:43.300
white list. So the operating
system won't run anything that's

166
00:08:43.300 --> 00:08:47.380
not been approved. And Apple's
got this very rigorous process

167
00:08:47.380 --> 00:08:49.330
of approving the software that
goes in the app store.

168
00:08:49.330 --> 00:08:51.010
And Microsoft's going to have
the same thing for our

169
00:08:51.010 --> 00:08:53.830
app store for windows eight,
that we've seen how incredibly

170
00:08:53.830 --> 00:08:56.850
successful that is when you
compare the kind of infections

171
00:08:56.850 --> 00:08:59.310
that you've seen on iOS
devices, with what you see

172
00:08:59.310 --> 00:09:03.420
on Macs even, or windows
devices, there's all been almost

173
00:09:03.420 --> 00:09:06.270
no activity there. And the
activity that's been there has

174
00:09:06.270 --> 00:09:09.270
been very controlled because once
it's identified, it's slapped down

175
00:09:09.270 --> 00:09:12.180
pretty fast through the, the
hands that reached down from

176
00:09:12.180 --> 00:09:15.210
the cloud and, and fix
things. So that's an example

177
00:09:15.210 --> 00:09:18.750
of technology. That's really helping
address part of this problem

178
00:09:18.750 --> 00:09:22.290
that social engineering ends up
causing. Now, it's not going

179
00:09:22.290 --> 00:09:24.780
to be perfect. And there's
going to be cases where

180
00:09:24.810 --> 00:09:26.850
the software running on these
devices is vulnerable. You have

181
00:09:26.850 --> 00:09:28.800
the browser Hauser, vulnerability, and
you navigate to the wrong

182
00:09:28.800 --> 00:09:31.320
place and you're going to
get something there. But then

183
00:09:31.750 --> 00:09:34.680
technology can also take over
there with sandboxes that are

184
00:09:34.680 --> 00:09:37.020
running in the LS to
try to contain the infection.

185
00:09:37.920 --> 00:09:39.980
So when I Explain stuff
like this to my wife

186
00:09:40.010 --> 00:09:42.350
or my mom or the
nontechnical people in my, in

187
00:09:42.350 --> 00:09:45.200
my life, from their perspective,
you know, they take an

188
00:09:45.200 --> 00:09:48.320
action and something happens and
it's their fault. So, you

189
00:09:48.320 --> 00:09:50.210
know, whether they click on
word and they run word

190
00:09:50.210 --> 00:09:53.180
or they click on evil
dot exe and something bad

191
00:09:53.180 --> 00:09:56.270
happens, there's this kind of
half guilt. I clicked it.

192
00:09:56.270 --> 00:09:58.150
It was my fault. And
then there's the also, well,

193
00:09:58.150 --> 00:10:00.620
why didn't they protect me?
Yeah. We have things like

194
00:10:00.620 --> 00:10:05.090
SmartScreen and different, you know,
antivirus definition type stuff. I

195
00:10:05.090 --> 00:10:06.950
kind of get that of
the user space. But then

196
00:10:06.950 --> 00:10:09.650
in the, in the book,
what is attack what's used

197
00:10:09.650 --> 00:10:11.750
to attack us is what's
called a routine. Yeah. What

198
00:10:11.750 --> 00:10:16.230
is that? Well, the root
kit is actually part, it,

199
00:10:16.230 --> 00:10:17.900
it comes with the malware.
So the malware has to

200
00:10:17.900 --> 00:10:19.730
get on your system. And
then once the malware is

201
00:10:19.730 --> 00:10:22.100
on the system, they can
use root kit, technology, techniques,

202
00:10:22.100 --> 00:10:25.700
and technologies to remain on
your system. And really what

203
00:10:25.700 --> 00:10:27.260
does it take to remain
on your system? Part of

204
00:10:27.260 --> 00:10:29.600
it is hidden. So you
look for me and I'm

205
00:10:29.600 --> 00:10:32.630
not, you're not going to
see the malware. And the

206
00:10:32.630 --> 00:10:34.880
other part is, of course,
even if you do see

207
00:10:34.880 --> 00:10:38.000
part of me, it's possible
for you to remove me

208
00:10:38.180 --> 00:10:41.570
once I'm there. Yeah. So
the root kit is really

209
00:10:42.330 --> 00:10:45.590
a cloak, basically that the
malware puts on. Once it's

210
00:10:45.590 --> 00:10:48.440
gotten into a system, Stuxnet
had example of this one.

211
00:10:48.440 --> 00:10:52.940
And then, so the conceal,
the fact that it was

212
00:10:52.940 --> 00:10:55.730
being transmitted by USB keys,
you'd stick in the USB

213
00:10:55.730 --> 00:10:58.460
key. They would explain the
vulnerability in the operating system

214
00:10:58.460 --> 00:11:01.460
to jump into the LS.
And this is independent of

215
00:11:01.460 --> 00:11:04.670
autoplay. So it was exploiting
a vulnerability and Explorer. So

216
00:11:04.700 --> 00:11:08.570
no action by the user
autoplay restrictions, didn't prevent this

217
00:11:08.570 --> 00:11:11.370
thing from jumping onto computers.
And then once it was

218
00:11:11.370 --> 00:11:14.840
in Explorer, it would install
a root kit filter in

219
00:11:14.840 --> 00:11:16.550
Explorer so that you would
look at the USB key

220
00:11:16.550 --> 00:11:19.160
and you wouldn't see the
Stuxnet files there. So the

221
00:11:19.160 --> 00:11:21.680
instant you stuck, the key
in the files would effectively

222
00:11:21.680 --> 00:11:24.410
disappear. So you wouldn't even
know that you'd gotten this

223
00:11:24.410 --> 00:11:27.410
payload along with the USB
key once your machine was

224
00:11:27.410 --> 00:11:30.050
infected. So that's an example
of a root kit there

225
00:11:30.050 --> 00:11:32.500
that Stuxnet was using. So
he's rude Hit the, that,

226
00:11:32.500 --> 00:11:35.240
that term, is that a
family of techniques? Yeah. It's

227
00:11:35.240 --> 00:11:38.000
a whole family of techniques.
Basically. I, I kind of

228
00:11:38.420 --> 00:11:42.740
summarize it as techniques that
the malware adopts to hide

229
00:11:42.740 --> 00:11:49.190
its presence from standard administrative
diagnostic and security software Now

230
00:11:49.220 --> 00:11:51.200
as a technical person. And
I know I've heard these

231
00:11:51.200 --> 00:11:54.790
kinds of CSI essays, your
blog. I think we've all

232
00:11:54.790 --> 00:11:58.090
had that experience where we've
opened up task manager and

233
00:11:58.090 --> 00:12:00.730
we've said, what is that?
You know, you know, you

234
00:12:00.730 --> 00:12:03.310
just have that open. I
know that in early versions

235
00:12:03.310 --> 00:12:05.380
of windows, I had task
manager open pretty much all

236
00:12:05.380 --> 00:12:07.960
the time, just sitting on
another window, cause I want

237
00:12:07.960 --> 00:12:10.060
to know what's going on.
I wanted that insight. And

238
00:12:10.060 --> 00:12:12.280
as soon as I spot
something on it, a family

239
00:12:12.280 --> 00:12:14.560
member of his machine I'll
immediately figure out what's going

240
00:12:14.560 --> 00:12:16.870
on. And when you do
these kinds of CSI things,

241
00:12:16.870 --> 00:12:18.850
we dig in and you
say, Oh, look, it's an

242
00:12:19.000 --> 00:12:21.010
active X control. And now
it's loading itself in the

243
00:12:21.010 --> 00:12:23.740
registry. And then you delete,
delete, delete you run, you

244
00:12:23.740 --> 00:12:27.430
know, crap cleaner and everything
is okay. I use saying

245
00:12:27.430 --> 00:12:29.260
in a root clip, I
can right click on task

246
00:12:29.260 --> 00:12:32.530
manager and it's there, but
it's not showing up when

247
00:12:32.530 --> 00:12:36.990
some operating system level call
says enumerate processes, Right? That's

248
00:12:36.990 --> 00:12:39.180
exactly what's going on. So
that's an example of not

249
00:12:39.180 --> 00:12:42.030
hiding files, but hiding processes.
And this one's really common

250
00:12:42.030 --> 00:12:45.420
as well for root kits.
So the what bill and

251
00:12:45.420 --> 00:12:47.460
there's lots of different ways
they can do this from

252
00:12:47.550 --> 00:12:51.690
manipulating the kernel data structures,
the list of processes. So

253
00:12:51.960 --> 00:12:54.450
a user mode application like
task manager calls into the

254
00:12:54.450 --> 00:12:56.880
Colonel says, get me the
list of processes. Well, the

255
00:12:56.880 --> 00:13:01.020
process list data structures have
been manipulated so that the

256
00:13:01.020 --> 00:13:03.600
malicious process is not even
on that list. So it's

257
00:13:03.600 --> 00:13:07.110
returned from the kernel without
the malicious process, or it

258
00:13:07.110 --> 00:13:08.700
can be done, but on
a, up in user mode.

259
00:13:08.700 --> 00:13:11.790
So the Colonel routine returns
the full list, including the

260
00:13:11.790 --> 00:13:15.090
malicious software, but the infected
processes, something running inside of

261
00:13:15.090 --> 00:13:18.210
task manager then takes the
malicious process out of it.

262
00:13:18.210 --> 00:13:20.760
List the tasks that it
then is handed back to

263
00:13:20.760 --> 00:13:24.270
task manager for it to
display. And then there's lots

264
00:13:24.270 --> 00:13:26.610
and lots of variants on
that same kind of technique

265
00:13:26.610 --> 00:13:29.940
of hiding something from a
tool like task manager Is

266
00:13:29.940 --> 00:13:33.090
it I've taken, you know,
operating system classes in college.

267
00:13:33.090 --> 00:13:35.940
And I did mimics and
all the little tiny S

268
00:13:35.940 --> 00:13:38.880
classes and things like that.
Or is this unique to

269
00:13:38.880 --> 00:13:41.790
windows or is this operating
system theory kind of stuff?

270
00:13:41.880 --> 00:13:44.200
This is operating system theory.
So yeah, it's not, not

271
00:13:44.220 --> 00:13:46.740
like windows is especially vulnerable
to this kind of stuff.

272
00:13:46.770 --> 00:13:48.780
Max, you can do this
and Lennox, you can do

273
00:13:48.780 --> 00:13:51.000
this in minutes. You could
do this same kind of

274
00:13:51.000 --> 00:13:53.820
thing, But how do you,
so how do you, you

275
00:13:53.820 --> 00:13:55.710
know, you guys are all
here, we're here in building

276
00:13:55.950 --> 00:13:57.600
one Oh nine and you
guys are kind of designing

277
00:13:57.600 --> 00:14:00.360
the next version of windows.
Do you have to double

278
00:14:00.360 --> 00:14:03.540
check everything in the sense
of at the, at every

279
00:14:03.540 --> 00:14:07.530
moment the system is running
and it has to, I

280
00:14:07.530 --> 00:14:11.880
don't know, Test its assumptions.
Yeah. There's windows itself have

281
00:14:11.880 --> 00:14:14.850
to say, this is what
I know get processes looked

282
00:14:14.850 --> 00:14:17.610
like when we shipped and
every minute on checking to

283
00:14:17.610 --> 00:14:21.240
make sure it hasn't changed.
No, we're not really doing

284
00:14:21.240 --> 00:14:25.170
that kind of thing. So,
so I'm working in the

285
00:14:25.170 --> 00:14:27.750
windows Azure team, which is
developing a cloud operating system.

286
00:14:27.750 --> 00:14:30.330
You could say we're developing,
delivering software into the data

287
00:14:30.330 --> 00:14:32.640
center. And the question is,
is what did we deliver

288
00:14:32.640 --> 00:14:35.940
it here? Actually, what's running
in the data center and

289
00:14:36.000 --> 00:14:40.710
this is a place where
we've got standard images. So

290
00:14:40.710 --> 00:14:44.820
we don't. So we actually
deploy images flat onto machines,

291
00:14:44.850 --> 00:14:48.330
right? When we update them,
instead of taking a approach

292
00:14:48.330 --> 00:14:51.000
where we go and just
send updated bits to the,

293
00:14:51.500 --> 00:14:53.810
and what this does is
make sure that when we

294
00:14:53.810 --> 00:14:56.330
say that, when we believe
that something's running on a

295
00:14:56.330 --> 00:14:59.630
machine, that it is actually
that set of code that's

296
00:14:59.630 --> 00:15:01.970
running on the machine, at
least when it's deployed. And

297
00:15:02.210 --> 00:15:04.100
we can understand the state
of the machine as it

298
00:15:04.100 --> 00:15:07.730
goes along, we haven't implemented
white listing in the operating

299
00:15:07.730 --> 00:15:09.890
system and Azure for guests
or the hosts, but we're

300
00:15:09.890 --> 00:15:14.390
working on implementing that as
well as an extra lockdown

301
00:15:14.390 --> 00:15:18.080
of the systems that we've
got in place. So they,

302
00:15:18.380 --> 00:15:21.680
the question that anybody has
of, of is what's running

303
00:15:21.680 --> 00:15:23.360
on the machine, really what
I think is supposed to

304
00:15:23.360 --> 00:15:26.060
be running a machine or
something, not something there that

305
00:15:26.060 --> 00:15:29.300
shouldn't be. There is one
that everybody has to deal

306
00:15:29.300 --> 00:15:32.050
with. And, and one that
there's no silver bullet for.

307
00:15:32.360 --> 00:15:34.790
So I'll say even in
the face of having perfect

308
00:15:34.790 --> 00:15:38.300
antivirus, having perfect white listing,
you know, take the iOS

309
00:15:38.300 --> 00:15:40.940
device example that I gave
you earlier. If you go

310
00:15:40.940 --> 00:15:44.240
to the app store and
there's a vulnerability, or if

311
00:15:44.240 --> 00:15:46.610
you go to the web
using the browser and iOS,

312
00:15:46.610 --> 00:15:49.190
and there's a vulnerability that
browser malware gets done on

313
00:15:49.190 --> 00:15:53.840
the iOS device and it
runs in memory. So it's

314
00:15:53.840 --> 00:15:56.660
not violating the white list,
but it's something that's active

315
00:15:56.660 --> 00:15:59.660
on the device at that
point, then you're infected. And

316
00:15:59.660 --> 00:16:01.790
really the only way to
clean it off is then

317
00:16:01.790 --> 00:16:04.610
to reboot the device or
to get antivirus down there,

318
00:16:04.610 --> 00:16:06.320
to go and clean it
off, you know, delete the

319
00:16:06.320 --> 00:16:09.800
thing. So it's not like
there's a magical solution. That

320
00:16:09.800 --> 00:16:12.260
means no malware is ever
going to be on anything,

321
00:16:12.260 --> 00:16:15.980
no matter what, it's a
matter of, of trying to

322
00:16:15.980 --> 00:16:17.900
make it harder and harder
and harder for malware to

323
00:16:17.900 --> 00:16:19.940
do that, to get on
a machine. And then once

324
00:16:19.940 --> 00:16:21.650
it's on the machine, I
think this is a key

325
00:16:21.650 --> 00:16:26.690
part of cybersecurity is will
we'll see evolving is a

326
00:16:26.720 --> 00:16:31.070
mining data to look for
malicious activity. Something that really

327
00:16:31.610 --> 00:16:33.710
there's been some work, but
I think there's a long

328
00:16:33.710 --> 00:16:36.050
way to go here. And
this is you're going to

329
00:16:36.050 --> 00:16:38.540
see this become more popular
as big data techniques come

330
00:16:38.540 --> 00:16:40.850
into play, where you can
analyze systems and look for

331
00:16:40.850 --> 00:16:45.260
anomalous patterns of network traffic,
and find, you know, use

332
00:16:45.260 --> 00:16:49.460
statistical algorithms to go and
help you pull that stuff

333
00:16:49.490 --> 00:16:51.530
out and say, wait, there's
funny traffic going on from

334
00:16:51.530 --> 00:16:53.840
this machine to this machine
over here that then ends

335
00:16:53.840 --> 00:16:56.090
up going to this machine
that then ends up going

336
00:16:56.090 --> 00:16:59.480
off into some server in
Hong Kong. So I believe that

337
00:16:59.480 --> 00:17:02.270
this machine here at the
core of it is infected

338
00:17:02.270 --> 00:17:04.490
and this you've got a
pipeline out of your network.

339
00:17:05.000 --> 00:17:06.350
You're going to see, start
to see stuff like that

340
00:17:06.350 --> 00:17:09.490
by analyzing network traffic and
log files. And Yeah, well,

341
00:17:09.490 --> 00:17:11.260
I w I used to
work in online banking and

342
00:17:11.260 --> 00:17:15.040
when we were shoving soap
around, they started putting stateful

343
00:17:15.040 --> 00:17:19.240
firewalls in between machines to
look for things leaving. You

344
00:17:19.240 --> 00:17:22.030
don't, you don't want any
other traffic than what is

345
00:17:22.030 --> 00:17:26.260
expected, complete, complete white listed,
you know, traffic. Yeah. So

346
00:17:26.560 --> 00:17:29.860
just another tool in the
bag of tools, but You

347
00:17:29.860 --> 00:17:32.170
brought up something interesting because
you work here in Azure,

348
00:17:32.200 --> 00:17:35.470
kind of a, not necessarily
downstream from windows server, but

349
00:17:35.470 --> 00:17:37.180
you're kind of a client
of windows server, and you've

350
00:17:37.180 --> 00:17:41.170
got this cloud-based operating system,
which isn't an operating system

351
00:17:41.440 --> 00:17:44.740
of operating systems. Yeah. And
you said that when you

352
00:17:44.740 --> 00:17:45.910
want to make sure that
the machine is in a

353
00:17:45.910 --> 00:17:48.550
good state, you could do
all sorts of heuristics. Like

354
00:17:48.550 --> 00:17:51.330
I kind made up right
there, but that really isn't

355
00:17:51.330 --> 00:17:54.270
efficient, better to just torch
that machine and lay down

356
00:17:54.270 --> 00:17:56.820
good bits again. Yeah. And
that was interesting to me

357
00:17:56.820 --> 00:17:59.610
because in the book, a
great deal of time was

358
00:17:59.610 --> 00:18:04.350
spent when one company was
attacked, looking for a backup.

359
00:18:05.190 --> 00:18:06.780
I spent a great deal
of time going farther and

360
00:18:06.780 --> 00:18:08.400
farther back in time to
make sure that they had

361
00:18:08.400 --> 00:18:10.890
a good image because they
were concerned that they'd actually

362
00:18:10.890 --> 00:18:13.890
backed up the, the virus.
Yeah. But I thought that

363
00:18:13.890 --> 00:18:17.160
was interesting because they, they
were looking to, you know,

364
00:18:17.220 --> 00:18:20.220
kind of TiVo their computer.
They just like, I, it

365
00:18:20.220 --> 00:18:23.340
was good Tuesday. Can't we
just go back to that

366
00:18:23.390 --> 00:18:27.390
last known good state. Yeah.
And it would be nice

367
00:18:27.390 --> 00:18:29.180
to be able to do
that. And I think we've

368
00:18:29.190 --> 00:18:31.130
got, actually, we've got that
now Does it's got that?

369
00:18:31.130 --> 00:18:34.490
Yeah. Reset it to the
factory settings, you know, and

370
00:18:34.490 --> 00:18:37.370
actually most mobile devices have
that as well. Right. Reset

371
00:18:37.370 --> 00:18:38.840
it to the fact that
I've done that several times.

372
00:18:38.950 --> 00:18:40.880
My iPhone just torched it
and went back to where

373
00:18:40.880 --> 00:18:44.330
it was. Yeah. Interesting. One
of the things that also

374
00:18:44.330 --> 00:18:47.540
struck me in the book
was that there was a

375
00:18:47.540 --> 00:18:53.030
lot of like thought and
talking, you didn't kind of

376
00:18:53.060 --> 00:18:55.100
cover up anything with action.
I think it was a

377
00:18:55.100 --> 00:18:57.830
lot of pros and I
kept wondering like something in

378
00:18:57.830 --> 00:19:00.080
a breakout into an action
thing. It's like, no, this

379
00:19:00.080 --> 00:19:02.240
is two people sitting down
and actually analyzing it. So

380
00:19:02.240 --> 00:19:04.520
it was almost like we
were there over the shoulder

381
00:19:04.520 --> 00:19:07.210
of the protagonists as they
were having this conversation. So

382
00:19:07.610 --> 00:19:10.100
I compliment you in the
sense that you didn't dumb

383
00:19:10.100 --> 00:19:14.540
it down. Yeah. I mean,
I felt like if you

384
00:19:14.540 --> 00:19:17.480
can make a cyber cyber
thriller, that's really thriller with

385
00:19:17.480 --> 00:19:19.820
no cyber. And I think
there's lots of people that

386
00:19:19.820 --> 00:19:22.850
do that. Yeah. The people
that are most more focused

387
00:19:22.850 --> 00:19:26.210
on just thriller genre, that
we'll toss cyber terms in

388
00:19:26.210 --> 00:19:30.890
there, but it's really just
a week just sprinkling cyber

389
00:19:31.340 --> 00:19:33.140
across their book. But I
really wanted to make it

390
00:19:33.260 --> 00:19:38.210
really about cybersecurity And the,
the, the backgrounds of the,

391
00:19:38.480 --> 00:19:41.210
of the people that, how
they got into security and

392
00:19:41.810 --> 00:19:44.810
the kinds of analysis that
they use. And some, the

393
00:19:44.840 --> 00:19:47.570
protagonist came in, you know,
kind of through a more

394
00:19:47.660 --> 00:19:52.010
government way to learn what
he learned while the, the

395
00:19:52.010 --> 00:19:54.530
female protagonists came in at
a different direction. We always

396
00:19:54.530 --> 00:19:56.870
based on people that you
knew or came upon, are

397
00:19:56.870 --> 00:19:59.720
these realistic portrayals of how
people get into security. I

398
00:19:59.720 --> 00:20:03.170
think they're realistic portrayals. The
only character that I think

399
00:20:03.170 --> 00:20:06.080
is more, more based on
a real person is the

400
00:20:06.110 --> 00:20:09.020
main protagonist Jeff Aiken. He
was kind of based on

401
00:20:09.020 --> 00:20:13.190
me. So actually, yeah. Right.
Exactly. And I think I,

402
00:20:13.880 --> 00:20:16.160
I saw that this is
a common pattern with first

403
00:20:16.160 --> 00:20:19.400
time authors is they're kind
of autobiographical their first novels,

404
00:20:19.580 --> 00:20:23.090
there's their themselves projected in
the book and somehow some

405
00:20:23.090 --> 00:20:25.340
manner and Jeff Akins kind
of a projection of me

406
00:20:25.760 --> 00:20:28.520
into the book When you
were, when you were writing

407
00:20:28.520 --> 00:20:31.280
it, you had made the
comment a minute ago that

408
00:20:32.090 --> 00:20:34.850
you didn't want to jump
over anything. There was a,

409
00:20:34.850 --> 00:20:36.740
there was a linear structure
to it in a, in

410
00:20:36.740 --> 00:20:40.250
a, in a focus that
felt like a programmer. Did

411
00:20:40.250 --> 00:20:41.720
you have anyone who worked
with you on it to

412
00:20:41.720 --> 00:20:43.700
make sure that the narrative
flow is the same? Or

413
00:20:43.700 --> 00:20:45.800
did you, did you write
this light code? I'm interested

414
00:20:45.800 --> 00:20:48.970
in the process? Did I
write it like code? I,

415
00:20:48.990 --> 00:20:52.050
you know, you said nothing,
you, I did, why I

416
00:20:52.050 --> 00:20:55.110
did whiteboard. I did plan
the plot ahead of time

417
00:20:56.190 --> 00:20:58.470
with less detail towards the
end than the beginning, but

418
00:20:58.470 --> 00:21:00.480
I did have a structure
like, okay, then this is

419
00:21:00.480 --> 00:21:02.490
going to happen roughly, and
then this next step is

420
00:21:02.490 --> 00:21:04.470
going to happen. This next
step is going to happen.

421
00:21:04.470 --> 00:21:05.970
And how do I make
these things all line up?

422
00:21:06.000 --> 00:21:09.930
So kind of like building
a, you know, a framework

423
00:21:09.930 --> 00:21:12.280
there where I wanted all
these different pieces and lines

424
00:21:12.280 --> 00:21:15.090
to, to come together in
a way that would be

425
00:21:15.090 --> 00:21:19.170
interesting. The challenging thing about
it is Trojan horse. The

426
00:21:19.170 --> 00:21:23.130
SQL got more complex. So
it became a harder problem

427
00:21:23.130 --> 00:21:25.530
for me to solve, to
have all the plot lines

428
00:21:25.530 --> 00:21:28.020
come together in an interesting
way where I didn't have

429
00:21:28.020 --> 00:21:32.040
to hand wave through things
and where I didn't re

430
00:21:32.220 --> 00:21:34.950
cover turf that had already
covered in zero day. So

431
00:21:34.950 --> 00:21:36.810
I'm actually working on a
plot for the third book

432
00:21:36.810 --> 00:21:39.420
and the Jeff Hakan series.
And that one's even more

433
00:21:39.420 --> 00:21:42.330
challenging because it's like, Oh,
I can't use that device

434
00:21:42.330 --> 00:21:44.040
because I use that in
Trojan horse. I can't use

435
00:21:44.040 --> 00:21:46.500
that because I used it
in zero day. I don't

436
00:21:46.500 --> 00:21:48.480
want people to go reading
through the book and go,

437
00:21:48.510 --> 00:21:51.480
Oh yeah, I remember that
from book two, but really

438
00:21:51.510 --> 00:21:54.360
it to be fresh. So
it's, it's kind of fun

439
00:21:54.360 --> 00:21:57.030
because they're brain teasers that
are getting harder as I

440
00:21:57.040 --> 00:21:59.790
go along. Do you think
that would be challenging though,

441
00:21:59.790 --> 00:22:03.150
because I think from a
layman's perspective, computers are kind

442
00:22:03.150 --> 00:22:06.720
of boring and stodgy, but
from our perspective, you know,

443
00:22:06.720 --> 00:22:09.390
there is an infinite number
of cool and interesting things

444
00:22:09.390 --> 00:22:11.940
that could go on. But
then when you Uplevel that

445
00:22:11.940 --> 00:22:14.130
to a plot point, someone
could just say, okay, a

446
00:22:14.130 --> 00:22:18.180
program fights the computer and
that's not interesting anymore. Well,

447
00:22:18.180 --> 00:22:20.940
they, like I said, I
want it, part of the

448
00:22:20.940 --> 00:22:23.040
reason for the books are
as educational as well as

449
00:22:23.040 --> 00:22:25.800
entertainment. So the first book
educating about a real threat

450
00:22:25.800 --> 00:22:28.530
that I believe in, and
the second part is educating

451
00:22:28.530 --> 00:22:33.300
people about cybersecurity. The second
book, Trojan horse is educating

452
00:22:33.300 --> 00:22:38.400
people about the cyber state-sponsored
cyber espionage, which is something

453
00:22:38.400 --> 00:22:41.580
that's going on all over
the place. Like what, how

454
00:22:41.580 --> 00:22:44.280
do governments carry this out?
What do they, how do

455
00:22:44.280 --> 00:22:49.860
they use cyber espionage to
further their national interests and

456
00:22:49.890 --> 00:22:52.680
how do they work against
each other? I wanted to

457
00:22:52.740 --> 00:22:56.790
educate that by making a
story that is based loosely

458
00:22:56.790 --> 00:22:59.730
on things that we actually
see going on these days

459
00:23:00.270 --> 00:23:03.600
and the same time making
entertaining and the inner. So

460
00:23:03.660 --> 00:23:05.550
the books, if you look
at the structure that I've

461
00:23:05.550 --> 00:23:09.870
kind of set upon, it's
the first part first a

462
00:23:09.900 --> 00:23:13.800
quarter to a third is
kind of how the story

463
00:23:13.800 --> 00:23:17.580
starts to build as the
computer cyber stuff happens. Like

464
00:23:17.610 --> 00:23:20.850
what's the infection and who's
being hacked and how they're

465
00:23:20.850 --> 00:23:22.830
being hacked. And this is
where you see Jeff analyzing

466
00:23:22.830 --> 00:23:25.350
stuff. And then it starts
to roll faster and faster

467
00:23:25.350 --> 00:23:29.070
into more action. As you
know, there just life's in

468
00:23:29.070 --> 00:23:32.130
danger or just trying to
stop something really horrible from

469
00:23:32.130 --> 00:23:34.620
happening. And then it ends
up boiling down into the

470
00:23:34.620 --> 00:23:37.680
end. It's like pure thriller.
Right. I thought, I thought

471
00:23:37.680 --> 00:23:40.620
it was interesting also that
there was a personal aspect

472
00:23:40.620 --> 00:23:44.940
to it in that you
didn't make the, cybercriminal this

473
00:23:44.960 --> 00:23:49.010
kind of nameless, faceless, you
know, evil person. And I

474
00:23:49.010 --> 00:23:50.540
know sometimes, you know, when
I get a virus, I'm

475
00:23:50.540 --> 00:23:53.330
just like, Oh man, those
guys, but it's, it's very

476
00:23:53.330 --> 00:23:57.890
abstract, but there was an
actual human in a room

477
00:23:58.040 --> 00:24:00.530
with a wife and a
life and an apartment. And,

478
00:24:00.560 --> 00:24:02.750
you know, he, he moved
from one apartment to another

479
00:24:02.750 --> 00:24:06.140
and that's like very kind
of denial details, but it

480
00:24:06.140 --> 00:24:09.470
reminds you that when you
get attacked or you get

481
00:24:09.470 --> 00:24:12.770
that mean toolbar, that you're
wondering is that malware or

482
00:24:12.770 --> 00:24:15.890
not, there was a human
being that pays rent and

483
00:24:15.890 --> 00:24:20.980
goes to the store who
did that? Yeah, It was

484
00:24:20.980 --> 00:24:23.650
a conscious choice to actually,
and this is another example

485
00:24:23.650 --> 00:24:26.230
of not wanting to hand
wave or go from point

486
00:24:26.230 --> 00:24:29.380
a to point B without
a sound explanation for how

487
00:24:29.440 --> 00:24:32.200
the plot move forward. I
didn't want to have faceless

488
00:24:32.380 --> 00:24:35.200
criminals behind the whole thing
that just get unveiled at

489
00:24:35.200 --> 00:24:38.950
the very end, as diabolical
people that have magical powers

490
00:24:38.950 --> 00:24:42.670
to wreck cyber terror, but
actually show really what's going

491
00:24:42.670 --> 00:24:44.200
on. And it's part of
the education and part of,

492
00:24:44.200 --> 00:24:47.950
I think, trying to make
a thriller that people see

493
00:24:49.270 --> 00:24:52.090
anchored in reality, kind of.
So it was a very

494
00:24:52.090 --> 00:24:54.160
conscious choice and actually to
put a human face on

495
00:24:54.160 --> 00:24:58.270
some of the characters, the,
the person you're talking you're

496
00:24:58.270 --> 00:25:00.700
talking about in the book,
he really isn't evil. He

497
00:25:00.700 --> 00:25:03.460
doesn't even really know that
he's part of this plot.

498
00:25:03.610 --> 00:25:07.420
And so that kind of
comes out too, that not

499
00:25:07.420 --> 00:25:10.810
everybody involved in something like
this necessarily realize the implications

500
00:25:10.810 --> 00:25:12.910
of what they're doing, Right.
And just as they are

501
00:25:12.910 --> 00:25:16.960
themselves building a distributed system
for attack, they are part

502
00:25:16.960 --> 00:25:20.410
of a larger human distributed
system where he was, he

503
00:25:20.410 --> 00:25:22.810
was taking pieces of things
and assembling something. But he

504
00:25:22.810 --> 00:25:25.270
was also the piece of
a larger thing that was

505
00:25:25.270 --> 00:25:28.660
being assembled by, by someone
else, which, which makes one

506
00:25:28.660 --> 00:25:31.750
wonder in the context of,
of terrorism or kind of

507
00:25:31.780 --> 00:25:35.140
nefarious plans, is it simply
the will to do it?

508
00:25:35.170 --> 00:25:38.200
That is preventing us from
being attacked again, whether it

509
00:25:38.200 --> 00:25:41.740
be attacked in something is
as base as an airplane

510
00:25:41.740 --> 00:25:45.400
into a tower or something
as subtle comparatively subtle as

511
00:25:45.400 --> 00:25:47.620
a, as a cyber attack.
It's just simply, no one

512
00:25:47.620 --> 00:25:48.970
has just sat down and
said, we're going to do

513
00:25:48.970 --> 00:25:52.240
this thing. Yeah. I think
it's lack of vision really

514
00:25:52.240 --> 00:25:54.130
is. What's the only reason
that we haven't had it

515
00:25:54.130 --> 00:25:56.920
happen so far, because if
you kind of stick a

516
00:25:56.920 --> 00:25:59.080
step back and say, how
much would it cost to

517
00:25:59.170 --> 00:26:02.290
do something like this? Even
something that is mild, mildly

518
00:26:03.130 --> 00:26:06.220
has a mild chance of
causing destruction. It's actually pretty

519
00:26:06.220 --> 00:26:08.590
low bar in terms of
budget. If you look at

520
00:26:08.590 --> 00:26:10.480
the budget that Al Qaeda
had prior to nine 11,

521
00:26:11.050 --> 00:26:13.660
they were making several million
dollars a year. And the

522
00:26:13.720 --> 00:26:16.150
arcade attack itself cost a
few hundred thousand dollars. They

523
00:26:16.150 --> 00:26:20.140
estimate. So the kinds of
numbers that you're talking about

524
00:26:20.140 --> 00:26:25.540
for hiring some competent hackers
in Russia or China, to

525
00:26:25.630 --> 00:26:27.400
help you out where they
don't even have to know

526
00:26:27.400 --> 00:26:30.160
what they're doing is it's
a pretty low bar in

527
00:26:30.160 --> 00:26:33.370
terms of number of organizations
that are, would be capable

528
00:26:33.370 --> 00:26:36.340
of outsourcing that kind of
work to cause one of

529
00:26:36.340 --> 00:26:39.280
the big pushbacks I got
from people, as I told

530
00:26:39.280 --> 00:26:42.040
them, started talking about the
plot is, Oh, no terrorists.

531
00:26:42.040 --> 00:26:43.950
They're not sophisticated enough to
this. I'm like, you don't

532
00:26:43.950 --> 00:26:46.110
get it. They don't have
to be, they just have

533
00:26:46.110 --> 00:26:48.780
to know that they, that
this is a weapon that

534
00:26:48.780 --> 00:26:51.330
can use. And then they
pay people that are sophisticated

535
00:26:51.330 --> 00:26:53.490
enough and there's lots of
people and they can pay.

536
00:26:54.410 --> 00:26:57.290
When you write a book
about something like this, are

537
00:26:57.290 --> 00:27:00.260
you concerned ever that you're
giving people an idea? Like

538
00:27:00.260 --> 00:27:02.060
whenever people have just read,
we just have this attack

539
00:27:02.090 --> 00:27:04.940
in, in Aurora, Colorado, and
people are trying to analyze

540
00:27:04.940 --> 00:27:07.700
it. And the first complaint
that comes up is like,

541
00:27:07.730 --> 00:27:09.350
Oh, there you go. Now
you're given the bad guy's

542
00:27:09.350 --> 00:27:11.750
ideas. Yeah. I don't, well,
I don't believe in that

543
00:27:11.750 --> 00:27:13.490
giving the bad guy's ideas.
I mean the bad guys

544
00:27:13.490 --> 00:27:15.320
are going to come up
with their ideas on their

545
00:27:15.320 --> 00:27:22.460
own. The, I mean, yeah,
just, I think that that's

546
00:27:22.520 --> 00:27:25.520
a foolish to think that
if you don't talk about

547
00:27:25.520 --> 00:27:27.740
it, nobody's going to figure
it out. Cause people will

548
00:27:27.740 --> 00:27:29.900
figure it out. And in
fact, it's better to talk

549
00:27:29.900 --> 00:27:31.490
about it before they figure
it out. So you can

550
00:27:31.490 --> 00:27:34.640
figure, you can determine what
we're, what's our reaction. Are

551
00:27:34.640 --> 00:27:37.070
we going to do something
proactively to try to prevent

552
00:27:37.070 --> 00:27:38.060
it? Or are we just
going to wait for it

553
00:27:38.060 --> 00:27:40.400
to happen and then react
like, Oh my God, I

554
00:27:40.400 --> 00:27:43.910
can't believe they figured it
out. The really ironic thing.

555
00:27:43.920 --> 00:27:47.180
Speaking of giving people ideas
kind of ironic and really

556
00:27:48.020 --> 00:27:51.620
kind of gives me some
pride is that one of

557
00:27:51.620 --> 00:27:53.690
the blurbs I got for
the book, when you write

558
00:27:53.690 --> 00:27:55.670
a book you're supposed to
go out and get blurbs

559
00:27:55.670 --> 00:27:59.270
from other authors that people
recognize that will say something

560
00:27:59.270 --> 00:28:01.910
nice about your book. And
one of the blurbs I

561
00:28:01.910 --> 00:28:05.210
got for zero day was
from Nelson DeMille who wrote

562
00:28:05.210 --> 00:28:10.040
the book that had the
airplane flying into buildings that

563
00:28:10.340 --> 00:28:13.280
people pointed at when nine
11 happened saying, he's the

564
00:28:13.280 --> 00:28:15.620
one that gave him the
idea. Then he gave me

565
00:28:15.620 --> 00:28:17.660
a blurb for my book,
which is kind of nine

566
00:28:17.660 --> 00:28:22.580
11 cyber version, which I
think I don't want it

567
00:28:22.580 --> 00:28:24.200
to play out the same
way, but it's kind of

568
00:28:24.200 --> 00:28:28.250
interesting that I, that I,
that kind of coincidence. How,

569
00:28:28.250 --> 00:28:31.820
how worried should, should one
be like, you know, you're

570
00:28:31.820 --> 00:28:35.960
as, as, as educated and
as inside as one could

571
00:28:35.960 --> 00:28:39.260
possibly be on this, if
you're worried that I'll be

572
00:28:39.260 --> 00:28:42.470
worried. Yeah. Well, how so?
How were it? Should you

573
00:28:42.470 --> 00:28:44.150
be worried? Should I be,
I think you should be

574
00:28:44.150 --> 00:28:49.490
pretty worried. I think that
the, you know, the legislation,

575
00:28:49.490 --> 00:28:51.290
that's trying to go through
Congress, for example, to try

576
00:28:51.290 --> 00:28:55.280
to put incentives and regulation
on private sector, running our

577
00:28:55.280 --> 00:28:58.190
critical infrastructure. I strongly believe,
and I strongly believe we

578
00:28:58.190 --> 00:29:04.040
need it. I believe that
that if we let private

579
00:29:04.040 --> 00:29:07.610
industry do what it wants
to do, it's not incentive

580
00:29:07.610 --> 00:29:10.670
really to invest money and
expertise into this, which I

581
00:29:10.670 --> 00:29:14.210
believe we need. And there's
plenty of examples we've seen

582
00:29:14.210 --> 00:29:16.490
up until now about the
poor state of cybersecurity. I

583
00:29:16.490 --> 00:29:18.650
mean, there's every week, there's
something that happens that you

584
00:29:18.660 --> 00:29:20.900
just look at it and
go really, I, you know,

585
00:29:20.930 --> 00:29:26.840
passwords that aren't encrypted and
pass weak passwords and software.

586
00:29:26.840 --> 00:29:28.880
That's not patched in several
years. I mean, all of

587
00:29:28.880 --> 00:29:31.100
this has been on the
headlines over the last few

588
00:29:31.100 --> 00:29:35.780
years. And two examples of
some guy that was taped,

589
00:29:35.780 --> 00:29:41.290
took pictures of the display
on a control system for

590
00:29:41.320 --> 00:29:44.110
water outside of a town
outside of Houston, it's small

591
00:29:44.110 --> 00:29:47.470
town. He just hacked in,
you know, within a few

592
00:29:47.470 --> 00:29:51.010
minutes with very little expertise
in scatter systems, but it

593
00:29:51.010 --> 00:29:52.720
was able to get in
right into the control system

594
00:29:52.720 --> 00:29:55.240
of the water supply to
another one of my favorite

595
00:29:55.240 --> 00:29:59.320
examples of penetration, the company
that does penetration testing that

596
00:29:59.320 --> 00:30:01.540
was hired by the city
of Los Angeles to penetrate

597
00:30:01.600 --> 00:30:04.300
the do pen testing on
their water supply within 24

598
00:30:04.300 --> 00:30:06.880
hours, they got into the
water supply computers to the

599
00:30:06.880 --> 00:30:08.920
point where they could have
an altered the chemical mix

600
00:30:09.250 --> 00:30:14.290
to a significant part of
the County. Wow. And so

601
00:30:14.290 --> 00:30:16.090
that, I mean, that's really
the state that we're in.

602
00:30:16.380 --> 00:30:19.330
I don't think we can
underestimate how bad things really

603
00:30:19.330 --> 00:30:22.150
are out there. I mean,
there's certain spots, right? Where

604
00:30:22.150 --> 00:30:25.420
there's good cybersecurity, but for
the most part, I think

605
00:30:25.420 --> 00:30:27.450
we've got a lot of
weakness. There was a thing,

606
00:30:27.450 --> 00:30:29.400
I think it was an
Oregon, a couple of maybe

607
00:30:29.410 --> 00:30:33.090
a year ago where they
hacked into the department of

608
00:30:33.090 --> 00:30:37.440
motor vehicles signs. It said,
you know, you know, <inaudible>

609
00:30:37.500 --> 00:30:41.820
zombies ahead saying that. Yeah.
That's somebody who's been doing

610
00:30:41.820 --> 00:30:44.460
it here in Seattle. Really?
Yeah. That's the last few

611
00:30:44.460 --> 00:30:46.710
weeks. And see, that's not,
that's a combination of physical

612
00:30:46.710 --> 00:30:49.650
security and cyber security. They
just literally bring their laptop

613
00:30:49.680 --> 00:30:51.810
and they busted into them.
They plug it into the

614
00:30:51.810 --> 00:30:54.930
sign. Hopefully that's the least
of the attacks that we'll

615
00:30:54.930 --> 00:30:58.530
see. Yeah. I actually, there
was another one yesterday, somebody

616
00:30:58.740 --> 00:31:01.290
at black hat doing a
talk on how locks it,

617
00:31:01.920 --> 00:31:05.760
this company that makes locks
from major hotel chains, the

618
00:31:05.760 --> 00:31:09.780
electronic locks that there's a
plug where you can connect

619
00:31:09.810 --> 00:31:13.020
to the wire to lock
itself to the lock itself.

620
00:31:13.680 --> 00:31:16.500
And the protocol that this
device, that lock device has,

621
00:31:16.500 --> 00:31:19.710
let's lets you read the
Ram of the device. So

622
00:31:19.710 --> 00:31:22.110
there's a cryptographic key in
there, but you can suck

623
00:31:22.110 --> 00:31:24.870
it out. And then given
the key, you can then

624
00:31:24.870 --> 00:31:28.050
unlock the door. You use
it as a master key

625
00:31:28.290 --> 00:31:32.430
to unlock the door. So
that's another, that's an example

626
00:31:32.430 --> 00:31:35.220
of where they actually had
some good security, but then

627
00:31:35.340 --> 00:31:41.190
one weakness and You can't
one can't even consider why

628
00:31:41.190 --> 00:31:43.230
someone would want to attack
something. I mean, a year

629
00:31:43.230 --> 00:31:46.110
ago I I'm diabetic. I
run into have an insulin

630
00:31:46.110 --> 00:31:50.400
pump. Yeah. A black cat
attacked an insulin pump, overflowed

631
00:31:50.400 --> 00:31:52.920
its buffers over a radio
frequency and caused it to

632
00:31:52.920 --> 00:31:56.610
give a least a lethal
dose of, of insulin. Like,

633
00:31:57.270 --> 00:31:59.490
wow, really? I mean, is
that, is that what we're

634
00:31:59.490 --> 00:32:01.110
going to do? But of
course, the point of that

635
00:32:01.110 --> 00:32:03.540
was to prove that it
could be done and then

636
00:32:03.780 --> 00:32:06.270
spur everyone into action. Is
that what needs to happen?

637
00:32:06.270 --> 00:32:08.610
The giant attack. And then
we get scared and then

638
00:32:08.610 --> 00:32:11.490
we fix that Just human
nature, right? I mean, people

639
00:32:11.490 --> 00:32:13.440
talk about it all day
long and then there's this

640
00:32:13.440 --> 00:32:15.750
very much. I don't believe
you unless you prove it

641
00:32:15.750 --> 00:32:19.140
to me. And Eva, what's
shocking in this case is

642
00:32:19.140 --> 00:32:21.210
the evidence has been all
around us. It's been a,

643
00:32:21.660 --> 00:32:24.270
a low hum of evidence
and people get kind of

644
00:32:24.270 --> 00:32:26.430
immune to hearing about it.
Oh, well there was another

645
00:32:26.430 --> 00:32:29.940
attack, but nothing really big
happened. So no big deal

646
00:32:29.940 --> 00:32:32.190
let's move on. Oh, well
another attack, nothing really big

647
00:32:32.190 --> 00:32:34.230
happened. And it's just gonna
be a matter of time

648
00:32:34.230 --> 00:32:37.020
before something really big happens.
And then people say, Oh

649
00:32:37.020 --> 00:32:39.030
my God, we should have
done something. You know how

650
00:32:39.320 --> 00:32:41.930
we let this happen, but
that's just, I think human

651
00:32:41.930 --> 00:32:44.500
nature. So what are the
URLs that people can check

652
00:32:44.500 --> 00:32:46.570
out to learn about the,
the Jeff Hakan series of

653
00:32:46.570 --> 00:32:51.760
books? Russinovich.com is the site
to go, to got information

654
00:32:51.760 --> 00:32:53.740
about all my books, including
the nonfiction books that I

655
00:32:53.740 --> 00:32:56.320
write as well and links
to where you can buy

656
00:32:56.320 --> 00:32:59.740
them and receive reviews on
them. Cool. And zero day

657
00:32:59.740 --> 00:33:02.350
is in stores now and
on Amazon and Trojan horse

658
00:33:02.350 --> 00:33:04.480
comes out in September. Yep.
So early beginning of September,

659
00:33:04.480 --> 00:33:06.640
I also have a Jeff
Hakan short story. That's the

660
00:33:06.640 --> 00:33:13.590
only 99 cents ebook Kindle and
all the ebook vendors, major

661
00:33:13.600 --> 00:33:16.570
ebook vendors. That's coming out
in August, I think August 8th.

662
00:33:16.720 --> 00:33:18.250
Great, cool. You know what
you should do. Here's an

663
00:33:18.300 --> 00:33:20.770
idea for your third book
is you should make sure

664
00:33:20.770 --> 00:33:24.400
that there's malware in the
ebook that gives other people

665
00:33:24.400 --> 00:33:27.220
copies of the ebook. Yeah.
Spread it like a virus.

666
00:33:27.280 --> 00:33:29.770
It could be a thing.
Thanks so much for talking

667
00:33:29.770 --> 00:33:32.200
to me. Thanks Scott. Thanks
for having me on this

668
00:33:32.200 --> 00:33:34.600
has been another episode of
Hanselminutes and we'll see you

669
00:33:34.600 --> 00:33:35.350
again next week.

