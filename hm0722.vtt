WEBVTT FILE

1
00:00:00.030 --> 00:00:03.540
Today's episode is sponsored by
Datadog a modern full stack

2
00:00:03.560 --> 00:00:08.730
monitoring platform for cloud infrastructure,
applications, and logs metrics, all

3
00:00:08.730 --> 00:00:11.970
in one place from their
recent report on serverless, adoption

4
00:00:11.970 --> 00:00:15.420
and trends. Datadog found half
their customer base using ECC

5
00:00:15.420 --> 00:00:19.710
twos have now adopted AWS
Lambda. They've examined real world

6
00:00:19.710 --> 00:00:22.740
serverless usage by thousands of
companies running on millions of

7
00:00:22.740 --> 00:00:26.310
distinct serverless functions. And they
found that half of the

8
00:00:26.310 --> 00:00:29.760
Lambda invocations run for less
than 800 milliseconds, you can

9
00:00:29.760 --> 00:00:32.940
easily monitor all your serverless
functions in one place and

10
00:00:32.940 --> 00:00:36.900
generate serverless metrics straight from
Datadog. Check it out yourself

11
00:00:36.930 --> 00:00:39.870
by signing up for a
free 14 day trial and

12
00:00:39.870 --> 00:00:46.800
get a free t-shirt visit
datadog.com/hanselman it's show to get

13
00:00:46.800 --> 00:01:05.840
started. That's datadog.com/hansel minutes. Show
to get started. Hi, this

14
00:01:05.840 --> 00:01:08.390
is Scott Hanselman. This is
another episode of Hansel minutes

15
00:01:08.420 --> 00:01:11.780
today. I'm talking with mega
Virginie. She's a data scientist

16
00:01:11.780 --> 00:01:15.110
with <inaudible>. How are you?
Hi Scott. I'm good. How

17
00:01:15.110 --> 00:01:18.470
are you? I am very
well. So you work in

18
00:01:18.470 --> 00:01:20.690
data science at a company
called <inaudible>. What does the

19
00:01:20.690 --> 00:01:24.380
Giza even mean? That's an
interesting name. It means wisdom.

20
00:01:24.650 --> 00:01:27.830
And because we come from
our consulting firm, we are

21
00:01:28.460 --> 00:01:32.180
using all of this to
provide solutions and I think

22
00:01:32.180 --> 00:01:35.360
it's very apt considering the
space we are in. Yeah,

23
00:01:35.360 --> 00:01:37.490
it is. And as a
space, as a data scientist,

24
00:01:38.180 --> 00:01:40.490
but you didn't start out
in, in data science, you

25
00:01:40.490 --> 00:01:44.780
were interested in telecommunications and
engineering. Yes. I started out

26
00:01:44.900 --> 00:01:50.930
in electronics and telecommunications. My
major was electronics, but again,

27
00:01:50.930 --> 00:01:54.050
all of this space, I
started doing a lot of

28
00:01:54.050 --> 00:01:59.330
robotics. I think that's where
I got hooked to data.

29
00:01:59.390 --> 00:02:03.320
And you know how you
are using data to make

30
00:02:03.320 --> 00:02:07.280
sure something works. You know,
it's just one sentence zeroes

31
00:02:07.310 --> 00:02:10.310
when you look at it,
but those ones and zeros

32
00:02:10.400 --> 00:02:15.020
are moving something. So I
think that's how I got

33
00:02:15.020 --> 00:02:18.770
into this field. And then
a lot of analysis, Oh,

34
00:02:18.800 --> 00:02:21.200
my robot has to go
straight, but it is not

35
00:02:21.200 --> 00:02:23.990
going straight. Let me look
at the data. And then

36
00:02:24.500 --> 00:02:27.170
I think that's how I
slowly moved into this field.

37
00:02:27.560 --> 00:02:30.470
Yeah. When I started out
with like basic databases in

38
00:02:30.470 --> 00:02:32.870
the early nineties, I just
thought about it in terms

39
00:02:32.870 --> 00:02:37.490
of tables, but then robots
and IOT and like streaming

40
00:02:37.490 --> 00:02:42.080
data, click stream, like data
over time is so fascinating,

41
00:02:42.080 --> 00:02:45.500
huge, huge amounts of data
that can be presented. And

42
00:02:45.500 --> 00:02:47.720
then if you have a
fleet of robots, like it's

43
00:02:47.720 --> 00:02:50.180
like one robot, all of
its things, it can do

44
00:02:50.180 --> 00:02:53.810
all of its axes. Then
you times that by an

45
00:02:54.050 --> 00:02:57.950
number of robots or cars
or thermostats or whatever, and

46
00:02:57.950 --> 00:03:01.240
suddenly a very simple problem
with a couple of tables

47
00:03:01.240 --> 00:03:03.760
suddenly became a massive data
store. And there's so many

48
00:03:03.760 --> 00:03:07.230
questions you can ask it.
Yes. I think we call

49
00:03:07.230 --> 00:03:12.690
it like increasing dimensions, yard
dataset. Okay. You were only

50
00:03:12.690 --> 00:03:16.320
looking at like you said
access, but now you have

51
00:03:16.320 --> 00:03:20.070
like five different degrees of
freedom. The robot is moving

52
00:03:20.070 --> 00:03:23.550
in so many directions and
yeah, I think once it

53
00:03:23.550 --> 00:03:28.260
goes beyond your neat structured
tables, things get a little

54
00:03:28.260 --> 00:03:31.860
bit complicated. Again, this is
not data science. This is

55
00:03:31.860 --> 00:03:35.970
just data. We are not
doing any science here, but

56
00:03:36.480 --> 00:03:38.490
I think it was a
good place for me to

57
00:03:38.490 --> 00:03:41.430
start Well. So data, yeah,
the data science, like you

58
00:03:41.430 --> 00:03:43.470
said, it does start with
data. And then you add

59
00:03:43.470 --> 00:03:47.850
in and number of sources
and, you know, X number

60
00:03:47.850 --> 00:03:51.450
of you change the frequency
or the sampling rate. And

61
00:03:51.480 --> 00:03:53.100
you have a huge amount
of data. That's just like

62
00:03:53.100 --> 00:03:56.850
you said, ones and zeros.
The data science starts where,

63
00:03:57.000 --> 00:04:00.120
when I guess a business
person has a question, Not

64
00:04:00.120 --> 00:04:03.060
necessarily a business person, even
when you are looking at

65
00:04:03.060 --> 00:04:05.880
the data. And if you
have a question, it could

66
00:04:05.880 --> 00:04:09.720
start from you also, because
one of the things that's

67
00:04:10.050 --> 00:04:14.550
important for us is to
read those ones and zeros

68
00:04:14.550 --> 00:04:18.060
and put it in some
context, because again, zeros and

69
00:04:18.060 --> 00:04:21.150
ones don't make sense, but
in a context, they tell

70
00:04:21.150 --> 00:04:25.890
a story, what is it
saying? And is it a

71
00:04:25.890 --> 00:04:30.180
problem? Should I solve it?
Get some other data, be

72
00:04:30.180 --> 00:04:33.690
bought into this context to
solve this problem. So it

73
00:04:33.870 --> 00:04:37.170
doesn't necessarily have to come
from the business. I mean,

74
00:04:37.170 --> 00:04:41.580
it always usually does, but
it does start from ourself

75
00:04:41.580 --> 00:04:46.170
also, right? These questions come
from anywhere, right? And then

76
00:04:46.170 --> 00:04:48.750
the idea of bringing data
from somewhere else again, when

77
00:04:48.750 --> 00:04:51.870
I started out, I thought
about a table join and,

78
00:04:52.150 --> 00:04:55.530
and for me, data was
limited to the database I

79
00:04:55.530 --> 00:04:58.080
was working in. But Diana,
I know that data scientists

80
00:04:58.470 --> 00:05:03.750
draw correlations and effectively table
joins between databases by saying,

81
00:05:03.750 --> 00:05:06.750
well, this data correlates to
that. Or I could bring

82
00:05:06.750 --> 00:05:08.970
a map or some map
tiles or whatever. And now

83
00:05:08.970 --> 00:05:11.820
I can see my robot
on a map and pull

84
00:05:11.820 --> 00:05:16.440
from multiple sources to ask
an answer. Yes. I don't

85
00:05:16.440 --> 00:05:18.780
know how many offers that
actually build that much of

86
00:05:18.780 --> 00:05:22.350
a complicated, a high level
of stuff. Maybe, you know,

87
00:05:22.350 --> 00:05:25.650
you can do data science,
even on just one database

88
00:05:25.740 --> 00:05:30.090
and tables and just joints.
You don't always have to,

89
00:05:30.690 --> 00:05:35.040
you know, use live, click
stream data or Twitter data

90
00:05:35.130 --> 00:05:39.210
with addition to your database
to come up with useful

91
00:05:39.210 --> 00:05:44.640
insights, you can use what
you have. But again, there

92
00:05:44.640 --> 00:05:47.640
has to be substantial data.
I'm not saying, Oh, I

93
00:05:47.640 --> 00:05:50.280
have like two weeks worth
of data. Please tell me

94
00:05:50.280 --> 00:05:53.610
what's going to happen two
years down the line. That's

95
00:05:53.670 --> 00:05:58.520
that's ambitious. But all I'm
saying is it's not always

96
00:05:58.520 --> 00:06:02.890
necessary. That more data means
a good thing. Okay. Well

97
00:06:02.890 --> 00:06:04.960
that actually brings me to
a really good question. Then

98
00:06:05.260 --> 00:06:10.540
when does a database person
or someone who is select

99
00:06:10.540 --> 00:06:12.910
star from this and that
with a modest database, when

100
00:06:12.910 --> 00:06:16.960
do they become a data
scientist? When does database administrator

101
00:06:16.960 --> 00:06:20.020
or data Wrangler graduate? If
I'm going to get into

102
00:06:20.020 --> 00:06:24.220
this field and when does
it become science? So again,

103
00:06:24.250 --> 00:06:28.660
are you solving any problems?
Are you doing your select

104
00:06:28.660 --> 00:06:33.490
star for a purpose of
something? Okay. Let's say you're

105
00:06:33.490 --> 00:06:37.450
doing a select star, all
my employees in the company.

106
00:06:37.600 --> 00:06:42.640
Why do you want to
see the probability of someone

107
00:06:42.640 --> 00:06:46.750
leaving? Do you just want
to be more prepared again?

108
00:06:46.750 --> 00:06:49.330
Like let's say, because I'm
in consulting, there is this

109
00:06:49.330 --> 00:06:53.020
concept of a bench where,
you know, even though you're

110
00:06:53.020 --> 00:06:55.540
just waiting for the projects
to roll in and you

111
00:06:55.540 --> 00:06:58.990
have a resource ready to
go. So if I am

112
00:06:58.990 --> 00:07:02.290
a database administrator, I will
do okay. Select star my

113
00:07:02.290 --> 00:07:06.190
projects and my employees. But
if I want to be

114
00:07:06.190 --> 00:07:09.040
a data scientist, what am
I going to do? What's

115
00:07:09.370 --> 00:07:12.730
coming in. How many resources
will I have at that

116
00:07:12.730 --> 00:07:16.870
point of time? And how
do I make the data?

117
00:07:16.900 --> 00:07:20.410
Tell me how many resources
I need at any point

118
00:07:20.410 --> 00:07:23.410
of time. You know what
I'm trying to go with

119
00:07:23.410 --> 00:07:27.370
this. Does that make sense?
What I'm hearing is there's

120
00:07:27.370 --> 00:07:32.260
a question very often a
predictive question. There's some data

121
00:07:32.260 --> 00:07:35.800
that represents some historical context,
but some business context that

122
00:07:35.800 --> 00:07:38.710
I may or may not
understand. And like you said,

123
00:07:38.710 --> 00:07:41.800
it's like, I can answer
basic questions. Like give me

124
00:07:41.800 --> 00:07:44.890
all of the people and
their salaries and sort, but

125
00:07:45.040 --> 00:07:47.890
I could ask more complicated
questions. Like, is this division

126
00:07:47.890 --> 00:07:51.370
losing people? Why are they
leaving? Why are people enter

127
00:07:51.370 --> 00:07:53.350
this division? And then leave?
Like, I can answer all

128
00:07:53.350 --> 00:07:56.470
kinds of questions over time
that are going to predict

129
00:07:56.470 --> 00:07:59.020
the future. Like you said,
Right? Do you see a

130
00:07:59.020 --> 00:08:03.220
trend somewhere? Are all the
people living from a particular

131
00:08:03.280 --> 00:08:08.020
age group or are they
all leaving after? You know,

132
00:08:08.020 --> 00:08:10.930
let's say there is this
amazing project, but as soon

133
00:08:10.930 --> 00:08:14.770
as you're placed there, everyone
just leaves. Is there something

134
00:08:14.770 --> 00:08:18.700
going on, you know, finding
a trend or a story

135
00:08:19.090 --> 00:08:22.420
within your database, once you
start doing that, once you

136
00:08:22.420 --> 00:08:26.320
start analyzing your data and
giving it a context, I

137
00:08:26.320 --> 00:08:30.820
think you can say, yeah,
Pew, you're touching the basics

138
00:08:30.820 --> 00:08:33.910
of data science. So when
does data science start to

139
00:08:33.910 --> 00:08:35.500
get into machine learning? Because
I know that you do

140
00:08:35.500 --> 00:08:37.000
some work in AI as
well. Like if I were

141
00:08:37.000 --> 00:08:39.850
going to make a model
and then make a prediction,

142
00:08:39.850 --> 00:08:42.280
I make a predictive model.
Am I an AI engineer?

143
00:08:42.280 --> 00:08:44.320
Am I a machine learning
engineer? Or am I still

144
00:08:44.710 --> 00:08:46.570
in the space of, of
data science? Or are they

145
00:08:46.570 --> 00:08:49.630
the same thing? They're all
the same thing. I mean,

146
00:08:49.630 --> 00:08:53.140
they're all in the same
space, but I think it's

147
00:08:53.200 --> 00:08:57.390
awfully late. That few are
breaking up how they define

148
00:08:57.390 --> 00:09:02.730
data science because it's such
a wast field. And what

149
00:09:02.730 --> 00:09:07.140
you do is all specific
to the problems you are

150
00:09:07.140 --> 00:09:09.990
trying to solve are specific
to the company or working

151
00:09:09.990 --> 00:09:14.580
for. So now we have
like machine learning, engineers or

152
00:09:15.300 --> 00:09:21.420
algorithms research. These guys are
only working towards how do

153
00:09:21.420 --> 00:09:25.230
we make our machine learning
algorithms better or faster or

154
00:09:25.230 --> 00:09:28.980
more accurate, but AI engineers,
they are, they're trying to

155
00:09:28.980 --> 00:09:33.600
do more deep planning stuff.
But again, all of this

156
00:09:33.630 --> 00:09:36.540
is data science. I mean,
yeah, you are using your

157
00:09:36.540 --> 00:09:41.850
data to using your data
and science behind it to

158
00:09:41.850 --> 00:09:45.750
come up with solutions. How
are you doing that is,

159
00:09:46.110 --> 00:09:48.390
you know, you can just
break it. Are you doing

160
00:09:48.390 --> 00:09:54.180
cutting edge research? Are you
just applying predictive analytics or

161
00:09:54.180 --> 00:09:57.360
statistics? It all comes down
to what you're trying to

162
00:09:57.360 --> 00:10:00.650
do. I think Here's the
part that I find confusing

163
00:10:00.650 --> 00:10:03.950
though, is we are creating
these models, these AIS, these

164
00:10:03.950 --> 00:10:08.150
systems of data science that
are using historical data, right?

165
00:10:08.150 --> 00:10:12.620
Because by definition, all data
is from the past. It

166
00:10:12.620 --> 00:10:16.850
is very likely imperfect data.
And then it is going

167
00:10:16.850 --> 00:10:19.280
to then express or we're
going to hope it expresses

168
00:10:19.280 --> 00:10:23.810
some theoretical predicted future. It
seems so ridiculous that we're

169
00:10:23.810 --> 00:10:28.070
building models. Assuming that past
results can predict future ones.

170
00:10:28.070 --> 00:10:29.930
And that's where the jump
I think is, is so

171
00:10:29.930 --> 00:10:34.010
challenging. I think this is
where a BI comes into

172
00:10:34.010 --> 00:10:38.030
place. I mean, before AI,
there was always business intelligence

173
00:10:38.480 --> 00:10:43.130
and business intelligence mostly is
to make sure that there

174
00:10:43.130 --> 00:10:46.400
is data integrity. And that
would be a good starting

175
00:10:46.400 --> 00:10:49.520
step. Okay. I know you
say you have data, but

176
00:10:49.580 --> 00:10:52.970
is that data right? That's
where BI comes in and

177
00:10:53.180 --> 00:10:57.410
probably using the correct data.
You're just saying, again, we

178
00:10:57.410 --> 00:11:01.130
are not stating that, Oh,
this happened in the past.

179
00:11:01.130 --> 00:11:03.470
It will happen in the
future. All we are saying

180
00:11:03.470 --> 00:11:06.860
is there is a high
probability of this happening in

181
00:11:06.860 --> 00:11:10.100
the future. We don't talk
in these terms, do their

182
00:11:10.100 --> 00:11:13.760
business. But you know, as
statisticians, we are always like,

183
00:11:13.820 --> 00:11:17.150
okay, there is an error
percentage, but we are leaning

184
00:11:17.150 --> 00:11:21.350
towards the possibility that this
is happening are going they'll

185
00:11:21.350 --> 00:11:28.370
happen. And if it's more
than like 50, 50, yeah.

186
00:11:28.490 --> 00:11:30.710
It's a true or false
at this point. So you're

187
00:11:30.710 --> 00:11:34.760
really just trying to beat
a coin flip. Yes, no,

188
00:11:34.760 --> 00:11:37.790
yeah. I mean, let's say
I flip a coin a

189
00:11:37.790 --> 00:11:40.310
hundred times. Can you say,
what am I going to

190
00:11:40.310 --> 00:11:43.760
get in the next five
times? Nope. So it's pretty

191
00:11:43.760 --> 00:11:47.480
much, but yeah, I know
it's not that simple, but

192
00:11:47.780 --> 00:11:50.660
no, we are. We cannot
say for sure that this

193
00:11:50.660 --> 00:11:53.440
will happen in the future,
but we can say, okay,

194
00:11:53.530 --> 00:11:56.080
I'm 90% sure that this
will happen in the future.

195
00:11:56.430 --> 00:11:57.930
So when you go and
you want to test these

196
00:11:57.930 --> 00:12:00.690
models, you've got some data
you're thinking about testing some

197
00:12:00.690 --> 00:12:03.840
prediction about it. You're making
this predictive analytic analysis model.

198
00:12:04.320 --> 00:12:07.800
I understand that there's a
training dataset. There's a test

199
00:12:07.950 --> 00:12:11.100
data set. Maybe there's a
validation data set. What is

200
00:12:11.100 --> 00:12:13.620
the relationship between the training
data set? The thing that

201
00:12:13.620 --> 00:12:15.240
you're training and on, do
you train it on all

202
00:12:15.240 --> 00:12:18.330
of your data or do
you pick and choose? How

203
00:12:18.330 --> 00:12:20.190
do you make the decision
about what you train on?

204
00:12:20.190 --> 00:12:23.490
Because I understand that picking
the wrong training dataset, like

205
00:12:23.490 --> 00:12:28.290
garbage in garbage out. Right?
Right. So don't pick, make

206
00:12:28.290 --> 00:12:31.860
it as random as possible
because if you want to

207
00:12:31.860 --> 00:12:36.960
your model to work again,
the whole reason of training

208
00:12:36.990 --> 00:12:40.710
and testing is because once
you are going to deploy

209
00:12:40.710 --> 00:12:44.280
it, the data which the
model is going to ingest,

210
00:12:44.340 --> 00:12:47.670
you don't know how it's
going to be. So why

211
00:12:47.670 --> 00:12:50.790
do you want to train
it on a specific kind

212
00:12:50.790 --> 00:12:54.900
of data? And then once
you deploy it, it doesn't

213
00:12:54.900 --> 00:12:57.990
work because the data that
you are getting in real

214
00:12:57.990 --> 00:13:02.310
time is completely different. So
you're essentially training it. You're

215
00:13:02.310 --> 00:13:06.150
training it to be as
robust as possible. And if

216
00:13:06.150 --> 00:13:08.670
you pick it, you're probably
going to get like, Oh,

217
00:13:08.670 --> 00:13:12.990
it's 98% accurate, which means
you're probably overfitting the data.

218
00:13:13.470 --> 00:13:17.250
So make it as random
as possible once you train

219
00:13:17.250 --> 00:13:19.740
it and you say, okay,
it works. Just test it

220
00:13:19.740 --> 00:13:22.380
out, test it out on
a data, which was not

221
00:13:22.380 --> 00:13:25.500
part of the training set
to see, okay. If I

222
00:13:25.500 --> 00:13:29.730
ever deploy it in a
real time situation, how is

223
00:13:29.730 --> 00:13:33.870
it going to be? And
probably that's the only relationship

224
00:13:33.900 --> 00:13:38.340
between training and testing, both
as random as possible, but

225
00:13:38.670 --> 00:13:43.980
80%, 20% is what we
most usually do. Now. You

226
00:13:43.980 --> 00:13:46.350
used a word there that
I don't think everyone caught.

227
00:13:46.380 --> 00:13:49.650
You said overfitting maybe you've
overfitted that. And if you

228
00:13:49.650 --> 00:13:52.980
could talk about what an
overfitted statistical model is, It

229
00:13:52.980 --> 00:13:57.210
would say, let's go back
to the quietness. I tossed

230
00:13:57.210 --> 00:14:02.190
my client a hundred times.
I got 98 times heads

231
00:14:02.190 --> 00:14:06.540
and two times tales. And
I'm training a model on

232
00:14:06.540 --> 00:14:11.070
this and I'll just say
my model. Okay. What is

233
00:14:11.070 --> 00:14:15.090
the probability that just tell
me what's going to happen

234
00:14:15.090 --> 00:14:18.270
in the next five tries
based on this data, it's

235
00:14:18.270 --> 00:14:20.760
going to tell me it's
probably going to be hit

236
00:14:21.000 --> 00:14:24.360
because you know, 98 out
of a hundred is a

237
00:14:24.360 --> 00:14:28.110
high thing. So this is
what overfitting is. Your data

238
00:14:28.110 --> 00:14:33.120
is so skewed and your
model is so accurate and

239
00:14:33.120 --> 00:14:36.390
perfect. It just thinks, Oh,
this is how the data

240
00:14:36.390 --> 00:14:40.560
always is Interesting. Okay. So
you're saying that you have

241
00:14:40.590 --> 00:14:44.310
pulled out some variation, some
noise, and then now you

242
00:14:44.310 --> 00:14:48.210
think that noise represents reality.
Like I happen to pick

243
00:14:48.870 --> 00:14:52.310
five heads in a row
that's sample. I go and

244
00:14:52.370 --> 00:14:55.430
fit to that. And now
what should be a random

245
00:14:55.430 --> 00:14:58.190
50, 50 is now a
hundred percent because I've completely,

246
00:14:58.190 --> 00:15:02.060
overfitted based on a piece
of noise that now potentially

247
00:15:02.060 --> 00:15:06.850
represents the, the model's structure.
I've lied to myself. Yes.

248
00:15:07.010 --> 00:15:10.270
That essentially is what all
fitting is. How do you

249
00:15:10.270 --> 00:15:12.370
know what happens though? Like
if you're working with data

250
00:15:12.370 --> 00:15:14.110
like coins, I can see
that you can look at

251
00:15:14.110 --> 00:15:16.180
it and think it through.
But if you're working on

252
00:15:16.180 --> 00:15:19.570
something big and complicated, like
voting, you know, or something

253
00:15:19.570 --> 00:15:22.240
like that, how do you
know that? You're right. Because

254
00:15:22.240 --> 00:15:25.330
that's the thing you're asking
a question to which you

255
00:15:25.330 --> 00:15:28.180
don't necessarily know the answer.
Well, let me, let me

256
00:15:28.180 --> 00:15:31.000
back up. There are data
science problems for which I

257
00:15:31.000 --> 00:15:33.160
don't know the answer so
I can make a model.

258
00:15:33.160 --> 00:15:34.630
And I still don't know
if I got it right.

259
00:15:34.960 --> 00:15:37.150
And then there's stuff where
I can actually say I've

260
00:15:37.150 --> 00:15:39.520
trained this. And now I
know that I got it

261
00:15:39.520 --> 00:15:42.190
right. Because I have a
validation piece of data, a

262
00:15:42.190 --> 00:15:47.200
data set that's valid. That's
validatable Well, you know, it's

263
00:15:47.200 --> 00:15:50.080
a funny story. If the
answers are too good to

264
00:15:50.080 --> 00:15:56.140
be true, it means we've
probably overfit them. It's an

265
00:15:56.140 --> 00:16:02.980
unfortunate part of the job.
But no, generally in reality,

266
00:16:02.980 --> 00:16:06.880
we are not supposed to
get such perfect models are

267
00:16:06.880 --> 00:16:09.250
such perfect fit. If you
say, Oh my God, your

268
00:16:09.250 --> 00:16:13.510
model is working with 98%
accuracy. We know we all

269
00:16:13.520 --> 00:16:16.540
affected, like you ask anyone,
we just, we just know

270
00:16:16.540 --> 00:16:19.990
it. So we go back,
we change our training sets

271
00:16:19.990 --> 00:16:23.800
or testing sets, or we
just create random data sets

272
00:16:23.800 --> 00:16:26.410
and see, okay, what's going
on? And then we try

273
00:16:26.410 --> 00:16:31.000
to change the variables to
unit and make sure, Oh,

274
00:16:31.000 --> 00:16:34.570
what comes up again? Yeah.
Interesting. That's all it is.

275
00:16:34.570 --> 00:16:37.210
It's a lot of trial
and error because when you're

276
00:16:37.210 --> 00:16:39.760
working with such huge data
sets, you can't go line

277
00:16:39.760 --> 00:16:42.940
by line or table by
table and figure out what's

278
00:16:42.940 --> 00:16:47.170
going on. I heard someone
say once that overfitting is

279
00:16:47.170 --> 00:16:50.650
when the model is starting
to memorize the data, as

280
00:16:50.650 --> 00:16:54.040
opposed to learning the data.
Yeah. That that's a good

281
00:16:54.040 --> 00:16:57.430
way to put it right.
Instead of seeing the trends,

282
00:16:57.430 --> 00:17:00.790
it's just like, this is
what the data is. So

283
00:17:00.790 --> 00:17:03.700
this is what the data
will look like. Not that,

284
00:17:03.820 --> 00:17:07.390
Oh, after every four or
five tries, I'm getting ahead.

285
00:17:07.420 --> 00:17:11.350
So every four or five
tries I will get ahead,

286
00:17:11.440 --> 00:17:14.230
you know? Yeah. No, that's
a good analogy. All right.

287
00:17:14.230 --> 00:17:16.930
That makes me happy. I'd
like to welcome our new

288
00:17:16.930 --> 00:17:21.760
sponsor. Couchbase Couchbase is an
open source. No SQL document

289
00:17:21.790 --> 00:17:25.990
and key value store database
requires no external cash supports

290
00:17:25.990 --> 00:17:30.670
CQL and analytical queries for
Jason data. Couchbase supports technologies

291
00:17:30.670 --> 00:17:36.400
like Kubernetes, java.net, JavaScript, go
and Python. Download it, give

292
00:17:36.400 --> 00:17:44.980
it a try at couchbase.com/hansel
minutes. That's couchbased.com/hansel minutes. And

293
00:17:44.980 --> 00:17:47.440
I'll remind you that when
you support our sponsors, you

294
00:17:47.440 --> 00:17:50.580
support this show. How often
do you find yourself doing

295
00:17:50.580 --> 00:17:53.520
these kinds of cool Hetty
things that we've been talking

296
00:17:53.520 --> 00:17:57.060
about versus just cleaning data?
Like how much are you

297
00:17:57.060 --> 00:18:02.300
a data janitor versus a
scientist? 80% of my job

298
00:18:02.360 --> 00:18:09.290
is killing the data. Yes.
Modeling hardly takes, I wouldn't

299
00:18:09.290 --> 00:18:13.910
say hardly, but modeling takes
up much less time than

300
00:18:14.990 --> 00:18:19.190
I wish a lot of
it is data cleaning or

301
00:18:19.190 --> 00:18:22.670
more, more so data gathering.
Really the number of times

302
00:18:22.670 --> 00:18:26.330
I had to just like,
where is the data? Where

303
00:18:26.330 --> 00:18:30.680
is the data I need
not just you'd really need

304
00:18:30.680 --> 00:18:34.160
to start with defining a
problem. Okay. This is the

305
00:18:34.160 --> 00:18:38.420
problem. What is causing this
problem? Do we have data

306
00:18:38.450 --> 00:18:42.920
relevant to that? Just because
I know let's pick an

307
00:18:42.920 --> 00:18:47.240
example for watering. You want
to see how the watting

308
00:18:47.270 --> 00:18:50.450
outcome is going to be,
how is weather going to

309
00:18:50.450 --> 00:18:52.760
affect that? I have so
much data and it's all

310
00:18:52.760 --> 00:18:57.350
weather data. Is that going
to affect my ordering? Probably

311
00:18:57.350 --> 00:19:01.910
not. So data gathering is
step one and then comes

312
00:19:01.910 --> 00:19:06.200
the data cleaning, making sure
that, okay, I have this

313
00:19:06.200 --> 00:19:10.460
vision or this spot, which
are these, these algorithms that

314
00:19:10.460 --> 00:19:13.430
I'm going to use. How
do I wrangle the data?

315
00:19:13.640 --> 00:19:17.540
So unfortunately, 80% of my
job is just being a

316
00:19:17.540 --> 00:19:22.790
data janitor. So you are
filtering out things that you

317
00:19:22.790 --> 00:19:26.150
don't want. You're removing things.
You're dropping things. I presume

318
00:19:26.150 --> 00:19:30.140
that you're removing outliers of
a certain kind Outliers of

319
00:19:30.140 --> 00:19:34.670
a certain guide are, you
know, cutting down dimensions. Because

320
00:19:35.300 --> 00:19:38.630
if two things probably say
the same thing to me,

321
00:19:38.720 --> 00:19:42.260
I have one column it
says is hot. The other

322
00:19:42.260 --> 00:19:45.860
column it says is not
cold. They probably bought me

323
00:19:45.860 --> 00:19:50.390
the same thing. So just
cutting those things out, yes.

324
00:19:50.420 --> 00:19:54.140
Starts with filtering. Then making
sure that I don't have,

325
00:19:54.410 --> 00:20:01.010
you know, missing values or
just random data, which is

326
00:20:01.250 --> 00:20:04.520
not part of the trend.
And then again, next step,

327
00:20:04.850 --> 00:20:06.920
what am I trying to
do? Do I have enough

328
00:20:07.280 --> 00:20:09.470
In the, in the real
world kind of work that

329
00:20:09.470 --> 00:20:12.050
you're doing? I'm curious about
this because I learned it

330
00:20:12.050 --> 00:20:13.700
in school, but I've never
dealt with it in the

331
00:20:13.700 --> 00:20:17.510
real world. Is how often
is the normal distribution? Like

332
00:20:17.510 --> 00:20:20.510
the bell curve that we
always talk about a real

333
00:20:20.510 --> 00:20:21.980
thing? Or is that just
a thing we learned in

334
00:20:21.980 --> 00:20:25.760
school? Is that true? I
haven't come across it yet,

335
00:20:26.390 --> 00:20:29.600
to be honest. So it's
statistics aren't as clean as

336
00:20:29.600 --> 00:20:32.000
we think they might be
when you apply variants and

337
00:20:32.000 --> 00:20:34.970
a lot of stuff, You
would just go with the

338
00:20:34.970 --> 00:20:37.640
assumption that it doesn't all
want distribution, but if you

339
00:20:37.640 --> 00:20:40.940
actually put it, I think
I've, I did try it.

340
00:20:40.940 --> 00:20:43.430
I had the same question
as you did. Okay. Is

341
00:20:43.430 --> 00:20:46.190
this following a normal distribution?
Am I going to get

342
00:20:46.190 --> 00:20:51.490
that nice inverted you graph?
No, but all these statistical

343
00:20:51.490 --> 00:20:54.730
tests are better on the
assumption that your data is

344
00:20:54.730 --> 00:20:58.750
normal distribution. And you just
go ahead with fate. They're

345
00:20:58.750 --> 00:21:01.930
not perfectly you, but yes,
you see outliers and you

346
00:21:01.930 --> 00:21:04.840
see a lot of the
data falling into a group

347
00:21:04.900 --> 00:21:08.110
in a way, yes, normal
distribution, but not perfectly normal

348
00:21:09.630 --> 00:21:13.620
As I'm teaching my children,
math and basic statistics, there

349
00:21:13.620 --> 00:21:16.020
are only 12 and 14.
One of the things that

350
00:21:16.020 --> 00:21:18.690
we've been using without swearing,
but I'll use this term,

351
00:21:19.290 --> 00:21:23.220
do they know how to
detect BS? Like, does it

352
00:21:23.220 --> 00:21:26.340
smell bad when you have
a math problem, you should

353
00:21:26.340 --> 00:21:29.160
have a good sense of
smell. You know? And I

354
00:21:29.160 --> 00:21:30.990
understand that when you're a
data scientist, you look at

355
00:21:30.990 --> 00:21:33.290
a dataset, you look at
the top 20 rows and

356
00:21:33.290 --> 00:21:35.100
the bottom 20 rows and
pick some in the middle

357
00:21:35.100 --> 00:21:38.130
and you say, is this
BS, does this smell right?

358
00:21:38.130 --> 00:21:41.670
Does this data make sense
and make whether or not

359
00:21:41.670 --> 00:21:44.070
it makes sense? Depends on
the kind of question you're

360
00:21:44.070 --> 00:21:46.260
trying to ask. Right. Is
it, is it names, is

361
00:21:46.260 --> 00:21:49.050
it addresses? Is it numeric?
Is it lat lawn? You

362
00:21:49.050 --> 00:21:51.630
know, you're, you, you don't
know, given a giant data

363
00:21:51.630 --> 00:21:55.740
set, whether this is nonsense
or not, You don't, you,

364
00:21:55.740 --> 00:21:59.850
you have to get your
hands dirty, spend some time

365
00:21:59.850 --> 00:22:03.420
with it before you just
come to the conclusion that

366
00:22:03.420 --> 00:22:07.620
it is BS, unless it's
a very small data set.

367
00:22:07.650 --> 00:22:10.260
But again, in real world,
we don't deal with small

368
00:22:10.260 --> 00:22:14.490
datasets with the whole advent
of big data and cloud.

369
00:22:14.490 --> 00:22:20.130
And the data set has
grown tremendously. And yeah, you

370
00:22:20.130 --> 00:22:24.960
need to spend some time
with it, run basic exploratory

371
00:22:24.960 --> 00:22:29.340
analysis to come up with
your own conclusions. What data

372
00:22:29.340 --> 00:22:31.830
science tools are you using
if I'm, if I'm listening

373
00:22:31.830 --> 00:22:33.540
to this and I'm thinking
maybe this is a fun,

374
00:22:33.990 --> 00:22:37.260
a fun job is there's
thousands of tools there's even

375
00:22:37.290 --> 00:22:40.440
hundreds and just for visualization,
but what are your kind

376
00:22:40.440 --> 00:22:42.780
of your toolbox of main
tools for being a data

377
00:22:42.780 --> 00:22:46.860
scientist? I use R and
by Tim, they are both

378
00:22:46.980 --> 00:22:52.350
really good and powerful for
data analysis, the, you know,

379
00:22:52.350 --> 00:22:58.710
starting analysis. And then obviously
you should have, if not

380
00:22:58.920 --> 00:23:03.810
absolutely well was, do you
should know how to engineer

381
00:23:03.810 --> 00:23:07.050
your own data. If I
have to say, okay, so

382
00:23:07.290 --> 00:23:13.950
sequel or working with cloud
warehouses, you should have all

383
00:23:13.950 --> 00:23:17.220
these tools. So I work
with snowflake. I work with

384
00:23:17.220 --> 00:23:21.480
sequel. I work with my
turn and R and for

385
00:23:21.480 --> 00:23:25.590
visualization tools, you can visualize
using Python and R, but

386
00:23:25.590 --> 00:23:30.060
if you want tools, power
BI and Tableau, these are

387
00:23:30.060 --> 00:23:32.730
pretty good. I think these
are the standards. So I've,

388
00:23:33.180 --> 00:23:36.840
I've had experience with. And
when you're working with you

389
00:23:36.840 --> 00:23:38.730
say Python and R, is
that something where you spend

390
00:23:38.730 --> 00:23:41.220
time in a Jupiter notebook?
Or where are you doing

391
00:23:41.220 --> 00:23:45.950
this work? I, for our,
our use our, I think

392
00:23:45.950 --> 00:23:49.760
that's the best IDE for
it, for Biden. I use

393
00:23:49.760 --> 00:23:54.620
Jupiter notebooks. I also, because
I said, I do work

394
00:23:54.650 --> 00:24:00.200
extensively with snowflake. Also snowflake
has its new partners called

395
00:24:00.200 --> 00:24:03.860
Zapple. Everything is built on
like a Python, Jupiter notebook

396
00:24:03.860 --> 00:24:07.610
interface, but I've been trying
out new tools. I think

397
00:24:07.610 --> 00:24:11.510
once you can master Jupiter
notebooks, everything else should be

398
00:24:11.510 --> 00:24:14.530
sort of similar. And for
people who don't know, it's

399
00:24:14.530 --> 00:24:16.510
no flick is it's a,
it's a cloud based data

400
00:24:16.510 --> 00:24:20.080
warehouse. So this idea of
a data warehouse is like

401
00:24:20.110 --> 00:24:23.320
more than a database. Like
it's like you think that

402
00:24:23.320 --> 00:24:25.780
this store is big, go
to Costco, that's it? That's

403
00:24:25.780 --> 00:24:31.690
a warehouse. Yes. It is
like that. Instead of one

404
00:24:31.690 --> 00:24:34.660
database, you have more than
one database or maybe one

405
00:24:34.660 --> 00:24:40.300
huge database. However, it makes
easier. It's a whole world

406
00:24:40.360 --> 00:24:43.240
of data that you could
potentially pull from. And you're,

407
00:24:43.240 --> 00:24:45.520
so you're dealing with data
mostly in the cloud. Like

408
00:24:45.520 --> 00:24:48.040
when I was doing work,
20, 30 years ago, I

409
00:24:48.040 --> 00:24:49.810
would be doing it on
a desktop or a laptop.

410
00:24:49.810 --> 00:24:52.120
And I'd be dealing with
only, you know, some gigabytes.

411
00:24:52.840 --> 00:24:55.450
What's the biggest thing you've
ever pushed around. What's the

412
00:24:55.450 --> 00:24:57.550
biggest amount of data you've
messed with. I don't know

413
00:24:57.550 --> 00:25:00.280
in terms of memory, but
I could say in terms

414
00:25:00.280 --> 00:25:03.430
of number of rows, just
one of the tables was

415
00:25:03.430 --> 00:25:09.160
like a 40 million row. Again,
that's small comparatively to the

416
00:25:09.220 --> 00:25:12.580
data sets that people are
using around, but yeah, 40 million

417
00:25:12.580 --> 00:25:17.590
rows. So 40 million rows is
small is a modest dataset.

418
00:25:19.570 --> 00:25:24.250
Yeah. I think once you've
worked with that much data,

419
00:25:24.280 --> 00:25:27.850
everything else seems small, but
no, I speak to people.

420
00:25:28.240 --> 00:25:32.920
They are working in terabytes
of data and trying to

421
00:25:32.920 --> 00:25:37.930
understand, and that's amazing work.
How, where do you start?

422
00:25:38.230 --> 00:25:41.890
So, So you, you said
that that people should start

423
00:25:41.890 --> 00:25:44.290
with Jupiter notebook. So if
you find data interesting, you

424
00:25:44.290 --> 00:25:47.590
can sit down and make
a Jupiter notebook at any

425
00:25:47.590 --> 00:25:51.400
other cloud vendors. Jupiter notebooks
works. If you're using visual

426
00:25:51.400 --> 00:25:54.340
studio code, you can go
and create your own environment

427
00:25:54.340 --> 00:25:58.210
locally, get Python all set
up and start learning Jupiter

428
00:25:58.210 --> 00:26:00.010
notebooks. Do you think that's
a good place to begin

429
00:26:00.310 --> 00:26:03.640
your data science journey? It
is. I know K girl

430
00:26:03.670 --> 00:26:07.090
is amazing. Our, when I
was in school, I would

431
00:26:07.090 --> 00:26:10.990
always go on to Kagel.
They have so many competitions.

432
00:26:11.380 --> 00:26:15.100
They already have notebooks for
someone new to come and

433
00:26:15.100 --> 00:26:18.520
take a look and see,
okay, this is how everyone

434
00:26:18.520 --> 00:26:21.910
else is doing or breaking
down that data. And they

435
00:26:21.910 --> 00:26:25.780
always have new problems and
it's so bad. It's hot

436
00:26:25.780 --> 00:26:28.270
out. I know there are
a lot of data sets

437
00:26:28.630 --> 00:26:32.080
that were put on KCL
by IBM or Google because

438
00:26:32.080 --> 00:26:36.790
they were trying to see
how everyone else is having

439
00:26:36.790 --> 00:26:39.790
a perspective towards this. That
would be the best place

440
00:26:39.790 --> 00:26:42.760
to start because you also
get your hands on data.

441
00:26:43.980 --> 00:26:46.080
There are so many open
data sets, but I think

442
00:26:46.080 --> 00:26:48.990
Cagle is a really good
place to start. You can

443
00:26:49.050 --> 00:26:51.480
choose your language. You can
choose to do it in

444
00:26:51.480 --> 00:26:57.630
Python or R or whatever
other languages you are familiar

445
00:26:57.630 --> 00:27:02.150
with and take it from
there. Okay. And Cagle or

446
00:27:02.150 --> 00:27:07.550
kaggle.com is K a G
G L e.com. I really

447
00:27:07.550 --> 00:27:10.670
liked their homepage because it
says start with more than

448
00:27:10.670 --> 00:27:13.220
a blinking cursor. You know,
you don't teach someone how

449
00:27:13.220 --> 00:27:16.760
to code with hello world,
necessarily. You say here here's

450
00:27:16.880 --> 00:27:21.260
20,000 public data sets, go
play and ask, ask questions.

451
00:27:21.260 --> 00:27:24.200
It's a great way to
get started rather than learning

452
00:27:24.200 --> 00:27:26.540
in the shallow end of
the pool. You just throw

453
00:27:26.540 --> 00:27:29.600
them into the deep end
and see them swim. Yes,

454
00:27:29.630 --> 00:27:34.190
that's true. And as a
data scientist, you always need

455
00:27:34.220 --> 00:27:36.800
to have, or need to
put a context to your

456
00:27:36.800 --> 00:27:41.210
data, and this pushes you
to do that. Well, I

457
00:27:41.210 --> 00:27:43.840
really appreciate you chatting with
me today. This was great.

458
00:27:43.910 --> 00:27:47.750
God, thank you for the
time. Yeah. Appreciate the opportunity.

459
00:27:47.750 --> 00:27:51.320
We've been chatting with mega
Virginia. She's a data scientist

460
00:27:51.320 --> 00:27:54.230
or say Geyser, and we're
learning all about pathways to

461
00:27:54.230 --> 00:27:57.860
data science. This has been
another episode of Hansel minutes

462
00:27:58.160 --> 00:28:11.060
and we'll see you again
next week. <inaudible>.

