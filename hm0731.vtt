WEBVTT FILE

1
00:00:00.240 --> 00:00:02.970
Hey friends. I want to
thank our sponsor. Reagan, are

2
00:00:02.970 --> 00:00:05.610
you struggling to replicate the
bugs and performance issues that

3
00:00:05.610 --> 00:00:08.850
your customers are reporting, plug
Reagan into your web and

4
00:00:08.850 --> 00:00:12.510
mobile applications right now, and
diagnose problems in minutes rather

5
00:00:12.510 --> 00:00:15.840
than hours, kiss goodbye. Having
to dig through log files

6
00:00:15.840 --> 00:00:19.470
and relying on frustrated users
to report issues, make your

7
00:00:19.470 --> 00:00:23.130
software development life so much
easier using Reagan's error, crash,

8
00:00:23.130 --> 00:00:27.270
and performance monitoring tools. Every
software team can create flawless

9
00:00:27.270 --> 00:00:30.660
software experiences for their customers
with Reagan. Try it free

10
00:00:30.690 --> 00:00:34.320
today. And Ray gun.com. That's
our a Y G U

11
00:00:34.320 --> 00:00:51.380
n.com. Hi, this is Scott
Hanselman. This is another Hansel

12
00:00:51.380 --> 00:00:55.100
minutes today. I'm talking with
Emily <inaudible>. She's a hacktivist

13
00:00:55.100 --> 00:00:58.790
who has a background in
AirCanada aeronautical and mechanical engineering.

14
00:00:58.790 --> 00:01:01.430
And then also a degree
in mathematics. And you worked

15
00:01:01.430 --> 00:01:04.070
in the, in the healthcare
industry, didn't you? Yeah, that's

16
00:01:04.070 --> 00:01:08.990
correct. I was a research
engineer and worked on a

17
00:01:08.990 --> 00:01:15.650
number of biomedical research projects,
building medical device, software and

18
00:01:15.650 --> 00:01:19.520
medical devices themselves. Actually, this
is a really, really important

19
00:01:19.520 --> 00:01:22.100
interest to me, not just
because of the current environment,

20
00:01:22.100 --> 00:01:25.130
but also my situation as
a 25 year type one

21
00:01:25.130 --> 00:01:28.130
diabetic, I've been on an
insulin pump from a company

22
00:01:28.130 --> 00:01:31.010
called Medtronic for now 15
years. This is a device

23
00:01:31.010 --> 00:01:34.010
that in 15 years has
never failed me. Not once

24
00:01:34.010 --> 00:01:37.130
it hasn't shut off rebooted.
I consider it the space

25
00:01:37.130 --> 00:01:40.490
shuttle of devices, but of
course I'm hacking into it

26
00:01:40.550 --> 00:01:43.100
and using an open source
artificial pancreas using it in

27
00:01:43.100 --> 00:01:47.210
ways. It was not particularly
designed to use. We'll come

28
00:01:47.210 --> 00:01:48.950
to that a little bit
towards the middle, but if

29
00:01:48.950 --> 00:01:52.850
we look at the current
environment, what are we facing?

30
00:01:53.240 --> 00:01:55.640
Yeah. You know, there's been
a lot of talk, especially

31
00:01:55.640 --> 00:01:59.210
in the past few days
about the lack of ventilators.

32
00:01:59.240 --> 00:02:03.230
As we're looking at the
surge in coronavirus cases, that's

33
00:02:03.230 --> 00:02:06.800
on the horizon and also
the lack of personal protective

34
00:02:06.800 --> 00:02:11.450
equipment for healthcare workers and
also the general public. And

35
00:02:12.320 --> 00:02:15.260
to me, this is interesting
because this is a pretty

36
00:02:16.010 --> 00:02:21.500
interesting case of a medical
device shortage, personal protective equipment,

37
00:02:21.530 --> 00:02:25.250
like face masks and gloves
and things like that. Those

38
00:02:25.250 --> 00:02:29.390
are actually regulated medical devices.
And one of the challenges

39
00:02:29.390 --> 00:02:31.970
that we see when we
have something like a medical

40
00:02:31.970 --> 00:02:35.990
device shortage is that it's
actually quite difficult to legally

41
00:02:36.290 --> 00:02:39.860
manufacture and sell a medical
device. So it's not easy

42
00:02:39.860 --> 00:02:43.460
to scale up production so
quickly. Is that a global

43
00:02:43.460 --> 00:02:46.010
thing or is that an
American thing? Is it everyone

44
00:02:46.010 --> 00:02:49.310
is careful about allowing people
to create medical devices more

45
00:02:49.310 --> 00:02:51.590
or less? Yes. So let
me preface this with a

46
00:02:51.590 --> 00:02:54.500
little, with a couple of
disclaimers here first that I

47
00:02:54.500 --> 00:02:56.810
am not a lawyer, as
he mentioned that my background

48
00:02:56.810 --> 00:03:01.930
is in aeronautical mechanical and
mathematics. I do, I have

49
00:03:01.930 --> 00:03:05.160
studied medical device regulations, but
I am not a professional

50
00:03:05.380 --> 00:03:10.090
in the certification process in
the United States or overall. And

51
00:03:10.090 --> 00:03:12.610
I also want to be
clear that what I'm saying

52
00:03:12.610 --> 00:03:15.550
here is not the opinion
of my employer. This is

53
00:03:15.550 --> 00:03:20.470
just my own background. So
that said it is different

54
00:03:20.530 --> 00:03:24.760
around the world. The United States
regulations are different than those

55
00:03:24.760 --> 00:03:27.490
in Canada, different than those
in the UK and different

56
00:03:27.490 --> 00:03:32.110
than those and Europe with
the European union regulations, there's

57
00:03:32.290 --> 00:03:36.940
obviously regulations that affect every
part of the world, every

58
00:03:36.940 --> 00:03:40.060
country, but the ones that
I'm most familiar with are

59
00:03:40.060 --> 00:03:44.890
the American set of standards.
However, there is an international

60
00:03:44.890 --> 00:03:47.800
set of medical device standards
that is more or less

61
00:03:47.800 --> 00:03:51.910
uniform in how they are
built in designed and audited

62
00:03:52.150 --> 00:03:56.010
essentially. So the shortage right
now, for example, if we

63
00:03:56.010 --> 00:03:59.130
look at masks, you just
can't, I just can't start

64
00:03:59.130 --> 00:04:00.750
up a company in my
garage right now and start

65
00:04:00.750 --> 00:04:02.730
selling masks and tell everyone
that these are great. There

66
00:04:02.730 --> 00:04:06.030
is formal testing standards about
whether or not these are

67
00:04:06.060 --> 00:04:09.780
in fact effective and specifically,
do they meet all of

68
00:04:09.780 --> 00:04:12.180
the standards, whether they be
ISO standards or medical standards

69
00:04:12.180 --> 00:04:14.130
and all of the above,
and do the thing that

70
00:04:14.130 --> 00:04:15.840
they are intended to do,
which is keep people from

71
00:04:15.840 --> 00:04:19.530
getting ill. They are personal
protective devices that are regulated

72
00:04:19.530 --> 00:04:24.270
medical, durable equipment. That's correct.
So the FDA in the

73
00:04:24.270 --> 00:04:29.490
United States is the body that
is empowered with regulating the

74
00:04:29.730 --> 00:04:33.420
manufacture and sale of medical
devices. And the FDA has

75
00:04:33.930 --> 00:04:37.680
sort of at least three
missions. One is food, the

76
00:04:37.680 --> 00:04:40.260
other is drugs. And then
a tiny little sliver of

77
00:04:40.260 --> 00:04:42.450
that pie is medical devices.
So it doesn't get a

78
00:04:42.450 --> 00:04:47.790
lot of attention compared to
say pharmaceuticals. But what is

79
00:04:47.790 --> 00:04:50.760
interesting is like, if you
take something as simple as

80
00:04:50.760 --> 00:04:56.760
a surgical mask, that's actually
a transmission barrier. And so

81
00:04:56.820 --> 00:05:00.420
when we look at how
do you manufacture medical device,

82
00:05:00.420 --> 00:05:04.410
what you have to do
is understand the risk components

83
00:05:04.410 --> 00:05:07.500
of that. So it might
seem like a surgical mask

84
00:05:07.500 --> 00:05:12.240
is nothing but some cloth
or paper and elastics, but

85
00:05:12.480 --> 00:05:15.300
what the FDA does is
they go through and they

86
00:05:15.300 --> 00:05:18.960
make sure that the materials
that you're using are biocompatible,

87
00:05:18.960 --> 00:05:23.490
that you're not creating skin
rashes, that the filtration system

88
00:05:23.490 --> 00:05:27.630
is actually performing as expected.
And then there's important things

89
00:05:27.630 --> 00:05:31.260
about how is the product
packaged and what are the

90
00:05:31.920 --> 00:05:36.420
instructions it's called labeling? What
is the indications for use

91
00:05:36.870 --> 00:05:40.290
of the device? Are people
properly trained on how to

92
00:05:40.290 --> 00:05:43.080
use it and what those
risks are? And actually that's

93
00:05:43.140 --> 00:05:47.010
not an impossible barrier to
overcome, but it is a

94
00:05:47.010 --> 00:05:50.640
barrier that you have to
overcome from a legal perspective.

95
00:05:50.940 --> 00:05:54.780
That labeling concept is incredibly
important. We hear things about

96
00:05:54.780 --> 00:05:57.740
things being used off label
there's talks about being used

97
00:05:57.740 --> 00:06:01.640
right now off label medical
devices, durable medical equipment can

98
00:06:01.640 --> 00:06:04.190
also be used off label,
which is saying, we know

99
00:06:04.190 --> 00:06:07.310
it's safe generally as a
general extent, and you want

100
00:06:07.310 --> 00:06:09.470
to try it on this
thing. It is not formally

101
00:06:09.470 --> 00:06:11.480
labeled for you can go
and do that. I'm using

102
00:06:11.480 --> 00:06:14.390
a number of actually two
separate diabetes drugs right now

103
00:06:14.390 --> 00:06:17.390
that are for type two
diabetics. I'm using them off

104
00:06:17.390 --> 00:06:21.440
label, which means my doctor
knows that it's being used.

105
00:06:21.650 --> 00:06:24.530
The FDA knows that it's
being used, but I'm ultimately

106
00:06:24.530 --> 00:06:27.560
on my own, if it
goes, goes South. Right? Right.

107
00:06:27.580 --> 00:06:31.450
And that's, that's the challenge.
And if you are a

108
00:06:31.450 --> 00:06:34.480
medical device manufacturer, if you
are somebody that is manufacturing,

109
00:06:34.480 --> 00:06:37.600
something that is serving as
a medical device, if you

110
00:06:37.600 --> 00:06:41.020
are not clear about those
intentions, you can expose yourself

111
00:06:41.020 --> 00:06:45.940
to quite a lot of
liability. And for those who

112
00:06:45.940 --> 00:06:50.200
are lawyers, that liability can
be pretty, pretty severe in

113
00:06:50.200 --> 00:06:53.320
the United States. Well, certainly we
don't want anyone to get

114
00:06:53.320 --> 00:06:56.920
hurt. So it makes sense
to have regulation of a

115
00:06:56.950 --> 00:07:01.090
drugs, be hardware, and then
additionally software. But there have

116
00:07:01.090 --> 00:07:03.850
been times where things have,
have failed. Like things need

117
00:07:03.850 --> 00:07:06.670
to be regulated because people
could get killed. Right. And

118
00:07:06.670 --> 00:07:10.000
people have been. Yeah, absolutely.
So, you know, currently I

119
00:07:10.000 --> 00:07:13.570
work as a software consultant
and I'm fascinated by safety,

120
00:07:13.570 --> 00:07:17.770
critical software. I've worked in
it. And every domain that

121
00:07:17.770 --> 00:07:21.730
you can think of from
medical devices to automobiles. And

122
00:07:22.330 --> 00:07:25.420
one of the case studies
that we look at is

123
00:07:25.420 --> 00:07:29.710
this device called theoric 25,
Derek 25 is a historical

124
00:07:29.710 --> 00:07:34.330
case study where it was
a radiation beam machine back

125
00:07:34.330 --> 00:07:37.090
in the late seventies and
early eighties. And over the

126
00:07:37.090 --> 00:07:39.910
course of a number of
years, there were a handful

127
00:07:39.910 --> 00:07:43.300
of incidents where it created
an overdose and actually led

128
00:07:43.300 --> 00:07:48.670
to people dying from the
radiation beam. And this is

129
00:07:48.880 --> 00:07:51.940
widely believed to be one
of the first instances of

130
00:07:51.940 --> 00:07:56.560
software, killing somebody in the
wake of theoretic 25, all

131
00:07:56.560 --> 00:07:59.920
of these new rules and
how to write software for

132
00:07:59.920 --> 00:08:03.190
medical devices came about. So
in the decade that followed

133
00:08:03.790 --> 00:08:08.050
the FDA and investigated what
happened. And they met with

134
00:08:08.050 --> 00:08:10.600
experts and they met with
people who understand how to

135
00:08:10.600 --> 00:08:13.840
do this from other industries,
like the space industry, the

136
00:08:13.840 --> 00:08:18.310
aerospace industry folks from NASA,
and they created a series

137
00:08:18.310 --> 00:08:22.060
of medical device regulations for
software. And so that saying

138
00:08:22.060 --> 00:08:24.970
that safety rules are written
in blood in this case,

139
00:08:24.970 --> 00:08:28.210
literally holds true. There were
four people who died as

140
00:08:28.210 --> 00:08:30.910
a result of this. These
things are so important. There's

141
00:08:30.910 --> 00:08:34.150
so much discussion right now
about airplanes and their user

142
00:08:34.150 --> 00:08:37.150
interfaces. And there was a
recent thing about touchscreens where

143
00:08:37.390 --> 00:08:42.280
someone was changing interfaces from
switches and, and knobs to

144
00:08:42.280 --> 00:08:44.470
touch screens. We've seen that
as well in the missile

145
00:08:44.710 --> 00:08:47.890
defense and that, that missile
warning that went out in

146
00:08:47.890 --> 00:08:50.410
Hawaii, we trying to figure
out why that would set.

147
00:08:50.410 --> 00:08:52.090
And everyone was told and
texted that there was a

148
00:08:52.090 --> 00:08:54.760
missile warning. And it was
in fact, a poorly designed

149
00:08:54.760 --> 00:08:58.710
user that caused them to
click the wrong button. Software

150
00:08:58.710 --> 00:09:02.400
sits between humans and computers
and expresses intent. And it

151
00:09:02.400 --> 00:09:04.200
could be as something as
simple as a bug where

152
00:09:04.200 --> 00:09:06.330
they wrote the code wrong,
or it could be a

153
00:09:06.330 --> 00:09:11.310
UX that expressed intent incorrectly,
but the result is serious

154
00:09:11.310 --> 00:09:15.800
damage to humans. Yeah. And
there's a fascinating ProPublica series

155
00:09:15.800 --> 00:09:19.820
recently about a similar incident
where a touch screen device

156
00:09:19.820 --> 00:09:23.180
with improper training and so
on and so forth is

157
00:09:23.180 --> 00:09:26.780
believed to be behind the
incident where a us Navy

158
00:09:26.780 --> 00:09:30.290
ship collided with another vessel
at sea and, and the

159
00:09:30.290 --> 00:09:34.160
number of sailors lost their
lives. And actually theoric 25

160
00:09:34.160 --> 00:09:37.720
was a case of a
UX problem. There was a

161
00:09:37.730 --> 00:09:42.260
bit of a race condition
in the code that sat

162
00:09:42.290 --> 00:09:45.710
between the user and the
actual device and that race

163
00:09:45.710 --> 00:09:49.310
condition, which was linked to
the user interface. It had

164
00:09:49.310 --> 00:09:52.550
to be initiated. If you
got a certain error message

165
00:09:52.550 --> 00:09:55.070
and pressed a certain set
of keys with a certain

166
00:09:55.070 --> 00:09:57.830
timing. But what they did
is because they went to

167
00:09:57.830 --> 00:10:01.070
a software, they removed these
hardware interlocks in the device,

168
00:10:01.400 --> 00:10:04.010
and that's what led to
this overdose of radiation. So,

169
00:10:04.490 --> 00:10:06.200
you know, these are, these
are patterns that we see

170
00:10:06.200 --> 00:10:10.130
over and over and over
in the safety critical software.

171
00:10:10.880 --> 00:10:13.640
So how do we get
these devices then given that

172
00:10:13.640 --> 00:10:15.860
we know what all the
different things we just discussed

173
00:10:15.860 --> 00:10:18.590
that can go wrong. What
stands between us and using

174
00:10:18.590 --> 00:10:22.520
medical devices on humans? You
know, the regulation regulatory process

175
00:10:22.520 --> 00:10:26.390
is complex, but it is
solvable. Certainly there are ways

176
00:10:26.390 --> 00:10:29.630
that we can improve this
process. The FDA has a

177
00:10:29.630 --> 00:10:33.800
long way to go. They're
fairly slow at understanding how

178
00:10:33.800 --> 00:10:38.090
to deal with software, software,
development practices, things like that,

179
00:10:38.390 --> 00:10:41.690
but also the, we can
get better at writing software

180
00:10:41.690 --> 00:10:44.690
and safety, critical systems. I
think that some of the

181
00:10:44.780 --> 00:10:48.020
practices that we've learned and
developed from doing, you know,

182
00:10:48.020 --> 00:10:54.200
global carrier scale distributed systems,
we know what works, we

183
00:10:54.200 --> 00:10:57.860
know what reliability is. And
it's a challenge to take

184
00:10:57.860 --> 00:11:01.820
that those lessons and translate
them into an embedded systems

185
00:11:01.820 --> 00:11:06.380
world where you're not building
things that are dealing with,

186
00:11:06.590 --> 00:11:10.100
you know, millions of requests
per minute, but rather a

187
00:11:10.100 --> 00:11:12.350
small number of devices that
have to run in high

188
00:11:12.350 --> 00:11:16.130
reliability mode. But there are
still engineering practices that we

189
00:11:16.130 --> 00:11:19.700
can learn and apply to
those domains. But it's, it's

190
00:11:19.700 --> 00:11:22.910
something that will take years
to, to shift that entire

191
00:11:22.910 --> 00:11:26.390
industry to that. As, As
a diabetic, I've always been

192
00:11:26.390 --> 00:11:28.910
told for the last 25
years that the solution is

193
00:11:28.910 --> 00:11:32.330
coming five years from now.
And in every year they

194
00:11:32.330 --> 00:11:34.430
tell me it'll be five
more years. So I have

195
00:11:34.430 --> 00:11:36.890
found myself kind of knee
jerk saying, well, they should

196
00:11:36.890 --> 00:11:40.070
let us try things more
risky. They should let us

197
00:11:40.070 --> 00:11:44.360
be more risky. Is that
a solution to experiment more

198
00:11:44.360 --> 00:11:46.850
and let more people get
hurt? Or like, is, is

199
00:11:46.850 --> 00:11:49.310
this, you know how they're
saying that right now, it's

200
00:11:49.310 --> 00:11:51.200
going to be 18 months
before there's a vaccine for

201
00:11:51.200 --> 00:11:54.550
the current situation. Is this,
you can't just bang this

202
00:11:54.550 --> 00:11:56.770
out in a month or
two, should we be less

203
00:11:56.770 --> 00:12:00.990
regulation and more, I don't
know, capitalism, I don't think

204
00:12:00.990 --> 00:12:05.910
so. I think that, you
know, there's certain timeframes that

205
00:12:05.910 --> 00:12:09.990
need to happen. Like there's
certain that the risk calculus

206
00:12:10.050 --> 00:12:13.350
that we do when we
look at a drug or

207
00:12:13.350 --> 00:12:19.260
a device or any intervention,
has to be around waive

208
00:12:19.260 --> 00:12:22.890
waiting the, the public benefits
against the public harms. We

209
00:12:22.890 --> 00:12:28.890
have to understand what that
risk analysis is. And, you

210
00:12:28.890 --> 00:12:33.570
know, frankly, banging things out
is more likely to get

211
00:12:33.570 --> 00:12:36.390
people hurt in ways that
they don't expect. There's all

212
00:12:36.390 --> 00:12:41.730
sorts of secondary effects that
you can have, like if

213
00:12:41.730 --> 00:12:46.830
the vaccine is not effective
and you don't do your

214
00:12:46.830 --> 00:12:49.770
proper studies for it, it
could be that we start

215
00:12:49.770 --> 00:12:52.680
giving out vaccines that are
ineffective. Maybe they're, they're not

216
00:12:52.680 --> 00:12:56.070
harmful in and of themselves.
You know, they're not going

217
00:12:56.070 --> 00:12:59.340
to make you grow a
third eye or, you know,

218
00:13:00.330 --> 00:13:04.500
something like that, but maybe
they're just ineffective. And that

219
00:13:04.500 --> 00:13:07.140
creates a false sense of
security. And then we have

220
00:13:07.440 --> 00:13:10.470
another outbreak or, you know,
maybe they do cause cancer

221
00:13:10.470 --> 00:13:13.590
or maybe they do, you
know, have some other side

222
00:13:13.590 --> 00:13:15.840
effects. So those are the
things that we try to

223
00:13:16.440 --> 00:13:19.680
suss out. And unfortunately, some
of this stuff takes time

224
00:13:19.710 --> 00:13:21.750
and it takes time to
ramp up the production. We

225
00:13:21.750 --> 00:13:25.740
need to make sure that
the facilities that are making

226
00:13:26.010 --> 00:13:29.580
these drugs or these medical
devices, whatever it might be

227
00:13:30.300 --> 00:13:33.090
are operating up to standards.
There needs to be certain

228
00:13:33.270 --> 00:13:36.210
processes in place to be
able to track batches and

229
00:13:36.210 --> 00:13:41.070
manufacturing runs. There's something called
the current good manufacturing processes.

230
00:13:41.070 --> 00:13:45.630
The CGMP that governs the
ways in which a manufacturer

231
00:13:45.630 --> 00:13:51.180
has to abide by certain
auditing and traceability requirements when

232
00:13:51.180 --> 00:13:54.510
you build this stuff. So,
you know, as tempting as

233
00:13:54.510 --> 00:13:57.180
it is to just say,
Oh, all we need to

234
00:13:57.180 --> 00:13:58.800
do is throw a bunch
of three D printers at

235
00:13:58.800 --> 00:14:02.580
the problem. We really have
to be calm and say,

236
00:14:02.760 --> 00:14:05.490
you know, is this going
to actually make the current

237
00:14:05.490 --> 00:14:08.640
health crisis worse? Okay. So
it sounds like in software

238
00:14:08.640 --> 00:14:12.660
engineering terms, this isn't a
scrum, let's iterate as fast

239
00:14:12.660 --> 00:14:14.490
as we can in a
week. This is a waterfall

240
00:14:14.490 --> 00:14:18.270
process and requires getting it
correct in really, really getting

241
00:14:18.270 --> 00:14:22.050
it correct. Well, I think,
you know, I don't know

242
00:14:22.050 --> 00:14:24.030
that it has to be
a waterfall process, but it's

243
00:14:24.030 --> 00:14:28.320
not a scrum process. There,
there is an ability to

244
00:14:29.100 --> 00:14:32.190
operate in agile ways. It's
just, the pace is going

245
00:14:32.190 --> 00:14:34.800
to be much slower. And
so when we have things

246
00:14:34.800 --> 00:14:36.930
that take a long time,
what we need to do

247
00:14:36.930 --> 00:14:42.840
is understand how to efficiently
parallelize those processes and those

248
00:14:42.840 --> 00:14:49.860
research efforts and how to
distribute some of that capability

249
00:14:50.010 --> 00:14:52.430
and what is best way,
the smartest way to do

250
00:14:52.430 --> 00:14:55.970
it. Certainly we can work
in an agile way, but

251
00:14:56.570 --> 00:15:00.380
it does, it's not, I'm
building a website, right? You

252
00:15:00.380 --> 00:15:04.250
can't just, you can't break
something and then, you know,

253
00:15:04.250 --> 00:15:05.960
fix it based on what
breaks you actually have to

254
00:15:05.960 --> 00:15:08.920
get it right in the
first place. Yeah. I, when

255
00:15:08.920 --> 00:15:11.410
I, I, I have a
team here at my company

256
00:15:11.410 --> 00:15:13.510
that I, that I manage
and I've led teams before,

257
00:15:13.510 --> 00:15:15.490
as I know you have,
and I know that we,

258
00:15:15.490 --> 00:15:18.160
as smart tech, people believe
that we can solve anything

259
00:15:18.340 --> 00:15:20.560
with tech. And it's very
difficult to be put into

260
00:15:20.560 --> 00:15:22.480
a crisis and not be
able to say, well, why

261
00:15:22.480 --> 00:15:25.480
don't you just, you know,
and I encourage my team

262
00:15:25.540 --> 00:15:27.640
to not say just because
it's such a way of

263
00:15:27.640 --> 00:15:30.730
minimizing a problem that you
don't understand. I know that

264
00:15:30.730 --> 00:15:33.520
we're just spitballing here, but
this isn't a, why don't

265
00:15:33.520 --> 00:15:35.590
you just, this is a
time for us to let

266
00:15:35.590 --> 00:15:39.100
the experts be. Yeah. And
it's, I think it's frustrating,

267
00:15:39.100 --> 00:15:41.950
you know, that we were
seeing people like Elon Musk

268
00:15:41.950 --> 00:15:44.170
and, and James Dyson saying,
Oh, you don't, we're going

269
00:15:44.170 --> 00:15:45.670
to do, we're going to
build a bunch of ventilators.

270
00:15:45.670 --> 00:15:49.990
It's like, okay, first of
all, I admire the heck

271
00:15:50.020 --> 00:15:52.900
out of Elon Musk's vision
and what he is trying

272
00:15:52.900 --> 00:15:55.630
to do. And I don't
want a bunch of Elon

273
00:15:55.630 --> 00:15:58.750
Musk fans coming after me
for saying this. But the

274
00:15:58.750 --> 00:16:02.050
fact of the matter is
he has made a living

275
00:16:02.050 --> 00:16:08.350
off of doing N and
end around around many regulations

276
00:16:08.380 --> 00:16:11.950
in the auto industry. And
in other industries, I don't

277
00:16:11.950 --> 00:16:13.900
want him doing that. Like,
I don't want to be

278
00:16:13.900 --> 00:16:17.620
on a Elon Musk put
together in two weeks ventilator.

279
00:16:17.710 --> 00:16:19.810
You know what I mean?
It was the difference between

280
00:16:20.230 --> 00:16:24.400
certain death and possible life.
Sure. But we have not

281
00:16:24.430 --> 00:16:27.280
yet exhausted all of our
other options for that. And

282
00:16:27.280 --> 00:16:30.640
so, you know, James Dyson,
there was a headline, I'm

283
00:16:30.760 --> 00:16:32.980
saying he's built a low
cost ventilator, and he's going

284
00:16:32.980 --> 00:16:35.860
to build 15,000 units and
the British government saying, well,

285
00:16:35.860 --> 00:16:37.390
that's great, but you still
have to go through the

286
00:16:37.390 --> 00:16:41.950
regulatory process. So, you know,
we can fast track that,

287
00:16:41.950 --> 00:16:44.740
but let's get this going.
When you need to focus

288
00:16:44.740 --> 00:16:46.750
on building, do you want
to get bogged down by

289
00:16:46.750 --> 00:16:50.770
your database? Mongo DB is
an intuitive, flexible document database

290
00:16:50.770 --> 00:16:54.040
that lets you get to
building Mongo. DBS document model

291
00:16:54.040 --> 00:16:56.230
is a natural way to
represent data. So you can

292
00:16:56.230 --> 00:16:59.650
focus on what matters. Mongo
DB Atlas is the best

293
00:16:59.650 --> 00:17:03.010
way to use Mongo DB.
It's a global cloud database

294
00:17:03.010 --> 00:17:05.230
service that gives you all
of the developer productivity of

295
00:17:05.230 --> 00:17:08.980
Mongo DB. Plus the added
simplicity of a fully managed

296
00:17:08.980 --> 00:17:12.490
database service. You can get
started free with Mongo DB

297
00:17:12.490 --> 00:17:19.000
atlas@mongodb.com slash Atlas. So that
actually brings up an interesting

298
00:17:19.000 --> 00:17:20.920
question though. And I put
this only in my own

299
00:17:20.920 --> 00:17:24.130
context that I might better
understand. I have been asked

300
00:17:24.190 --> 00:17:26.860
as I am using an
open source artificial pancreas, which

301
00:17:26.860 --> 00:17:32.170
is a D a, a
recalled out of, out of

302
00:17:32.170 --> 00:17:36.970
warranty pump with a known
security issue, an insulin pump,

303
00:17:37.240 --> 00:17:41.740
and I'm using it with
unsupported on FDA approved software.

304
00:17:41.740 --> 00:17:45.100
So people say, aren't you
concerned that it will X,

305
00:17:45.100 --> 00:17:48.580
Y, Z kill you, but
I'm saying, I'm okay with

306
00:17:48.580 --> 00:17:52.890
that. I am consciously. And
with, you know, attention saying

307
00:17:53.040 --> 00:17:56.220
not doing it as worse,
you know, my uncontrolled diabetes

308
00:17:56.220 --> 00:17:58.560
is worse to me. The,
the, the, the result of

309
00:17:58.560 --> 00:18:01.650
that is worse than the
risk, but I'm, I'm able

310
00:18:01.650 --> 00:18:03.600
to make that decision while
someone who maybe needs to

311
00:18:03.600 --> 00:18:05.820
be put on a ventilator,
doesn't necessarily get to take

312
00:18:05.820 --> 00:18:08.250
that chance, sign that paper
to say, I'll try a

313
00:18:08.250 --> 00:18:11.580
James Dyson, three D printed
in a week rental later.

314
00:18:12.560 --> 00:18:15.230
Exactly. And so I think,
you know, when we talk

315
00:18:15.230 --> 00:18:18.470
about medical ethics, and this
is something that has a

316
00:18:18.470 --> 00:18:21.770
long and, and troubled history,
if you look at the

317
00:18:21.770 --> 00:18:26.030
history of modern medical ethics,
going back to the Nuremberg

318
00:18:26.060 --> 00:18:29.810
code in the late 1940s,
which came as a result

319
00:18:29.810 --> 00:18:34.850
of the doctor's trial in
Nuremberg of Karl Brandt and

320
00:18:34.850 --> 00:18:40.250
several other Nazi physicians, that
point number one of all

321
00:18:40.250 --> 00:18:43.160
of this is the informed
consent must be freely and

322
00:18:43.160 --> 00:18:47.120
willingly given by the research
subject. And you have the

323
00:18:47.120 --> 00:18:50.000
ability to create that consent
or to, to give that

324
00:18:50.000 --> 00:18:55.280
consent for what you're doing.
Our processes. Our social contract

325
00:18:55.940 --> 00:18:57.560
that we have is that
if I walk into a

326
00:18:57.560 --> 00:19:00.800
hospital or if I am
unconscious and brought into a

327
00:19:00.800 --> 00:19:04.460
hospital, I know the people
who brought me there, know

328
00:19:04.700 --> 00:19:08.300
my loved ones know that
that hospital is operating under

329
00:19:08.330 --> 00:19:11.960
a set of principles that
they're using devices that they

330
00:19:11.960 --> 00:19:14.150
know to be the safest,
that they can find that

331
00:19:14.150 --> 00:19:17.330
they're using practices that are
the safest, that they know

332
00:19:17.330 --> 00:19:20.150
that they're using staff that
is trained. And that is

333
00:19:20.150 --> 00:19:25.490
part of our social contract.
And when we start looking

334
00:19:25.490 --> 00:19:31.100
for reasons to breach that
social contract in the name

335
00:19:31.100 --> 00:19:34.910
of public health, I start
to get very worried because

336
00:19:34.910 --> 00:19:39.530
while it may seem benevolent,
now there's a lot of

337
00:19:39.530 --> 00:19:42.050
ways that this can go
wrong. And if you read

338
00:19:42.050 --> 00:19:45.440
the transcripts of the doctor's
trial, if you read that

339
00:19:45.440 --> 00:19:50.060
history, Carl Brandt believed that
what he was doing was

340
00:19:50.060 --> 00:19:54.020
in the public benefit. Of
course, his public benefit was

341
00:19:54.290 --> 00:19:59.360
an area nation purged of
disabled people and Jewish people

342
00:19:59.360 --> 00:20:02.960
and the Roman, the Sinti
people. And, and just about

343
00:20:02.960 --> 00:20:06.080
everybody else that was not,
you know, at Germanic and

344
00:20:06.080 --> 00:20:11.390
white. And we can very
easily slip into that in

345
00:20:11.390 --> 00:20:16.550
ways that we don't see,
just look at what hospitals

346
00:20:16.550 --> 00:20:20.300
are using, what equipment on
what patients we know that

347
00:20:20.300 --> 00:20:23.300
these are, there is inequality
in our medical system. And

348
00:20:23.300 --> 00:20:26.900
so this is all very,
very relevant, important stuff that

349
00:20:26.900 --> 00:20:28.790
we can't just sweep under
the rug and say, well,

350
00:20:28.790 --> 00:20:32.120
we have a global health
pandemic. It's time to relax

351
00:20:32.120 --> 00:20:35.390
these these standards of, and
to, you know, throw out

352
00:20:35.390 --> 00:20:40.460
this social contract. So if
we think about simpler things

353
00:20:40.460 --> 00:20:44.060
like masks, they're what you
call class two medical devices.

354
00:20:44.060 --> 00:20:46.160
A mask is not as
complicated as a ventilator, but

355
00:20:46.160 --> 00:20:50.440
it's still incredibly important. I
understand that the Dutch received

356
00:20:50.440 --> 00:20:52.990
a large shipment of masks,
but they chose not to

357
00:20:52.990 --> 00:20:54.880
use them because they felt
that they were not meeting

358
00:20:54.880 --> 00:20:58.170
the standards. That's a big,
that's a big deal, Right?

359
00:20:58.170 --> 00:21:01.710
And that was a situation
where the, a Chinese company

360
00:21:01.710 --> 00:21:06.800
sent something like 600, 600,000
masks to assist with the,

361
00:21:06.800 --> 00:21:11.340
the Corona pandemic in the
Netherlands and in Europe. And

362
00:21:11.340 --> 00:21:14.010
it turns out they were
not manufactured to standards. And

363
00:21:14.010 --> 00:21:18.000
these masks had actually been
distributed to frontline medical personnel.

364
00:21:18.000 --> 00:21:20.970
They were doctors and nurses
and hospitals using them. And

365
00:21:20.970 --> 00:21:25.290
they had to be recalled
because of that. And, you

366
00:21:25.290 --> 00:21:29.550
know, maybe again in a,
if there's a shortage, is

367
00:21:29.550 --> 00:21:33.570
something better than nothing. Maybe
I'm inclined to say yes,

368
00:21:33.600 --> 00:21:35.490
if I, if you had
to put me, you know,

369
00:21:35.910 --> 00:21:40.470
under the spotlight, but it
is still complicated. You mentioned

370
00:21:40.470 --> 00:21:44.790
that they're class two medical
devices in the United States just

371
00:21:44.790 --> 00:21:47.100
to give the listeners some
context to class two is

372
00:21:47.310 --> 00:21:50.550
sort of the, a moderate
risk category. Class. One is

373
00:21:50.800 --> 00:21:53.610
the least risk in class
three is the most risk.

374
00:21:53.970 --> 00:21:56.130
And so, you know, something
as simple as a, as

375
00:21:56.130 --> 00:21:59.790
a mask, it's actually the
same risk level as a

376
00:21:59.790 --> 00:22:03.810
mechanical ventilator. Wow. When it
goes bad, people get hurt

377
00:22:04.530 --> 00:22:07.440
in. That's why that is
classified as such. Yep. So

378
00:22:07.630 --> 00:22:11.820
those, those classifications are not
based on the complexity of

379
00:22:11.820 --> 00:22:13.860
the device or the cost
of the device, or the

380
00:22:13.860 --> 00:22:15.660
amount of research that has
to go into it. They're

381
00:22:15.660 --> 00:22:22.260
based on a risk analysis
on the potential harms that

382
00:22:22.260 --> 00:22:24.810
can happen if that device
fails or if it's used

383
00:22:24.810 --> 00:22:28.210
in properly. And so, you
know, if you're wearing an

384
00:22:28.210 --> 00:22:32.460
end 95 mask, if you're
wearing something that is supposed

385
00:22:32.460 --> 00:22:36.870
to filter our filter out
95% of particles under a

386
00:22:36.870 --> 00:22:40.320
certain size, there's a reason
that you're wearing that. If

387
00:22:40.320 --> 00:22:42.600
you didn't need to be,
to have that level of

388
00:22:42.600 --> 00:22:44.910
fine filtration, you might use
as something cheaper, like a

389
00:22:44.910 --> 00:22:47.280
surgical mask, which is also
still a class two medical

390
00:22:47.280 --> 00:22:50.910
device, but the risks here
are you catch a disease

391
00:22:51.060 --> 00:22:54.630
there, you can transmit a
disease to somebody it's over

392
00:22:54.630 --> 00:22:57.870
your face, there's choking hazards
or suffocation hazards. There's all

393
00:22:57.870 --> 00:23:00.900
sorts of stuff that you
don't even necessarily think about

394
00:23:00.900 --> 00:23:03.510
when you're just saying, Oh,
I need to cover my

395
00:23:03.510 --> 00:23:07.350
face. And so these are,
are actually quite important concerns.

396
00:23:07.800 --> 00:23:11.190
Well, you brought up Elon
Musk and Dyson who are,

397
00:23:11.760 --> 00:23:15.630
you know, certainly visionaries and
well thought of it from

398
00:23:15.630 --> 00:23:20.460
their technical perspectives. But what
about the smaller revolutionaries, like

399
00:23:20.850 --> 00:23:26.300
Yosef push pressure, the three
D printer? You know, the

400
00:23:26.580 --> 00:23:29.580
think, I think it's pronounced
presser. I'm sorry. Yeah. I

401
00:23:29.580 --> 00:23:32.190
wish I knew how to
pronounce his name, but, you

402
00:23:32.190 --> 00:23:35.280
know, I think that that
is great because one of

403
00:23:35.280 --> 00:23:39.150
the things that we can
do is focus on putting

404
00:23:39.180 --> 00:23:43.320
some of this sort of
Homebrew energy away from supporting

405
00:23:43.440 --> 00:23:47.240
the frontline medical personnel and
more towards what can we

406
00:23:47.240 --> 00:23:50.300
do to help people in
less risky scenarios. So what

407
00:23:50.300 --> 00:23:55.190
can we do to support
people, trying to go out

408
00:23:55.190 --> 00:23:56.900
and about and do their
business, or who might have

409
00:23:56.900 --> 00:24:00.500
to go out in public
because they are, you know,

410
00:24:00.500 --> 00:24:03.440
a grocery store clerk or,
or they're a delivery driver

411
00:24:03.440 --> 00:24:05.960
or something like that, right?
Those are the ways that

412
00:24:05.960 --> 00:24:08.450
we can really help. So,
you know, we, what we

413
00:24:08.450 --> 00:24:12.110
should be doing, it's, it's
a resource allocation problem. The

414
00:24:12.110 --> 00:24:15.080
hospitals need the hospital grade
stuff. We don't need the

415
00:24:15.080 --> 00:24:17.210
hospital grade stuff, even if
it would be nice to

416
00:24:17.210 --> 00:24:19.430
have. So I do, I
do think that some of

417
00:24:19.430 --> 00:24:21.620
these three D printing initiatives
are great. And in my

418
00:24:21.620 --> 00:24:27.710
community, there's a, an initiative
of building face shields from,

419
00:24:28.490 --> 00:24:31.910
you know, sort of scavenged
and other equipment. And it's

420
00:24:33.140 --> 00:24:36.230
not necessarily for the hospitals,
but it's for other people

421
00:24:36.230 --> 00:24:39.680
who are in areas of
need. And we're distributing it

422
00:24:39.680 --> 00:24:42.920
to people who are working
in grocery stores and stuff

423
00:24:42.920 --> 00:24:45.200
like that, so that they
can continue to provide the

424
00:24:45.200 --> 00:24:49.060
essential services that we all
need. That is a, that's

425
00:24:49.060 --> 00:24:51.100
a hard thing to hear,
I think, but I think

426
00:24:51.100 --> 00:24:53.890
that it is the right
thing, you know, is it,

427
00:24:53.920 --> 00:24:56.200
you know, Hey, I'm a
smart technologist. Maybe I should

428
00:24:56.200 --> 00:24:57.910
drop everything and try to
three D print a new

429
00:24:57.910 --> 00:25:01.120
ventilator in my, in my
garage because, you know, I

430
00:25:01.120 --> 00:25:05.170
alone can fix it is
exciting and it gives a

431
00:25:05.170 --> 00:25:08.050
sense of urgency, but it's
also rooted in a sense

432
00:25:08.050 --> 00:25:10.960
of narcissism. But if I
can help my local small

433
00:25:10.960 --> 00:25:13.990
business, if I can make
a website for my, my

434
00:25:13.990 --> 00:25:15.700
barber or the local bagel
shop, that's going to go

435
00:25:15.700 --> 00:25:18.160
out of business because they
don't have a technologist. Those

436
00:25:18.160 --> 00:25:20.080
are things I do know
how to make, you know,

437
00:25:20.080 --> 00:25:23.230
those are ways I can
help my local community, helping

438
00:25:23.230 --> 00:25:25.990
a school, get online to
teach classes because they don't

439
00:25:25.990 --> 00:25:28.750
have an it department to
do, to do video calls

440
00:25:29.050 --> 00:25:33.340
is something that is desperately
important and desperately needed, but

441
00:25:33.340 --> 00:25:37.060
absolutely not gonna kill somebody.
Yeah, well, at least we

442
00:25:37.060 --> 00:25:38.890
hope so. And I think
that there's a lot of,

443
00:25:39.460 --> 00:25:41.020
a lot of great ways
that we can help as

444
00:25:41.020 --> 00:25:44.440
technologists, right? If you want
to build a ventilator, look,

445
00:25:44.440 --> 00:25:46.870
I'm sure that the ventilator
companies are hiring right now.

446
00:25:46.900 --> 00:25:50.470
Cause they're about to get
$2 billion worth of orders. So

447
00:25:50.470 --> 00:25:54.220
go like, and that's not
being facetious. If you want

448
00:25:54.220 --> 00:25:57.910
to do that, go do
that. Technologists who can bring

449
00:25:57.910 --> 00:26:02.230
their software engineering skills from
this very high paced web

450
00:26:02.440 --> 00:26:06.970
distributed systems world and bring
those skills into that sort

451
00:26:06.970 --> 00:26:09.250
of different world of technology
development. I think that's a

452
00:26:09.250 --> 00:26:11.470
good thing. And there are
people that we definitely need

453
00:26:11.470 --> 00:26:14.470
people who can do that,
but if you want to

454
00:26:14.470 --> 00:26:18.490
help right now and do
something immediate, the USDS recently

455
00:26:18.550 --> 00:26:22.240
at the United States, digital service
recently shared a tweet where

456
00:26:22.240 --> 00:26:27.010
they're looking for like 2,500
volunteers, I'm doing technical coordination

457
00:26:27.010 --> 00:26:32.290
and other work communities need
people to help manage technology.

458
00:26:32.290 --> 00:26:35.800
And sometimes it's as simple
as just handling a spreadsheet.

459
00:26:35.980 --> 00:26:38.890
We need that more than
we need somebody to try

460
00:26:38.890 --> 00:26:42.520
to three D print a
valve that is untested and

461
00:26:42.520 --> 00:26:46.020
unproven. That is really significant.
Like it doesn't, it feels

462
00:26:46.020 --> 00:26:48.810
like the only thing we
can do sometimes is three

463
00:26:48.810 --> 00:26:51.990
D printed Val, because we
are just desperately grasping for

464
00:26:52.350 --> 00:26:55.200
something to be useful. But
I'm looking here at the

465
00:26:55.200 --> 00:26:57.720
U S digital response tweet
that says, well, what are

466
00:26:57.720 --> 00:27:01.170
these people working on? It
could be an ML engineer

467
00:27:01.170 --> 00:27:04.320
using OCR to pull fields
out, to help application processing,

468
00:27:04.320 --> 00:27:08.310
to help on internationalization, to
translate things into local languages.

469
00:27:08.310 --> 00:27:10.140
Like you might be able
to look at that list

470
00:27:10.140 --> 00:27:12.300
of things and say, Oh,
I'm a front end developer.

471
00:27:12.300 --> 00:27:15.360
I can help my state,
my municipality in some way

472
00:27:15.780 --> 00:27:19.410
that is still frontline work
and truly important. But like

473
00:27:19.410 --> 00:27:23.130
you said, not pushing the
limits of, of health ethics.

474
00:27:23.490 --> 00:27:25.590
Totally. And I think that
those are, those are the

475
00:27:25.590 --> 00:27:28.200
most important things to do
right now. That's what gets

476
00:27:28.200 --> 00:27:31.290
us through a crisis, right?
Community gets us through crises.

477
00:27:33.270 --> 00:27:35.280
So what we should be
focusing on is building up

478
00:27:35.280 --> 00:27:39.300
our community first. Now the
U S digital response is

479
00:27:39.300 --> 00:27:42.870
former us deputy CTOs. So
this is an organ, it's

480
00:27:42.870 --> 00:27:45.180
not the government properly, but
it's people who have been

481
00:27:45.180 --> 00:27:48.570
working in and around the,
the government. Yeah. So I

482
00:27:48.600 --> 00:27:52.470
don't know the entire background
of that, that organization, but

483
00:27:52.500 --> 00:27:55.260
I know that it is
closely related to some of

484
00:27:55.260 --> 00:28:00.760
the government sort of digital
re modernization efforts, 18 <inaudible>

485
00:28:00.760 --> 00:28:04.860
and all of that, trying
to bring the sort of

486
00:28:04.950 --> 00:28:07.830
very slow, slow moving ship.
That is the federal government's

487
00:28:07.830 --> 00:28:11.910
technology services into the modern
world and getting people to

488
00:28:12.750 --> 00:28:14.760
learn how to do that
the right way. And then

489
00:28:14.760 --> 00:28:16.290
I'm going to make sure
that I put links to

490
00:28:16.290 --> 00:28:18.870
all of this in the
show notes, as well as

491
00:28:18.870 --> 00:28:23.520
everything that we talked about,
the thera 25 report, Dyson,

492
00:28:23.520 --> 00:28:25.350
Elon, all of these different
folks, as well as some

493
00:28:25.350 --> 00:28:28.170
of the interesting stories like
the Chinese mask being recalled.

494
00:28:28.560 --> 00:28:31.590
And I think also, as
you mentioned to me, before

495
00:28:31.590 --> 00:28:33.630
we started the call, just
reaching out to your community,

496
00:28:33.630 --> 00:28:35.790
helping the community out, making
sure that your neighbors are

497
00:28:35.790 --> 00:28:39.570
okay and making sure that
the people in your area,

498
00:28:39.600 --> 00:28:42.930
whether they be elderly or
immunocompromised have what they need

499
00:28:42.930 --> 00:28:45.030
is also a fundamental way
that we can do to

500
00:28:45.030 --> 00:28:48.660
help. Absolutely. And hopefully this
will inspire some people to

501
00:28:48.660 --> 00:28:51.660
do that. And I'd love
to hear what everyone comes

502
00:28:51.660 --> 00:28:54.040
up with and how they
can help. Fantastic. Well, thank

503
00:28:54.050 --> 00:28:57.060
you so much. <inaudible> for
chatting with me today. Thanks

504
00:28:57.060 --> 00:28:59.790
for having me. This has
been another episode of Hanselminutes

505
00:28:59.850 --> 00:29:13.370
and we'll see <inaudible>.

