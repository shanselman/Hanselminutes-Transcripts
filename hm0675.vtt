WEBVTT FILE

1
00:00:00.150 --> 00:00:02.520
Would you like to write
code faster and smarter with

2
00:00:02.520 --> 00:00:06.030
rich code completion and clever
code analysis, find anything and

3
00:00:06.030 --> 00:00:08.820
a solution instantly. What if
you could easily explore and

4
00:00:08.820 --> 00:00:12.780
run tests, work with good
material or TFS seamlessly and

5
00:00:12.780 --> 00:00:14.970
refactor in a few clicks,
all of this or more

6
00:00:14.970 --> 00:00:18.540
is available in jet brains
writer, a.net ID for windows,

7
00:00:18.540 --> 00:00:22.140
Mac, and Linux. Try it
free for 30 days. Get

8
00:00:22.140 --> 00:00:43.310
Ryder today@ouridride.net. That's Ryder IDE
<inaudible>. So Scott Hanselman, this

9
00:00:43.310 --> 00:00:45.530
is another episode of Hansel
minutes. And today I'm talking

10
00:00:45.530 --> 00:00:48.440
with Jeremy boy, he's a
CTO at Ray gun and

11
00:00:48.440 --> 00:00:52.460
an expert on all things
scale and APM. What is,

12
00:00:52.460 --> 00:00:54.920
what is APM? I hear
this a lot that I,

13
00:00:54.920 --> 00:00:59.000
Scott, thanks for having me.
Well, APM stands for application

14
00:00:59.030 --> 00:01:02.690
performance monitoring or application performance
management, depending on which flavor

15
00:01:02.690 --> 00:01:06.770
you take, really, in a
nutshell, it's about looking at

16
00:01:06.770 --> 00:01:10.910
server side performance. How, what
is your application actually doing?

17
00:01:10.910 --> 00:01:14.630
And an interesting sort of
way of thinking about this

18
00:01:14.630 --> 00:01:18.950
is that when we build
web applications, for example, we

19
00:01:18.950 --> 00:01:21.620
load the site and we
get really good data in

20
00:01:21.620 --> 00:01:24.920
the browser, actually these days
about what is happening with

21
00:01:24.920 --> 00:01:28.070
a request. And what you
generally find is that the

22
00:01:28.070 --> 00:01:30.950
longest time is waiting for
things to come back from

23
00:01:30.950 --> 00:01:33.590
the server, right? The code
that you wrote just takes

24
00:01:33.590 --> 00:01:37.040
time to execute and you
often wonder what what's going

25
00:01:37.040 --> 00:01:39.050
on down there. What, why
is it taking so long?

26
00:01:39.050 --> 00:01:41.990
Is it a bad query?
Is it some bad code

27
00:01:41.990 --> 00:01:44.510
that I wrote? And so
IPM is all about trying

28
00:01:44.510 --> 00:01:47.810
to demystify that really give
you the insights into what's

29
00:01:47.810 --> 00:01:50.750
going on down there and
more specifically, what is it

30
00:01:50.750 --> 00:01:52.880
that could be a problem
that you could actually then

31
00:01:53.060 --> 00:01:56.150
take some action on and
fix and improve the situation.

32
00:01:57.250 --> 00:01:59.990
I might be making myself
look bad or giving away

33
00:01:59.990 --> 00:02:04.280
secrets or not good secrets.
But 20 years ago, when

34
00:02:04.280 --> 00:02:07.670
I was doing really large
financial services system, at least

35
00:02:07.670 --> 00:02:10.280
large for the, for the
late nineties, early two thousands,

36
00:02:10.820 --> 00:02:13.490
we were still spending a
lot of time, parsing logs,

37
00:02:13.490 --> 00:02:16.760
running log parsers, sucking logs
into SQL server and trying

38
00:02:16.760 --> 00:02:18.710
to figure out what was
going on. And we would

39
00:02:18.710 --> 00:02:22.190
do these things much like
forensically. We could tell you

40
00:02:22.190 --> 00:02:25.550
what happened afterwards, but there
was very little what's happening,

41
00:02:25.550 --> 00:02:28.580
right? This moment going on.
When, when did that start

42
00:02:28.580 --> 00:02:31.820
to change? That's right. And
I remember those days as

43
00:02:31.820 --> 00:02:34.430
well, and I'm actually pretty
glad that we've moved past

44
00:02:34.430 --> 00:02:36.680
a lot of that when,
when the sort of changed

45
00:02:36.680 --> 00:02:38.540
in my opinion. And I,
I think has really, when

46
00:02:38.540 --> 00:02:44.120
we saw bandwidth really increase
and, and PayPal, particularly for

47
00:02:44.150 --> 00:02:47.720
hosting environments and for getting
access to the status, bandwidth

48
00:02:47.720 --> 00:02:51.080
became less of a problem.
And also the proliferation of

49
00:02:51.080 --> 00:02:53.750
the cloud, which allowed us
to really ramp up resources

50
00:02:53.750 --> 00:02:56.780
to meet the sort of
scale challenge that you're faced

51
00:02:56.780 --> 00:03:00.580
with dealing with increasing volumes
of data. Typically when you

52
00:03:00.580 --> 00:03:04.270
start measuring things and increasing
the smaller and smaller level,

53
00:03:05.530 --> 00:03:07.640
this just as a bit
of a tangent, I guess

54
00:03:07.930 --> 00:03:10.210
one of the interesting things
that we sort of found

55
00:03:10.210 --> 00:03:14.710
when we got into the
outpatient performance and space is

56
00:03:15.550 --> 00:03:18.550
what's actually going on under
the hood. And as it

57
00:03:18.550 --> 00:03:21.160
turns out, there's an amazing
amount of things going on

58
00:03:21.160 --> 00:03:23.200
under the hood. It kind
of reminded me a little

59
00:03:23.200 --> 00:03:28.300
bit when I was younger,
you read scientific American or

60
00:03:28.300 --> 00:03:30.580
something like that. And, and,
you know, learn that, Oh,

61
00:03:31.030 --> 00:03:33.190
the low, the, the level
of the atom, there's another

62
00:03:33.190 --> 00:03:36.760
level. And it's kind of
like that with the code

63
00:03:36.760 --> 00:03:39.730
that we write. And so
as we delve down, you

64
00:03:39.730 --> 00:03:42.400
know, even as simple program,
like how I world, you

65
00:03:42.400 --> 00:03:46.450
know, console dot Rightline hello
world, even though on the

66
00:03:46.450 --> 00:03:50.020
surface that only looks like
it would take two medicals,

67
00:03:50.050 --> 00:03:54.010
you know, enters Maine enters,
console dot Rightline and exits.

68
00:03:54.880 --> 00:03:57.670
There's actually hundreds of underlying
calls that go on in

69
00:03:57.670 --> 00:04:01.510
the.net framework to actually support
that. And so as you

70
00:04:01.510 --> 00:04:03.280
start to kind of measure
down to that level, the

71
00:04:03.280 --> 00:04:06.910
amount of data that you
can start, you know, generating

72
00:04:06.910 --> 00:04:11.830
and interpreting starts to really
mess up. And I think,

73
00:04:11.980 --> 00:04:13.750
you know, in the, in
the past, we were never

74
00:04:13.750 --> 00:04:19.000
really able to take onboard
all of that data all

75
00:04:19.000 --> 00:04:21.430
at once. You know, we
couldn't put it through the

76
00:04:21.430 --> 00:04:24.520
network fast enough, the machines
that we had access to

77
00:04:24.730 --> 00:04:27.970
just simply weren't fast enough
to process that we could

78
00:04:27.970 --> 00:04:30.700
do, you know, batch processing
or a lot of offline

79
00:04:30.700 --> 00:04:33.670
processing and crunch those numbers
over time. But we never

80
00:04:33.670 --> 00:04:35.560
really had access to it
in the way that we

81
00:04:35.560 --> 00:04:38.170
could look at the stuff
in real time. And I

82
00:04:38.170 --> 00:04:42.070
think between the cloud, between
that, that sort of increase

83
00:04:42.070 --> 00:04:45.400
in bandwidth, we've been able
to start unlocking some of

84
00:04:45.400 --> 00:04:48.420
these new realms that exist
below the surface. Yeah. I

85
00:04:48.420 --> 00:04:51.030
remember in production, we used
to worry about things like,

86
00:04:51.030 --> 00:04:52.680
well, you don't want to
turn the logging on and

87
00:04:52.680 --> 00:04:56.070
production. It's certainly not on
a verbose or diagnostic because

88
00:04:56.070 --> 00:04:58.950
you're going to be filling
up the disc or filling

89
00:04:58.950 --> 00:05:01.740
up the pipe or whatever.
Like if you're doing aggressive

90
00:05:01.740 --> 00:05:04.800
logging, you can, you know,
the perception was at least

91
00:05:04.800 --> 00:05:07.560
when I was starting out
that you're not scaling if

92
00:05:07.560 --> 00:05:09.780
you're doing all of these
logging, but do we have

93
00:05:09.780 --> 00:05:12.270
enough perf and enough pipe
now that we can be

94
00:05:12.270 --> 00:05:14.670
a lot more verbose in
our logging? Oh, you sure

95
00:05:14.670 --> 00:05:17.460
can fair to say, there's
always a trade off for

96
00:05:17.460 --> 00:05:20.760
these things. I mean, it's
interesting because it certainly, when

97
00:05:20.760 --> 00:05:23.550
you delve into this realm,
you know, performance is becoming

98
00:05:23.550 --> 00:05:25.860
much more of a concern
for you, you know, for

99
00:05:25.860 --> 00:05:29.190
people who are looking at
APM solutions, you know, a

100
00:05:29.190 --> 00:05:31.200
big question on their mind
is how can I improve

101
00:05:31.200 --> 00:05:34.890
performance of my system? And
so, you know, one of

102
00:05:34.890 --> 00:05:37.440
the things you don't want
us to do necessarily degrade

103
00:05:37.440 --> 00:05:40.080
the system by putting in
some sort of invasive approach,

104
00:05:40.110 --> 00:05:42.810
like you mentioned, the logging,
which, you know, that will

105
00:05:42.810 --> 00:05:45.270
generate a lot of IO.
So that, that would hamper

106
00:05:45.270 --> 00:05:50.190
things if that's not managed
properly. So we are able

107
00:05:50.190 --> 00:05:54.120
to really sort of solve
this now, partially because machines

108
00:05:54.120 --> 00:05:56.580
are a little bit faster,
we've got better resources, but

109
00:05:56.580 --> 00:05:59.960
also we're now offloading that
data, not necessarily locally, but

110
00:06:00.350 --> 00:06:02.930
you know, through a network,
through to the cloud and

111
00:06:03.530 --> 00:06:05.600
that, you know, again, that
sort of couples with that

112
00:06:05.600 --> 00:06:07.580
bandwidth story, we've got the
ability to just kind of

113
00:06:07.580 --> 00:06:11.030
just send vast amounts, more
data than we would have

114
00:06:11.030 --> 00:06:13.700
thought about in the past
as being sort of real

115
00:06:13.970 --> 00:06:17.160
or possible. Right. So then
you're saying that the, the

116
00:06:17.190 --> 00:06:20.560
simplistic perspective that I was
doing 20 years ago was

117
00:06:20.860 --> 00:06:24.430
logging or maybe log shipping,
but now it's events, it's

118
00:06:24.430 --> 00:06:27.220
exceptions, it's internal, and it's
how deep you want to

119
00:06:27.220 --> 00:06:29.740
go in the stack. And
then you're offloading all of

120
00:06:29.740 --> 00:06:31.420
that, get it off of
the machine as quickly as

121
00:06:31.420 --> 00:06:33.250
possible and into some kind
of a pipeline or an

122
00:06:33.250 --> 00:06:37.000
ingestion pipeline. That's exactly right.
Yeah. I mean, so conceptually

123
00:06:37.000 --> 00:06:39.940
how our sort of approach
works is that we, we

124
00:06:40.330 --> 00:06:45.400
say for.net profile, there's profiling
API APIs and.net, which for

125
00:06:45.400 --> 00:06:48.460
anyone who would love a
good little adventure, a bit

126
00:06:48.460 --> 00:06:52.420
of a geek adventure, I
can highly recommend actually looking

127
00:06:52.420 --> 00:06:54.820
at into the profiling APIs,
just to learn a little

128
00:06:54.820 --> 00:06:57.010
bit more about how the
darknet framework actually works. It's

129
00:06:57.010 --> 00:07:00.640
really enlightening quick, I guess,
quick sort of example of

130
00:07:00.640 --> 00:07:04.390
that. As you know, going
back to my mention of

131
00:07:04.840 --> 00:07:08.320
under the hood, there's actually
hundreds of these medicals happening

132
00:07:08.320 --> 00:07:10.870
on a, on a simple
program, even like, hello world,

133
00:07:11.530 --> 00:07:13.900
the hello world example for
say the full framework would

134
00:07:13.900 --> 00:07:18.040
generate about two, 200 odd
method calls under the hood

135
00:07:18.580 --> 00:07:21.760
where, and you don't think
about this it's things like,

136
00:07:21.790 --> 00:07:24.730
you know, system, not globalization
because it's writing to a

137
00:07:24.730 --> 00:07:27.070
stream which then goes to
some output source, which has

138
00:07:27.070 --> 00:07:31.300
to be formatted for the
local culture. It's a stream.

139
00:07:31.300 --> 00:07:32.890
So it's got a lot
of mechanics under the hood

140
00:07:32.890 --> 00:07:36.940
there. So all of that
is, you know, quite interesting

141
00:07:36.940 --> 00:07:38.680
to understand how it works.
And when you sort of

142
00:07:38.710 --> 00:07:41.200
get down to that level,
we suddenly realized, well, actually,

143
00:07:41.230 --> 00:07:43.300
there's, you know, there's a
lot going on here and

144
00:07:43.300 --> 00:07:45.790
there's a lot I could
potentially control and manage the

145
00:07:45.790 --> 00:07:49.540
performance of, and that sort
of, you know, we learned

146
00:07:49.540 --> 00:07:52.120
a lot of that through
building an APM. So, and

147
00:07:52.120 --> 00:07:54.740
then sort of that gave
us new insights, I guess,

148
00:07:55.250 --> 00:07:57.760
a new level of kind
of understanding of how things

149
00:07:57.760 --> 00:08:00.340
work and where the optimizations
might be able to be

150
00:08:00.340 --> 00:08:04.120
gained potentially by looking at
how the sort of framework

151
00:08:04.150 --> 00:08:06.640
itself has actually been built.
You know, we're quite lucky

152
00:08:06.640 --> 00:08:09.250
these days with the core
CLR, the work that's been

153
00:08:09.250 --> 00:08:13.240
going on in.net core because
that's in the open and,

154
00:08:13.270 --> 00:08:15.490
you know, a big focus
and.net core has been on

155
00:08:15.490 --> 00:08:19.000
improving performance of the framework.
So I, you know, I

156
00:08:19.030 --> 00:08:21.190
do a lot of watching
of the commits that go

157
00:08:21.190 --> 00:08:25.090
into the.net core. Positories often
just to kind of look

158
00:08:25.090 --> 00:08:27.940
at where things being tuned
and how, what are the

159
00:08:27.940 --> 00:08:30.580
techniques that are being used
to tune, you know, performance

160
00:08:30.600 --> 00:08:33.070
and the framework itself. Cause
it's got a lot of

161
00:08:33.070 --> 00:08:35.680
time. Those techniques were actually
transposable to the code that

162
00:08:35.680 --> 00:08:38.680
you might write, particularly when,
again, you're looking at your

163
00:08:38.680 --> 00:08:40.570
system and you're thinking, well,
you know, this area is

164
00:08:40.570 --> 00:08:44.920
slow, you've delved into a
specific sort of view of

165
00:08:44.920 --> 00:08:46.660
it to say, right, well,
it's this method or it's

166
00:08:46.660 --> 00:08:48.850
this kind of our rhythm
that we were operating over

167
00:08:48.850 --> 00:08:50.680
that sort of not running
as well as it could.

168
00:08:51.070 --> 00:08:52.870
What are our approaches that
we could look at to

169
00:08:52.870 --> 00:08:55.980
tune the performance here? So
know we applied a lot

170
00:08:55.980 --> 00:08:58.620
of that and our ingestion
pipeline, because, you know, as

171
00:08:58.800 --> 00:09:01.170
you kind of mentioned, you
know, that there's a potential

172
00:09:01.170 --> 00:09:03.810
to just generate a, an
amazing amount of data by

173
00:09:04.020 --> 00:09:07.770
sort of observing what's going
on and a process. And,

174
00:09:07.770 --> 00:09:09.570
you know, we have to
deal with that data. And,

175
00:09:09.570 --> 00:09:11.940
you know, as sort of
data comes into our system,

176
00:09:11.940 --> 00:09:13.620
we have to kind of
take a look at it,

177
00:09:13.620 --> 00:09:16.200
figure out what it, what
it represents. We do a

178
00:09:16.200 --> 00:09:20.280
lot of work in terms
of kind of rationalizing the

179
00:09:20.280 --> 00:09:22.890
view of what happened in
the program and presenting that

180
00:09:22.890 --> 00:09:25.660
nicely, for example, using a
flame chat to, to a

181
00:09:25.660 --> 00:09:28.530
developer so they can better
understand and sort of focus

182
00:09:28.530 --> 00:09:30.990
in on what is it
that really is gonna make

183
00:09:30.990 --> 00:09:34.490
a difference to improve in
my system. How important would

184
00:09:34.490 --> 00:09:36.710
it be then though, to
not look at some of

185
00:09:36.710 --> 00:09:38.660
those events? I mean, like
you really want to monitor

186
00:09:39.140 --> 00:09:41.840
what matters and like there's
a joke I heard on

187
00:09:41.840 --> 00:09:45.290
Twitter recently said that the
biggest crime that the C

188
00:09:45.290 --> 00:09:47.990
programming language ever did was
that they convinced the world

189
00:09:47.990 --> 00:09:51.050
there wasn't a runtime. So
someone might hear you say,

190
00:09:51.050 --> 00:09:53.660
well, you know, there's like
2000 things happening underneath console

191
00:09:53.660 --> 00:09:57.890
dot Rightline now.net sucks, but
console dot Rightline, you know,

192
00:09:57.890 --> 00:10:00.500
it doesn't get even close
to the metal, no matter

193
00:10:00.500 --> 00:10:02.780
what language you're writing it.
And there's always some thing

194
00:10:02.780 --> 00:10:04.970
underneath, but do they really
matter if I'm trying to

195
00:10:04.970 --> 00:10:08.300
do hello world at scale,
I probably could lose some

196
00:10:08.300 --> 00:10:11.540
of those events. Yep. And
you know, you always have

197
00:10:11.540 --> 00:10:13.490
to put this stuff in
perspective, you know, you can,

198
00:10:13.580 --> 00:10:18.650
you could optimize the hell
out of anything, but you

199
00:10:18.650 --> 00:10:20.450
have to kind of put
it in perspective of what

200
00:10:20.480 --> 00:10:23.120
we are. What's gonna make
the best impact for the

201
00:10:23.120 --> 00:10:25.190
objectives I'm trying to reach
with the system. You know,

202
00:10:25.190 --> 00:10:27.050
is it, is it the
effect that I want my

203
00:10:27.050 --> 00:10:30.950
customers to have a certain
experience, net infers, a certain

204
00:10:30.950 --> 00:10:33.350
load time, which infers that
I need to kind of

205
00:10:33.350 --> 00:10:37.190
target performance on certain queries
to, to meet certain SLS.

206
00:10:37.190 --> 00:10:39.800
And generally I'll focus my,
if it's there, I'm not

207
00:10:39.800 --> 00:10:42.740
going to focus my efforts
necessarily on, you know, shaving

208
00:10:42.740 --> 00:10:46.400
off another few nanoseconds off
this particular function. So the

209
00:10:46.400 --> 00:10:50.180
context certainly matters. And again,
you know, a big part

210
00:10:50.180 --> 00:10:52.730
of what our job is
really is to try and

211
00:10:52.730 --> 00:10:56.060
highlight where is it that
the big wins are? Where

212
00:10:56.060 --> 00:10:59.300
are you going to gain
performance to try and meet

213
00:10:59.300 --> 00:11:01.760
those objectives that you've got
about what your system should

214
00:11:01.760 --> 00:11:03.920
be doing and how your
customers should be experiencing it?

215
00:11:04.460 --> 00:11:06.800
Hmm. What about some of
the, like if you think

216
00:11:06.800 --> 00:11:08.990
about it from a more
philosophical perspective, I'd like to

217
00:11:08.990 --> 00:11:11.390
think about like the Heisenberg
uncertainty principle that I can

218
00:11:11.390 --> 00:11:13.730
observe something and tell you
where it is or how

219
00:11:13.730 --> 00:11:17.600
fast it's going. But not
both. When we observe systems

220
00:11:17.600 --> 00:11:21.170
large systems like this, when
we instrument them, are, are

221
00:11:21.270 --> 00:11:23.540
we taking a chance that
it might not behave the

222
00:11:23.540 --> 00:11:25.520
same way it did because
we don't want to say,

223
00:11:25.520 --> 00:11:27.920
well, it worked on my
machine or worked before I

224
00:11:28.160 --> 00:11:32.540
plugged in an APM solution.
Yeah. Yeah. Certainly that's always

225
00:11:32.540 --> 00:11:35.300
a concern. Another thing that
comes comes into play is

226
00:11:35.300 --> 00:11:38.900
that, you know, isolated observations
are always just going to

227
00:11:38.900 --> 00:11:40.520
be that they're just going
to be a snapshot of

228
00:11:40.520 --> 00:11:43.070
the activity and given point
in time. And that doesn't

229
00:11:43.070 --> 00:11:46.250
necessarily mean that that's how
the, you know, the rest

230
00:11:46.250 --> 00:11:48.860
of the, the requests or
the rest of the interactions

231
00:11:48.860 --> 00:11:52.220
with that particular method or
particular end point are going

232
00:11:52.220 --> 00:11:56.020
to always behave. And so
again, it's about building up

233
00:11:56.020 --> 00:11:58.270
a big picture of this
over time. You know, the

234
00:11:58.300 --> 00:12:01.450
good thing about putting in
a solution like this is

235
00:12:01.450 --> 00:12:04.330
that, and having it kind
of observing for longer periods

236
00:12:04.330 --> 00:12:06.160
of time, as you build
up a bit of view,

237
00:12:06.220 --> 00:12:09.040
a better holistic view of
what's going on in the

238
00:12:09.040 --> 00:12:11.860
longer term, you know, is
it just certain types of

239
00:12:11.860 --> 00:12:14.800
users? And they might be,
you know, important users or

240
00:12:14.800 --> 00:12:16.600
they might just be kind
of different in the way

241
00:12:16.600 --> 00:12:19.420
that they're interacting by myself,
where those users are having

242
00:12:19.420 --> 00:12:21.670
a problem, but everyone else
is fine and, you know,

243
00:12:22.090 --> 00:12:26.170
information is power. So taking
a lot of that insight

244
00:12:26.330 --> 00:12:29.230
and be able to kind
of make informed decisions about

245
00:12:29.230 --> 00:12:32.440
where to deploy your, your
time and effort. Because at

246
00:12:32.440 --> 00:12:33.760
the end of the day,
you know, for most of

247
00:12:33.760 --> 00:12:37.270
us doing development, cutting code,
you know, there's a never

248
00:12:37.270 --> 00:12:39.880
ending list of things to
be done. And really a

249
00:12:39.880 --> 00:12:41.500
lot of the time, we
just want to want to

250
00:12:41.500 --> 00:12:43.360
focus ourselves on the things
that are going to make

251
00:12:43.360 --> 00:12:45.700
the most difference and actually
achieve good wins and, you

252
00:12:45.700 --> 00:12:49.510
know, get, get, get all
the good, positive feedback out

253
00:12:49.510 --> 00:12:51.190
of that. The last thing
we want to do is

254
00:12:51.190 --> 00:12:53.920
make, you know, an optimization
that was just not actually

255
00:12:54.280 --> 00:12:58.600
worth that or anything like
that. Yeah. There's always an

256
00:12:58.600 --> 00:13:03.420
overhead with bringing in some
kind of observation approach, a

257
00:13:03.420 --> 00:13:07.360
lot monitoring tool, a logging
framework. So you just have

258
00:13:07.360 --> 00:13:10.090
to keep that in mind.
And that's where we often

259
00:13:10.090 --> 00:13:12.910
do an approach where we'll
do an AB kind of

260
00:13:12.940 --> 00:13:15.910
deployment of something where we,
we, we put a new

261
00:13:15.910 --> 00:13:19.360
approach and we measure how
we've got, how the baseline

262
00:13:19.360 --> 00:13:22.330
looks. We'll put it on
measure the other side of

263
00:13:22.390 --> 00:13:25.870
afterwards, what's the impact of,
of putting this technique in

264
00:13:25.870 --> 00:13:29.170
play? That's important. You've always
got to measure things and,

265
00:13:29.180 --> 00:13:31.390
and just kind of understand
and put that back into

266
00:13:31.390 --> 00:13:34.120
the context of, you know,
what am I trying to

267
00:13:34.120 --> 00:13:37.710
do here? What was I
trying to achieve Act? And

268
00:13:37.710 --> 00:13:41.040
Zen database is the best
in class, single secure, scalable

269
00:13:41.040 --> 00:13:44.790
architecture for edge data management.
It's the perfect solution for

270
00:13:44.790 --> 00:13:48.900
software developers who want dedicated
application data management and deliver

271
00:13:48.900 --> 00:13:52.380
business critical products and services
into OT and low it

272
00:13:52.380 --> 00:13:58.560
environments, customizable installation, self tuning,
seamless backward compatibility, minimal memory

273
00:13:58.560 --> 00:14:02.670
requirements and exceptionally low support
requirements and better performance than

274
00:14:02.670 --> 00:14:05.580
most alternatives like SQL Lite
all means that you can

275
00:14:05.580 --> 00:14:09.240
deliver applications to customers at
scale across a wide range

276
00:14:09.240 --> 00:14:12.990
of platforms with direct access
from C plus plus Python

277
00:14:12.990 --> 00:14:16.860
and other popular languages. Zen
simple set of API significantly

278
00:14:16.860 --> 00:14:20.250
expands the pools of developers
capable of building their next

279
00:14:20.280 --> 00:14:24.420
business critical application on acting
Zen, try it today at

280
00:14:24.450 --> 00:14:30.930
<inaudible> dot com slash Zen
that's act I a n.com/zen.

281
00:14:31.830 --> 00:14:34.290
I've heard that there are,
there are profilers that are

282
00:14:34.290 --> 00:14:36.480
listening all the time and
APM systems that are paying

283
00:14:36.480 --> 00:14:39.270
attention to everything that I've
also heard that the idea

284
00:14:39.270 --> 00:14:43.140
of a sampling profiler, or
like it looks at 5%

285
00:14:43.140 --> 00:14:46.860
of the, of the requests
you have thoughts about whether

286
00:14:46.860 --> 00:14:49.320
that's a good idea or
not. I think there's certainly

287
00:14:49.320 --> 00:14:52.940
things sampling a reasonably good
idea. There's certainly an overhead

288
00:14:52.940 --> 00:14:57.650
involved with, for.net, the, the,
the implementation of how profilers

289
00:14:57.650 --> 00:15:01.190
work with the.net framework, which
again, you know, kudos to

290
00:15:01.190 --> 00:15:03.590
the, to the efforts that
are going on and.net core.

291
00:15:03.590 --> 00:15:05.330
One of the things that's
happened there is there's bit

292
00:15:05.390 --> 00:15:08.330
documentation and sort of surface
around how to interact with

293
00:15:08.330 --> 00:15:11.300
the profiling API that exist
in the.net framework and then.net

294
00:15:11.300 --> 00:15:14.960
core. But there's always an
overhead of using that sort

295
00:15:14.960 --> 00:15:18.470
of approach. You can, you
can reduce the impact of

296
00:15:18.470 --> 00:15:20.630
that sort of thing by
taking more of a sampling

297
00:15:20.660 --> 00:15:24.200
based mindset to this. Again,
it's sort of a, it's

298
00:15:24.200 --> 00:15:26.870
one of these things where
you need to kind of

299
00:15:26.870 --> 00:15:29.510
find the right balance. You
know, if you sample too

300
00:15:29.510 --> 00:15:33.500
aggressively, you, you open the
window to losing a lot

301
00:15:33.500 --> 00:15:36.830
of the outliers that might
occur often. It's a case

302
00:15:36.830 --> 00:15:39.320
where you, you know, you
often want to build up

303
00:15:39.380 --> 00:15:41.480
the big picture first, and
there's a cost to that

304
00:15:41.810 --> 00:15:44.410
over time, you might build
feel there's a confidence level.

305
00:15:44.420 --> 00:15:46.910
You understand the nature of
the data you're seeing come

306
00:15:46.930 --> 00:15:50.750
through the trends. You know,
you've already identified where the

307
00:15:50.750 --> 00:15:52.970
key hot spots are and
you dial that. You start

308
00:15:52.970 --> 00:15:56.990
to dial the, the rate
of observation down accordingly, which

309
00:15:56.990 --> 00:16:02.000
would correspond to improved and
performance just through less overhead

310
00:16:02.000 --> 00:16:04.780
of that sort of approach
being implied. I see. So

311
00:16:04.990 --> 00:16:07.630
you could do something like
have it beyond listening for

312
00:16:07.660 --> 00:16:10.750
everything in dev and half
the things that staging and

313
00:16:10.750 --> 00:16:13.930
10% or something at production
depends on your, your, your,

314
00:16:14.050 --> 00:16:16.630
your problem. And then of
course, all exceptions or anything

315
00:16:16.630 --> 00:16:20.740
bad that might've happened. Exactly.
Yup. And one other, one

316
00:16:20.740 --> 00:16:24.820
other sort of approach that
we certainly, you know, pushing

317
00:16:24.970 --> 00:16:28.120
in this space is the
idea of leveraging this more

318
00:16:28.120 --> 00:16:30.550
for supporting the bagging scenarios.
You know, one of the

319
00:16:30.910 --> 00:16:33.820
key challenges that a lot
of developers have, particularly when

320
00:16:33.820 --> 00:16:36.550
things go into production is
that you, you lose your

321
00:16:36.550 --> 00:16:40.960
access to kind of instrument
or get really detailed analysis

322
00:16:40.960 --> 00:16:44.530
of what's going on, for
example, local state variables, or

323
00:16:44.530 --> 00:16:46.690
what are the values of
those methods? You know, arguments

324
00:16:46.690 --> 00:16:49.690
that come through to parameters
for method calls, you know,

325
00:16:49.690 --> 00:16:51.850
often a lot of that
context is quite important to

326
00:16:51.850 --> 00:16:56.050
reproducing a problem or understanding
how a problem manifests, you

327
00:16:56.050 --> 00:16:58.240
know, be at a performance
problem, be it a crash.

328
00:16:58.270 --> 00:17:01.510
You know, the context often
is very critical to really

329
00:17:01.510 --> 00:17:05.170
understanding the nature of the
problem. So, you know, one

330
00:17:05.170 --> 00:17:07.480
of the things that we
really sort of have spent

331
00:17:07.480 --> 00:17:09.940
a lot of time looking
at is how we can

332
00:17:10.690 --> 00:17:13.660
leverage the sort of capability
to try to really support

333
00:17:13.660 --> 00:17:17.830
those production, the bagging type
scenarios, where you kind of

334
00:17:17.830 --> 00:17:21.100
know the heuristics of how
a problem is going to

335
00:17:21.100 --> 00:17:22.960
manifest. It's going to be
this user at this time

336
00:17:22.960 --> 00:17:25.090
of day with this type,
you, that's the end point,

337
00:17:25.720 --> 00:17:28.000
and we've seen this behavior
and I just want to

338
00:17:28.000 --> 00:17:30.910
know more about it. And
so, you know, the, the,

339
00:17:30.940 --> 00:17:34.120
the controls are there to
allow you to just sort

340
00:17:34.120 --> 00:17:36.790
of set a role when
this type of thing is

341
00:17:37.090 --> 00:17:40.210
inaction in play. Give me
more data about it, but

342
00:17:40.210 --> 00:17:43.510
every other time, just don't,
don't send as much data

343
00:17:43.510 --> 00:17:45.760
about what's going on because
I'm not going to be

344
00:17:45.760 --> 00:17:47.860
looking at, and I'm not
interested in collecting all that.

345
00:17:48.310 --> 00:17:50.250
So it really is where
you die. You don't necessarily

346
00:17:50.250 --> 00:17:52.920
Dial it up for the
entire application, but you might,

347
00:17:52.980 --> 00:17:55.860
you might categorize things like
the shopping carts acting weird,

348
00:17:55.860 --> 00:17:58.350
let's dial up, logging on
the shopping cart or dial

349
00:17:58.350 --> 00:18:00.980
up all events for the
shopping Exact period. I mean,

350
00:18:00.980 --> 00:18:02.510
there's always going to be
areas which you're going to

351
00:18:02.510 --> 00:18:05.660
be focusing focused on, you
know, today, you know, this

352
00:18:05.660 --> 00:18:08.150
week, you know, w we,
we, we really focused on

353
00:18:08.180 --> 00:18:11.990
the shopping cart and we
really need a much richer

354
00:18:11.990 --> 00:18:14.360
level of information about what's
going on there to make

355
00:18:14.360 --> 00:18:16.910
better decisions about what we
need to do. You know,

356
00:18:16.910 --> 00:18:19.070
we're in that investigation phase,
we just need to flick

357
00:18:19.080 --> 00:18:21.830
blood data in this space,
but everything else, you know,

358
00:18:21.860 --> 00:18:25.010
that's just business as usual.
Let's just sample that that's

359
00:18:25.010 --> 00:18:28.820
not collect as much information.
You know, we obviously want

360
00:18:28.820 --> 00:18:30.500
to know what's going on
there in case any problems

361
00:18:30.500 --> 00:18:33.350
do turn up, but we
don't need as much detail.

362
00:18:34.250 --> 00:18:38.360
Now, oftentimes when you've got,
you know, mobile devices or

363
00:18:38.810 --> 00:18:41.630
local applications and app that
I'm running on windows, or

364
00:18:41.630 --> 00:18:44.930
now that I'm running on
my iPhone, there's privacy concerns,

365
00:18:44.930 --> 00:18:46.310
I want to make sure
I'm not, you know, like

366
00:18:46.490 --> 00:18:48.350
no one likes a lot
of people don't like telemetry.

367
00:18:48.350 --> 00:18:49.790
They don't want to be
kind of quote unquote spite

368
00:18:49.790 --> 00:18:51.530
on, on the website. You
have a little bit less

369
00:18:51.530 --> 00:18:55.400
control if someone's implementing an
APM product, how do they

370
00:18:55.400 --> 00:18:58.120
make sure that they don't
accidentally leak information out? You

371
00:18:58.120 --> 00:19:01.220
don't wanna necessarily throw a
credit card across a boundary

372
00:19:01.580 --> 00:19:04.610
into some, you know, some
third party APM system. Do

373
00:19:04.610 --> 00:19:06.740
you have filters or what's
the best practice for that?

374
00:19:07.440 --> 00:19:10.100
Yeah, that's a really good
question. I mean, data privacy

375
00:19:10.100 --> 00:19:13.610
is, is quite an important
concern in our space. You

376
00:19:13.610 --> 00:19:16.400
know, the, the nature of
the problem is quite vast,

377
00:19:16.400 --> 00:19:20.570
really because as you kind
of allude to the, the

378
00:19:20.570 --> 00:19:23.600
opportunity to just send sensitive
data across the wire, when

379
00:19:23.600 --> 00:19:25.520
you kind of capture, when
you're looking at things more

380
00:19:25.520 --> 00:19:28.730
at a system level, rather
than thinking so much about

381
00:19:28.730 --> 00:19:31.310
the data that's going on
through these systems, you know,

382
00:19:31.310 --> 00:19:34.430
the, the opportunities have asked,
you know, whether that be

383
00:19:34.430 --> 00:19:38.000
PII information or, you know,
access tokens, which would give

384
00:19:38.000 --> 00:19:40.700
you, you know, an opportunity
to escalate privilege into a

385
00:19:40.700 --> 00:19:45.560
system, those are all concerned.
Our general approach for this

386
00:19:45.560 --> 00:19:48.200
is to allow people to,
to sort of filter out

387
00:19:48.200 --> 00:19:51.110
the information to kind of
effectively kind of give you

388
00:19:51.110 --> 00:19:53.630
a hook then before the
information leaves your, your, a

389
00:19:53.630 --> 00:19:56.420
boundary to do our system
to, to sort of do

390
00:19:56.420 --> 00:20:00.050
any kind of data segmentation,
meet your own requirements as

391
00:20:00.050 --> 00:20:02.540
it were in terms of
what data is sensitive. You

392
00:20:02.540 --> 00:20:05.930
know, usually this can be
expressed with patterns or rejects,

393
00:20:05.930 --> 00:20:09.020
you know, so that, that's
kind of typically how we

394
00:20:09.020 --> 00:20:12.200
deal with this problem. We
also, you know, particularly with,

395
00:20:12.710 --> 00:20:16.070
you know, other products that
we build, like crash reporting,

396
00:20:16.670 --> 00:20:18.350
you know, it's more a
case of there's some standard

397
00:20:18.350 --> 00:20:19.970
things, you know, like a
lot of it's going into

398
00:20:19.970 --> 00:20:21.920
web systems. So, you know,
you always want to look

399
00:20:21.920 --> 00:20:23.720
at the form. You're always
gonna look at the what's

400
00:20:23.720 --> 00:20:26.240
coming across in the query
string user input. You know,

401
00:20:26.240 --> 00:20:28.550
that that's where this information
is likely to be coming

402
00:20:28.550 --> 00:20:30.920
from. So let's just scan
that for known patterns first,

403
00:20:30.920 --> 00:20:33.080
and you can get rid
of a lot of that

404
00:20:33.080 --> 00:20:35.750
information by default, but then,
you know, there's always going

405
00:20:35.750 --> 00:20:40.730
to be system specific stuff
like those security tokens, or

406
00:20:40.790 --> 00:20:45.020
they're just things that only
the developer of that system

407
00:20:45.020 --> 00:20:47.920
would have an intimate awareness
of that required them to

408
00:20:47.920 --> 00:20:51.160
really kind of ensure that
that data is removed prior

409
00:20:51.160 --> 00:20:53.400
to sending it up to
a service like ours. Now,

410
00:20:53.400 --> 00:20:56.370
of course, in the interest
of a full disclosure, there

411
00:20:56.370 --> 00:21:00.690
have been episodes of the
podcast that Reagan has sponsored

412
00:21:00.690 --> 00:21:03.210
in the past. But of
course, for this, this conversation,

413
00:21:03.210 --> 00:21:04.560
they're one of the reasons
that I called you and

414
00:21:04.560 --> 00:21:06.960
wanted to talk to you
was the scale that you're

415
00:21:06.960 --> 00:21:11.940
running is just bananas. Like
not just saying billions of

416
00:21:11.940 --> 00:21:15.360
events, how I want to
talk. I want to understand

417
00:21:15.360 --> 00:21:19.620
how one scales like that.
And do you get backed

418
00:21:19.620 --> 00:21:24.120
up? Is there a queue
what's the queue? Like, I

419
00:21:24.120 --> 00:21:27.810
just can't quite get my
head around the scale at

420
00:21:27.810 --> 00:21:31.230
which you ingest information. It's
pretty vast. I have to

421
00:21:31.230 --> 00:21:33.480
tell ya. And again, sort
of going back to that

422
00:21:33.630 --> 00:21:35.700
sense of, you know, where
we were 20 years ago,

423
00:21:37.050 --> 00:21:39.450
I would never really dreamt
that, you know, the, the

424
00:21:39.450 --> 00:21:42.240
rates at which we kind
of can ingest information, you

425
00:21:42.240 --> 00:21:44.430
know, when you're dealing with
the whole engineer as your

426
00:21:44.430 --> 00:21:47.850
potential source, there's, you know,
there's a real, it's very,

427
00:21:47.850 --> 00:21:51.450
very easy actually to just
completely overwhelm yourself with traffic.

428
00:21:52.200 --> 00:21:54.810
So in terms of how
we sort of went about

429
00:21:54.810 --> 00:21:57.600
it, you know, it's, I
actually took a lot of,

430
00:21:58.410 --> 00:22:04.020
I guess, a vision or
inspiration from early talks that

431
00:22:04.020 --> 00:22:06.540
came out of Amazon, how
they sort of did their

432
00:22:06.540 --> 00:22:09.210
scaling. You know, they sort
of talked about how they

433
00:22:09.420 --> 00:22:11.700
really went through more of
an incrementally sort of scaling

434
00:22:11.790 --> 00:22:14.490
approach. You know, we, we,
we rebuilt the system because

435
00:22:14.490 --> 00:22:16.320
we reached the scaling point
and then we rebooted again,

436
00:22:16.320 --> 00:22:19.920
cause we didn't, we reached
another scaling point. And so

437
00:22:19.920 --> 00:22:21.900
we've kind of progressed in
the similar way. You know,

438
00:22:21.900 --> 00:22:25.200
we, we initially, when we,
when we sort of embarked

439
00:22:25.200 --> 00:22:28.410
on this journey, we were
kind of a different company

440
00:22:28.410 --> 00:22:30.390
and we did different things,
and this was just an

441
00:22:30.390 --> 00:22:33.120
idea. And so at that
point, you know, you don't

442
00:22:33.120 --> 00:22:35.100
really want to over commit
to, you know, wow, you

443
00:22:35.100 --> 00:22:38.010
know, this could turn to
be a really, really massive

444
00:22:38.010 --> 00:22:40.320
thing. So we might want
to, might want to provision

445
00:22:40.320 --> 00:22:42.720
a head of ourselves. And,
you know, one of our

446
00:22:42.720 --> 00:22:46.050
other focuses has always been
on cost and performance, you

447
00:22:46.050 --> 00:22:48.330
know, squeezing out everything from
the dollars that we spend.

448
00:22:48.660 --> 00:22:50.610
So for us, you know,
it was a case of,

449
00:22:50.640 --> 00:22:52.380
you know, let's get something
and that's going to see

450
00:22:52.380 --> 00:22:55.290
us through the, you know,
10 times the amount of

451
00:22:55.290 --> 00:22:57.270
customers we've got now, and
then a hundred times the

452
00:22:57.270 --> 00:22:59.400
amount of customers that we've
got now, and then a

453
00:22:59.400 --> 00:23:01.620
thousand times, and, you know,
to be fair along the

454
00:23:01.620 --> 00:23:06.150
way, you know, we've certainly
been, you know, tested and

455
00:23:06.180 --> 00:23:08.520
frightened a little bit by
how much data we can

456
00:23:08.520 --> 00:23:11.280
actually get. There was one
time early on that. In

457
00:23:11.280 --> 00:23:13.590
fact, it was only a
few weeks into having launched

458
00:23:13.850 --> 00:23:16.320
our system. We are, you
know, a new customer came

459
00:23:16.320 --> 00:23:17.910
onboard and all of a
sudden they were sending at

460
00:23:17.910 --> 00:23:20.040
rates that were sort of
tens of thousands of times

461
00:23:20.040 --> 00:23:23.400
above what we had seen
before. I remember being sort

462
00:23:23.400 --> 00:23:27.030
of online one night and
the pager alerts went off

463
00:23:27.030 --> 00:23:29.520
and it was like the,
the, the asset of internal

464
00:23:29.520 --> 00:23:33.570
buffers were, were, were being
saturated. And we literally had

465
00:23:33.570 --> 00:23:37.080
sort of seconds before. They're
about to run out by

466
00:23:37.080 --> 00:23:38.760
the time we kind of,
we dealt with the problem.

467
00:23:38.760 --> 00:23:41.250
And so a lot of
the time it's just about,

468
00:23:41.250 --> 00:23:43.800
you know, just, just scaling
one step ahead of yourself.

469
00:23:44.340 --> 00:23:47.640
So that sort of notion
of scaling our systems is,

470
00:23:47.640 --> 00:23:51.320
is actually just sort of
a continuous cycle for us.

471
00:23:51.450 --> 00:23:54.710
You know, we were always
thinking about where, where are

472
00:23:54.710 --> 00:23:56.660
the bottlenecks? You know, what
are we going to be

473
00:23:56.660 --> 00:23:58.520
doing to kind of ramp
this up so that we

474
00:23:58.520 --> 00:24:00.320
can sort of like 10
X the volume through this

475
00:24:00.450 --> 00:24:03.950
section of the pipeline and
just really approach it sort

476
00:24:03.950 --> 00:24:06.370
of methodical fashion like that.
It almost seems like you're

477
00:24:06.370 --> 00:24:11.200
every day preparing for a,
a benevolent DDoSs where someone's

478
00:24:11.200 --> 00:24:13.300
going to distribute, you know,
do a distributed denial of

479
00:24:13.300 --> 00:24:15.760
service on you, except they're
using your APIs and your

480
00:24:15.760 --> 00:24:18.640
own product against you without
meaning to like, you know,

481
00:24:18.640 --> 00:24:21.700
they, oops, sorry, we turned
everything on verbose and you

482
00:24:21.700 --> 00:24:23.680
have to Ready for anything
surprised at how much that

483
00:24:23.680 --> 00:24:27.870
happens. Yeah. It's, it's, it's,
it's just the nature of,

484
00:24:27.870 --> 00:24:29.800
of this, you know, and,
and to be fair, you

485
00:24:29.800 --> 00:24:31.630
know, this is what the
cloud has unlocked in a

486
00:24:31.630 --> 00:24:34.540
way it's unlocked the ability
for, you know, that the

487
00:24:34.540 --> 00:24:38.080
engineer to be, you know,
be heading you pretty regularly.

488
00:24:38.080 --> 00:24:40.750
And so by design, when
you kind of set yourself

489
00:24:40.750 --> 00:24:44.860
up with that model, you
are effectively asking for Adidas

490
00:24:44.920 --> 00:24:46.960
at any given point in
time. And so you just

491
00:24:46.960 --> 00:24:49.660
have to be prepared for
that. And, you know, build,

492
00:24:49.660 --> 00:24:51.970
build a bit of resilience
into the system to just

493
00:24:51.970 --> 00:24:53.380
know that that's actually going
to be a thing that

494
00:24:53.380 --> 00:24:56.200
you're dealing with all the
time. And, you know, we're,

495
00:24:56.200 --> 00:24:58.090
we're as doing scale, there's
plenty of people, we're at

496
00:24:58.090 --> 00:24:59.560
a much bigger scale than
us. So, you know, we

497
00:24:59.560 --> 00:25:02.380
can take inspiration and learnings
from what other people are

498
00:25:02.380 --> 00:25:04.000
doing, you know, they're, they
might be in a different

499
00:25:04.000 --> 00:25:07.150
stage of their journey, but
you know, another great thing,

500
00:25:07.150 --> 00:25:09.610
you know, certainly in the
last sort of 10 years,

501
00:25:10.240 --> 00:25:13.210
which I'm sure you probably
agree with is that, you

502
00:25:13.210 --> 00:25:15.700
know, there's a lot more
sharing of this information. You

503
00:25:15.700 --> 00:25:17.670
have the learnings of the
fact that, you know, we,

504
00:25:17.670 --> 00:25:20.170
we, we're dealing with these
challenges, you know, maybe it's

505
00:25:20.170 --> 00:25:24.010
not the, the most, you
know, elegant solution that everyone

506
00:25:24.010 --> 00:25:25.810
uses, but, you know, here's
the way it is in

507
00:25:25.810 --> 00:25:27.790
practice that we deal with
these problems and, you know,

508
00:25:27.790 --> 00:25:30.040
we're all learning wrong commenting.
And, you know, we might,

509
00:25:30.070 --> 00:25:33.610
we might find better ways
over time, but, you know,

510
00:25:33.640 --> 00:25:37.840
it's, it's, it's really a
happening that, you know, we,

511
00:25:37.840 --> 00:25:40.540
as a, as a industry
are able to kind of

512
00:25:40.570 --> 00:25:44.650
collectively level up in this
way. Now this is built

513
00:25:44.650 --> 00:25:48.490
in.net core, but your state,
your, your SDKs are all

514
00:25:48.490 --> 00:25:51.790
languages. I go, every doesn't
matter, it's all HTTP, but

515
00:25:51.790 --> 00:25:55.090
you picked Dynacore on the
backend, is that correct? Yeah.

516
00:25:55.120 --> 00:25:57.370
Originally, I mean, we're very
much a, you know, historically

517
00:25:57.370 --> 00:26:02.340
a Mark soft shop, both
JD and I JD, and

518
00:26:02.340 --> 00:26:06.550
my co founder, we were.net
developers. So, you know, it's

519
00:26:06.550 --> 00:26:08.650
a common thing, you know,
developers go with what they

520
00:26:08.650 --> 00:26:11.890
know and, and, and what
they trust. So for a

521
00:26:11.890 --> 00:26:15.340
long time, we were, we
were leveraging both framework when

522
00:26:15.340 --> 00:26:17.590
dotnet core started to appear
on the horizon. We were

523
00:26:17.590 --> 00:26:20.860
quite interested in it, particularly
with the view that there

524
00:26:20.860 --> 00:26:22.780
was going to be a
lot more iteration and that

525
00:26:22.780 --> 00:26:25.240
framework. So there was the
opportunity to get involved as

526
00:26:25.240 --> 00:26:28.690
well with, you know, looking
at, at, at how the,

527
00:26:28.750 --> 00:26:31.750
how the framework works, submitting
a pull request. You know,

528
00:26:31.840 --> 00:26:33.820
we haven't really done too
much of that in practice,

529
00:26:33.850 --> 00:26:35.610
but, you know, we've been
able to leverage off the,

530
00:26:35.610 --> 00:26:37.930
the great ethics that exist
in the community. You know,

531
00:26:37.930 --> 00:26:39.670
there's people I've been Adams
who have really put on

532
00:26:39.730 --> 00:26:42.550
a huge focus on performance
and the framework we're all

533
00:26:42.580 --> 00:26:47.340
beneficiaries of has, you know,
amazing work. So, yeah, we,

534
00:26:47.340 --> 00:26:50.190
we've, we're really in the
transition phase now of trying

535
00:26:50.190 --> 00:26:53.310
to pour as much of
our ingestion pipeline over to

536
00:26:53.310 --> 00:26:56.460
dotnet core as quickly as
possible. There's amazing sort of

537
00:26:56.460 --> 00:27:00.330
performance wins that we can
unlock by using.net core. And

538
00:27:00.330 --> 00:27:04.140
obviously from our thinking more
holistically as a CTO, you

539
00:27:04.140 --> 00:27:06.870
know, the, the technology choice
is just a one to

540
00:27:06.870 --> 00:27:09.810
one, right? There's still dark
net and still building using

541
00:27:09.810 --> 00:27:11.670
the same base class libraries.
You know, there's a little

542
00:27:11.670 --> 00:27:13.890
bit of difference there, I
guess, but at the end

543
00:27:13.890 --> 00:27:15.840
of the day, it's very,
very familiar and it's, you

544
00:27:15.840 --> 00:27:17.730
know, still as productive and
you're still using the same

545
00:27:17.730 --> 00:27:19.800
tooling and the same tool
chain and all the build

546
00:27:19.800 --> 00:27:22.410
systems and all of that.
So it makes the switch

547
00:27:22.410 --> 00:27:26.130
quite easy. And, you know,
I think I've, I've also

548
00:27:26.130 --> 00:27:28.270
sort of derived a lot
of confidence from, you know,

549
00:27:28.410 --> 00:27:30.360
Microsoft sort of stance on
this, which is, you know,

550
00:27:30.410 --> 00:27:32.220
this is the bleeding edge,
but, you know, we're going

551
00:27:32.220 --> 00:27:34.200
to bring back a lot
of the good stuff and

552
00:27:34.200 --> 00:27:36.300
try, and, you know, land
that back into the, into

553
00:27:36.300 --> 00:27:38.990
the full framework at the
time, If I were going

554
00:27:38.990 --> 00:27:42.500
to build something big, real
big, the thing that I

555
00:27:42.500 --> 00:27:45.230
always worry about isn't that
I can do it or

556
00:27:45.230 --> 00:27:47.660
not. It's that the thing
that I'm building on top

557
00:27:47.660 --> 00:27:51.560
of is not going to
have some weird insidious problem.

558
00:27:52.160 --> 00:27:55.850
Like underload, whether it be
node or go or.net or

559
00:27:55.850 --> 00:27:58.340
whatever, there's always that concern
that you're sitting on a

560
00:27:58.340 --> 00:28:00.860
stack and you just don't
know if it's going to

561
00:28:00.860 --> 00:28:04.130
like, have a memory leak
or blow up under pressure,

562
00:28:04.130 --> 00:28:10.100
or have some fundamental architectural
issue around threading or async

563
00:28:10.100 --> 00:28:12.470
or whatever, you know, how
do you, how do you

564
00:28:12.470 --> 00:28:14.930
deal with that when you're
pushing so much traffic through

565
00:28:14.930 --> 00:28:17.030
such a huge pipe? Did
you think about that in

566
00:28:17.030 --> 00:28:19.880
the context of.net or done
a core, or did you,

567
00:28:20.230 --> 00:28:23.510
did you test for things
like that? Yeah, they are.

568
00:28:23.510 --> 00:28:25.640
And we probably wouldn't have
thought too much about it

569
00:28:25.640 --> 00:28:27.380
at all. Really. You know,
we were, we were committed

570
00:28:27.380 --> 00:28:30.740
to building and dynamic. We
built and darn it over

571
00:28:30.740 --> 00:28:33.920
time. Obviously, as the scale
started, ramping up performance became

572
00:28:33.920 --> 00:28:36.260
far more of a thing,
you know, like it becomes

573
00:28:36.350 --> 00:28:38.900
a feature, you know, it's
something that is ingrained into

574
00:28:38.900 --> 00:28:41.330
our thinking. It's ingrained into
this, you know, the way

575
00:28:41.330 --> 00:28:44.060
in which these parts of
our system have to work.

576
00:28:45.110 --> 00:28:48.650
So over time, you know,
we've, I guess gotten a

577
00:28:48.650 --> 00:28:52.700
lot more into really benchmarking
and understanding what's going on,

578
00:28:52.700 --> 00:28:55.310
where where's the time going,
you know, like I sort

579
00:28:55.310 --> 00:28:57.470
of talked about at the
beginning with why you'd use

580
00:28:57.470 --> 00:28:59.780
an APM tool in the
first place, you know, this,

581
00:29:00.020 --> 00:29:02.570
this technique kind of obviously
just goes, you know, can

582
00:29:02.570 --> 00:29:06.230
be applied further to, you
know, w w how how's

583
00:29:06.230 --> 00:29:08.210
the framework looking, you know,
we can measure that as

584
00:29:08.210 --> 00:29:11.900
well. So, and we can
obviously just benchmark the system

585
00:29:11.900 --> 00:29:14.550
as a whole and understand,
you know, okay, we're, we're

586
00:29:14.630 --> 00:29:18.680
slowing down and, you know,
why is it essentially locking

587
00:29:18.680 --> 00:29:20.780
up or where's the contention?
Is that a framework problem?

588
00:29:20.780 --> 00:29:23.600
Is that something on our
side, again, you know, we

589
00:29:23.600 --> 00:29:27.080
want to, you kinda mentioned,
you know, you wouldn't wanna

590
00:29:27.080 --> 00:29:32.270
be building on like a,
a house cards and with

591
00:29:32.270 --> 00:29:35.480
the full framework, you know,
I never particularly found any

592
00:29:35.570 --> 00:29:37.940
issues there, but, you know,
as we've sort of seen

593
00:29:37.940 --> 00:29:39.950
with the development of dotnet
core and all the community

594
00:29:39.950 --> 00:29:44.470
contributions, there's plenty of room,
plenty of room on the

595
00:29:44.470 --> 00:29:48.520
table still to improve performance.
And, but that hasn't necessarily

596
00:29:48.520 --> 00:29:51.040
hampered anyone in terms of
delivering systems, but it's really

597
00:29:51.040 --> 00:29:54.940
nice to know that that's
a far bigger focus within

598
00:29:55.060 --> 00:29:58.930
Microsoft and suddenly the development
of.net core and the continuing

599
00:29:58.930 --> 00:30:00.910
kind of evolution of it
that, you know, a lot

600
00:30:00.910 --> 00:30:03.610
of people are dealing with
these problems. They're concerned about

601
00:30:03.610 --> 00:30:06.490
performance. They're interested in making
sure the frameworks as tight

602
00:30:06.490 --> 00:30:09.370
as possible, and, you know,
those contributions all kind of

603
00:30:09.370 --> 00:30:12.190
come together, you know, and
we all benefit from it.

604
00:30:12.670 --> 00:30:16.240
Right. And it seems like,
like there's subtle things. Like

605
00:30:16.290 --> 00:30:20.200
I know that some people
feel like.net folks talk about

606
00:30:20.200 --> 00:30:23.770
span of T too much.
Like it's the biggest thing

607
00:30:23.770 --> 00:30:26.890
since link or the biggest
thing since, you know, generics,

608
00:30:26.890 --> 00:30:31.120
but it feels to me,
like not avoiding unnecessarily copying

609
00:30:31.120 --> 00:30:34.120
around stuff that you already
have in memory is a

610
00:30:34.120 --> 00:30:37.000
pretty big deal. And the
underlying parts of Danette core

611
00:30:37.000 --> 00:30:39.460
that have been improved by
the span of T would

612
00:30:39.460 --> 00:30:43.060
probably benefit an APM system
as well. I think that

613
00:30:43.060 --> 00:30:45.190
would benefit most people, to
be honest, you know, one,

614
00:30:45.310 --> 00:30:48.340
one quick example with, within
the context of our ingestion

615
00:30:48.340 --> 00:30:52.630
pipeline, that where this makes
a big difference is Jason

616
00:30:52.690 --> 00:30:57.130
serialization or destabilization, right. You
know, that's something that, you

617
00:30:57.130 --> 00:30:59.170
know, historically, you know, everyone
just kind of uses a

618
00:30:59.170 --> 00:31:02.500
library for, and you just
don't really think too much

619
00:31:02.500 --> 00:31:04.300
about it. Everyone kind of
knows that, or else it's

620
00:31:04.310 --> 00:31:07.090
kind of slow. One of
the reasons it's slow is

621
00:31:07.090 --> 00:31:10.330
that there's a lot of
memory allocations and copying that

622
00:31:10.330 --> 00:31:13.000
goes around because, you know,
you're dividing things up and

623
00:31:13.000 --> 00:31:15.790
creating new little objects to
represent the object model and

624
00:31:15.790 --> 00:31:19.600
all of that. And by,
you know, using a technique

625
00:31:19.600 --> 00:31:21.340
like span, which at the
end of the day, it's

626
00:31:21.340 --> 00:31:23.530
just fixed a fixed sort
of point where across a

627
00:31:23.530 --> 00:31:26.440
block of memory where you
can avoid those allocations was

628
00:31:26.440 --> 00:31:29.110
by re pointing and, you
know, well, this, this is

629
00:31:29.110 --> 00:31:31.540
just, this copy is just,
you know, these bites from

630
00:31:32.170 --> 00:31:35.430
four to 16, rather than
we'll copy it and, and,

631
00:31:35.470 --> 00:31:39.640
you know, and cure all
of that cost. So everyone

632
00:31:39.940 --> 00:31:44.590
who's using Dyson, generalization <inaudible>
today. And, you know, if

633
00:31:44.590 --> 00:31:46.510
they were to move to
dotnet core three, where those

634
00:31:46.510 --> 00:31:49.720
improvements have been made, they
will benefit from that for

635
00:31:49.720 --> 00:31:53.890
free. So those sort of
performance wins, you know? Wow.

636
00:31:53.890 --> 00:31:56.650
Yeah, sure. Using span is
definitely a great thing, you

637
00:31:56.650 --> 00:31:59.380
know, where we can leverage
it. You know, it's good

638
00:31:59.380 --> 00:32:02.650
to say that that's been
kind of baked in at,

639
00:32:02.740 --> 00:32:04.780
into the framework itself. So
they, even if you're not

640
00:32:04.780 --> 00:32:07.060
necessarily thinking about these things,
or don't want to think

641
00:32:07.060 --> 00:32:08.800
about these things, they're not
really top of mind, they're

642
00:32:08.800 --> 00:32:11.650
not a major concern. You
are still going to pick

643
00:32:11.650 --> 00:32:13.990
up the benefits of having
these things brought into the,

644
00:32:13.990 --> 00:32:17.260
into the, you know, the
worldview of.net. Very cool. Well,

645
00:32:17.260 --> 00:32:20.500
thank you so much. Jeremy Boyd,
CTO of Reagan for talking

646
00:32:20.500 --> 00:32:24.190
to me today about the
world of application performance monitoring

647
00:32:24.280 --> 00:32:26.590
management, however you want to
call it. I've learned a

648
00:32:26.590 --> 00:32:29.260
lot. I appreciate your time.
Thanks, Scott. And really appreciate

649
00:32:29.260 --> 00:32:33.070
it. This has been another
episode of Hanselminutes and we'll

650
00:32:33.070 --> 00:32:54.410
see you again Next week.
<inaudible>.

