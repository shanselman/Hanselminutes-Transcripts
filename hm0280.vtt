WEBVTT FILE

1
00:00:04.380 --> 00:00:16.830
<inaudible> from Hansel minutes.com. It's
Hansel minutes, a weekly discussion

2
00:00:16.830 --> 00:00:21.300
with web developer and technologists.
Scott Hanselman. This is Lawrence Ryan

3
00:00:21.300 --> 00:00:27.510
announcing show number two 80
recorded live Thursday, August 18th, 2011. Support

4
00:00:27.510 --> 00:00:31.110
for Hanselman it's provided by
Telerik rad controls, the most

5
00:00:31.110 --> 00:00:34.800
comprehensive suite of components for
windows forums and asp.net web

6
00:00:34.800 --> 00:00:43.680
applications. online@wwwdottelerik.com. In this episode,
Scott talks with hashing Wong

7
00:00:43.830 --> 00:00:50.870
from Microsoft research Asia about
Trinity. Hi, this is Scott

8
00:00:50.870 --> 00:00:53.570
Hanselman and this is another
episode of Hansel minutes. And

9
00:00:53.570 --> 00:00:57.320
today I am Skyped in
with hi Shing Wong from

10
00:00:57.320 --> 00:01:01.410
Microsoft research Asia calling in
all the way from, from

11
00:01:01.490 --> 00:01:04.640
China right now. Yes. Fantastic.
Thank you for taking the

12
00:01:04.640 --> 00:01:08.360
time to, to chat with
me. I wanted to talk

13
00:01:08.360 --> 00:01:13.070
to you about your project
called Trinity, and you do

14
00:01:13.070 --> 00:01:16.280
a lot of work in,
in Microsoft research and you've

15
00:01:16.280 --> 00:01:19.190
got a number of projects.
You've got Trinity one called

16
00:01:19.190 --> 00:01:23.750
web Q and probates, but
Trinity is a data structure

17
00:01:23.750 --> 00:01:27.200
that thinks about things in
terms of a graph. It

18
00:01:27.200 --> 00:01:32.180
gives me some background on
what Trinity is. Well, Trinity

19
00:01:32.180 --> 00:01:39.290
is actually two projects. Trinity
first is a graph database,

20
00:01:39.320 --> 00:01:44.450
a graph database, which handles
graph very, very large graph

21
00:01:44.450 --> 00:01:49.220
structures and the support online
quarter processing. It's just like

22
00:01:49.220 --> 00:01:53.780
a database which answers quarries
posts by the users. And

23
00:01:54.590 --> 00:01:58.490
on the other hand, Trinity
is also a graph computation

24
00:01:58.490 --> 00:02:03.830
platform for offline large analytics.
So if you want to

25
00:02:03.830 --> 00:02:08.960
do a very, very large
jobs graph data, and it's

26
00:02:09.050 --> 00:02:12.410
just like what you would
to do for text data

27
00:02:12.410 --> 00:02:16.700
or other kinds of data
using, for example, map, reduce

28
00:02:17.220 --> 00:02:21.770
a mechanism. You can use
Trinity to process very large

29
00:02:21.800 --> 00:02:27.200
data in an offline manner.
Okay. So for a developer

30
00:02:27.200 --> 00:02:31.970
who might be listening, who
is familiar with object, relational

31
00:02:31.970 --> 00:02:37.670
data or document databases like
Mongo, what is a graph

32
00:02:37.670 --> 00:02:43.940
database? The graph database is
special in the sense that,

33
00:02:44.150 --> 00:02:49.070
you know, it makes the
graphics proration much easier than

34
00:02:49.100 --> 00:02:54.740
traditional database. So you can
use traditional database, for example,

35
00:02:54.750 --> 00:02:59.800
relational database to, to, to
support graph data. But then

36
00:02:59.800 --> 00:03:02.680
you'll run into a very,
very big problem, which is

37
00:03:02.980 --> 00:03:07.570
a graphics proration will correspond
to join operations on the,

38
00:03:08.380 --> 00:03:10.930
on the, on the data.
And the joint is a

39
00:03:10.930 --> 00:03:17.440
very, very expensive operation. And
the usually for graph data,

40
00:03:17.440 --> 00:03:21.220
you would like to explore
the graph, you know, freely,

41
00:03:21.490 --> 00:03:26.380
and then each Explorer. Every
step you want to explore

42
00:03:26.390 --> 00:03:30.610
will correspond to our joint
operation. So relational database pattern

43
00:03:30.610 --> 00:03:34.720
today cannot handle that. And
the current other no sequel

44
00:03:34.720 --> 00:03:38.320
approach, including for example, how
to pan the other key

45
00:03:38.320 --> 00:03:43.090
value pad stores. They, they
won't be able to do

46
00:03:43.090 --> 00:03:47.890
that as well because they
cannot handle that many joins

47
00:03:48.610 --> 00:03:52.330
when they want to process
the quarters in an online

48
00:03:52.330 --> 00:03:56.110
fashion. So a graph database
is just special. I mean,

49
00:03:56.110 --> 00:04:03.850
it supports online graphics, proration
without using joins. That's the

50
00:04:03.850 --> 00:04:08.040
most important thing to know
about the graph database. Okay.

51
00:04:08.070 --> 00:04:10.830
So let me think if
I understand this correctly, because

52
00:04:10.830 --> 00:04:13.710
I do not have a
PhD and I'm not sure

53
00:04:13.710 --> 00:04:16.470
how many of our listeners
do. I know that when

54
00:04:16.470 --> 00:04:21.060
I've given interview questions before
I've asked junior engineers to

55
00:04:21.060 --> 00:04:25.500
say, can you express a
tree structure in an object

56
00:04:25.500 --> 00:04:29.760
relational database? And often very
beginner people will make multiple

57
00:04:29.760 --> 00:04:32.370
tables. And then a more
advanced person will make a

58
00:04:32.370 --> 00:04:36.390
tree structure. That's a single
self referential table. And then

59
00:04:36.390 --> 00:04:41.700
the tree structure becomes extremely
complex as the joins to

60
00:04:41.700 --> 00:04:45.510
the table itself, kind of
start to Recurse and it

61
00:04:45.510 --> 00:04:49.440
becomes pretty hairy to make
these kind of infinitely deep

62
00:04:49.440 --> 00:04:53.820
self referential tables. Is that
what you're describing to, to

63
00:04:54.030 --> 00:04:57.090
the trouble in creating a
graph in an object relational

64
00:04:57.090 --> 00:05:02.850
manner? Yes. So imagine you
want to, for example, represent

65
00:05:02.850 --> 00:05:06.840
a tree or a graph
using, you know, multiple tables

66
00:05:06.840 --> 00:05:11.130
or a single table with
Def referencing pointers. So basically

67
00:05:11.130 --> 00:05:13.920
what you are doing is
that you are using keys

68
00:05:14.610 --> 00:05:19.050
to a reference, for example,
the neighbors of a particular

69
00:05:19.050 --> 00:05:21.440
node, or the child nodes
have a pattern, know that

70
00:05:21.450 --> 00:05:24.570
you a tree structure. So
you order to find your

71
00:05:24.810 --> 00:05:28.080
child knows child knows all
your neighbors in a graph,

72
00:05:28.350 --> 00:05:32.250
you basically need to search
through those keys, right? You

73
00:05:32.250 --> 00:05:35.700
need to use an index
structure to help you to

74
00:05:35.700 --> 00:05:40.920
find those keys immediate, right?
And they will retrieve those

75
00:05:40.920 --> 00:05:44.100
red cards from the database,
from the table. And then

76
00:05:44.100 --> 00:05:46.620
you find that your neighbors
all your channels. So you

77
00:05:46.620 --> 00:05:50.220
need to go through this
process. So this is going

78
00:05:50.220 --> 00:05:53.110
to be very, very slow
because basically you are, you

79
00:05:53.110 --> 00:05:56.520
are accessing the index and
you are doing a joint

80
00:05:56.750 --> 00:06:01.040
operation. So by doing a
joint operation, I mean the,

81
00:06:01.190 --> 00:06:05.060
those values are not correct
connected the directory, you need

82
00:06:05.060 --> 00:06:08.900
to go through the index.
So across database can be

83
00:06:08.900 --> 00:06:15.500
defined as, you know, it
can find its neighbors or

84
00:06:15.500 --> 00:06:19.010
its channels without using the
index. If you, if a

85
00:06:19.010 --> 00:06:22.410
database system can do that,
then we can call it

86
00:06:22.920 --> 00:06:26.840
a native graph database system.
Otherwise it's just, you know,

87
00:06:27.200 --> 00:06:31.580
using, for example, multiple tables
or relational database to simulate

88
00:06:31.850 --> 00:06:35.380
a graph database. I see.
So would it be fair

89
00:06:35.380 --> 00:06:41.320
to say that often people
have data that is graph

90
00:06:41.440 --> 00:06:44.470
in shape and then they
use the database that they're

91
00:06:44.470 --> 00:06:47.560
the most comfortable with and
begin to run into trouble.

92
00:06:47.800 --> 00:06:50.710
And this is kind of
a, a specific kind of

93
00:06:50.710 --> 00:06:56.680
database for a specific kind
of data. Yes. So of

94
00:06:56.680 --> 00:06:59.680
course, a lot of transaction
data, they are not really

95
00:07:00.580 --> 00:07:02.890
in the, you know, in
the form of a graph,

96
00:07:02.920 --> 00:07:08.290
but you know, more and
more appropriate applications right now,

97
00:07:08.290 --> 00:07:11.410
they are working on very
complex data. And this kind

98
00:07:11.410 --> 00:07:14.980
of data is, you know,
can be nice to be

99
00:07:14.980 --> 00:07:18.790
represented by graphs because graph
has have a lot of

100
00:07:19.210 --> 00:07:24.070
flexibility, flexibility in representing those
kinds of structures. And just

101
00:07:24.070 --> 00:07:29.650
like you said, people will
naturally use a traditional, you

102
00:07:29.650 --> 00:07:34.060
know, data management systems, key
Beto stalls, or relational database

103
00:07:34.090 --> 00:07:38.500
to support these kinds of
new applications. And whenever the

104
00:07:38.500 --> 00:07:43.810
data gets larger and the,
the operations get more complex,

105
00:07:43.870 --> 00:07:47.920
they will run into problems
where, you know, response time

106
00:07:47.980 --> 00:07:52.120
is just not the response
time is just too long

107
00:07:52.300 --> 00:07:58.720
for the online processing. And
if I were to create

108
00:07:58.870 --> 00:08:03.790
a naive in memory graph
structure myself, and maybe I

109
00:08:03.790 --> 00:08:05.710
said, I'm going to have
a database of a couple

110
00:08:05.710 --> 00:08:08.680
of gigabytes and in memory,
and I'll make just a

111
00:08:08.680 --> 00:08:12.040
big, giant bunch of C
sharp objects. What kinds of

112
00:08:12.040 --> 00:08:15.460
issues would I run into
with a naive implementation that

113
00:08:15.460 --> 00:08:21.550
would be solved by a
formal implementation like Trinity? So

114
00:08:21.640 --> 00:08:25.630
basically first of all, you
would need the data structure

115
00:08:25.660 --> 00:08:31.090
to, to, to be stored
in memory because typically the

116
00:08:31.090 --> 00:08:34.840
graph data does not have
locality, which means you cannot

117
00:08:35.050 --> 00:08:40.390
really use, you know, sequential
access to get your information.

118
00:08:40.390 --> 00:08:43.990
Usually, you know, your nodes,
that the neighbors of a

119
00:08:43.990 --> 00:08:46.810
particular node, that they are
all over the place. So

120
00:08:46.900 --> 00:08:50.710
you would like all those
kinds of information residing the

121
00:08:50.710 --> 00:08:54.010
memory, you know, main memory
you said on the disc,

122
00:08:54.100 --> 00:09:00.390
right? So if you only
have a small graph, then

123
00:09:00.390 --> 00:09:03.630
you can do that. Using
all kinds of, you know,

124
00:09:05.790 --> 00:09:12.960
the runtime structures to manage
your, your graph. That that

125
00:09:12.960 --> 00:09:16.620
is fine, but usually we
need to handle very, very

126
00:09:16.620 --> 00:09:21.030
large graphs, so many applications,
they need to handle very

127
00:09:21.030 --> 00:09:24.240
large graphs, like a, you
know, a social network or,

128
00:09:24.240 --> 00:09:29.190
you know, bioinformatics, you need
to handle the gene sequence

129
00:09:29.190 --> 00:09:32.100
of our human being and
the, those kinds of data.

130
00:09:32.760 --> 00:09:38.550
You cannot use a single
machine to support it because

131
00:09:38.640 --> 00:09:42.150
it's just, the memory is
not that right. And then

132
00:09:42.950 --> 00:09:47.520
one approach actually used by
a lot of, you know,

133
00:09:47.550 --> 00:09:49.860
kind of an application is
that, you know, they are

134
00:09:49.860 --> 00:09:55.200
buying a very, very powerful
machine, which can have up

135
00:09:55.200 --> 00:10:03.000
to say one terabyte of
memory. So this is sort

136
00:10:03.000 --> 00:10:05.550
of the, the, you know,
the approach people are taking

137
00:10:05.550 --> 00:10:08.580
right now, but of course
those machines are very costly

138
00:10:08.580 --> 00:10:13.740
and it's, it's, it still
has the scalability problem because

139
00:10:13.740 --> 00:10:18.630
data is getting larger and
larger. So that's the major,

140
00:10:18.660 --> 00:10:23.220
major challenge. And for example,
if you imagine a larger

141
00:10:23.230 --> 00:10:29.550
social network like Facebook, right?
So Facebook has probably close

142
00:10:29.550 --> 00:10:33.780
to 1 billion, let's say 800 million
users. And for each year

143
00:10:33.890 --> 00:10:39.300
on average, you will have
like 150 friends. So for

144
00:10:39.300 --> 00:10:43.530
such a graph, we are
talking about over a one

145
00:10:43.530 --> 00:10:50.640
terabytes of information just to,
you know, represent it's the

146
00:10:50.640 --> 00:10:53.820
graph topology. Okay. And nothing.
I was just a graph

147
00:10:53.820 --> 00:10:59.670
topology. So you'll probably cannot
use a single machine to

148
00:10:59.670 --> 00:11:03.870
do that. And if you
can, a single machine probably

149
00:11:03.870 --> 00:11:08.340
does not have that much
parallel capability to support so

150
00:11:08.340 --> 00:11:14.610
many concurrent online operations. So
you want to scale out

151
00:11:14.640 --> 00:11:21.540
that system into, for example,
15 machines or 200 machines

152
00:11:21.570 --> 00:11:25.020
or things like that. And
that is actually what we

153
00:11:25.020 --> 00:11:31.950
are doing. We are providing
this scalability through class tiles

154
00:11:32.010 --> 00:11:34.890
when, you know, maybe hundreds
or even thousands of machines

155
00:11:35.100 --> 00:11:40.890
to support applications at the
same time, many concurrent operations

156
00:11:40.890 --> 00:11:46.290
at the same time. So,
and the, in this way,

157
00:11:46.290 --> 00:11:48.810
of course we can support
very, very large graph. So

158
00:11:48.810 --> 00:11:52.530
we can support, for example,
the entire web graph, which

159
00:11:52.530 --> 00:11:57.220
will take probably 300 to
500 machines. And for the

160
00:11:57.220 --> 00:12:00.910
user, we provide a very
nice interface. So the user,

161
00:12:01.720 --> 00:12:07.030
it seems to the user
that everything is <inaudible> of

162
00:12:07.030 --> 00:12:09.970
a single machine. So he
does not have to worry

163
00:12:09.970 --> 00:12:13.390
about where to find its
neighbors or, you know, how

164
00:12:13.390 --> 00:12:17.440
the graph is distributed. So
many machines on the cluster.

165
00:12:17.740 --> 00:12:22.530
So that's what Trinity is
doing. So to understand, you

166
00:12:22.530 --> 00:12:26.460
just said the entire web
graph, like you're talking, like

167
00:12:26.520 --> 00:12:29.100
represent a representation of the
web and all of its

168
00:12:29.100 --> 00:12:33.870
interlinking nodes feeling as if
it is in memory and

169
00:12:33.870 --> 00:12:37.890
available to you, right? Like,
like, like Google or being

170
00:12:37.890 --> 00:12:42.420
it's just there and it's
instantaneously available. Right. Right. So,

171
00:12:42.450 --> 00:12:45.270
but I'm only talking about
the topology of the graph.

172
00:12:45.270 --> 00:12:48.270
So I'm only talking about,
for example, a webpage, it

173
00:12:48.270 --> 00:12:52.080
has on average, maybe 50
links to other, other webpage.

174
00:12:52.110 --> 00:12:57.060
I'm only, you know, storing
the, the nodes, which is

175
00:12:57.460 --> 00:13:01.230
basically a UIL. And also
it's all going links in

176
00:13:01.230 --> 00:13:06.420
this, you know, Trinity's memory
structure, but the content of

177
00:13:06.510 --> 00:13:11.550
a particular webpage is not
extra study memory. That's called

178
00:13:11.750 --> 00:13:15.510
in a database. So only
the typology of the graph

179
00:13:15.510 --> 00:13:17.850
is seen by members. Right.
And that's why I think

180
00:13:17.850 --> 00:13:20.220
that the social networking example
is such a good one

181
00:13:20.220 --> 00:13:23.070
on your, on your research
site, you give the example

182
00:13:23.070 --> 00:13:27.270
that a person on average
has 120 friends in Facebook.

183
00:13:27.540 --> 00:13:31.260
So then if you want
to search me, my friends

184
00:13:31.530 --> 00:13:35.820
and my friends, friends, a
three hop search, while that

185
00:13:35.820 --> 00:13:40.050
seems quite easy, you know,
it's easy to say, you're

186
00:13:40.050 --> 00:13:45.270
looking at 120 plus 120
squared plus 120 cubed. That

187
00:13:45.270 --> 00:13:49.920
would be quite an amazing
SQL query and no small

188
00:13:49.920 --> 00:13:52.830
feat to represent in a,
in a traditional object relational

189
00:13:52.830 --> 00:13:55.290
database. And you're able to
do that in just milliseconds,

190
00:13:56.370 --> 00:14:00.390
Right? So this is extra,
very, very important operation on

191
00:14:00.420 --> 00:14:04.380
a social network graph. So
for example, if someone's such

192
00:14:04.410 --> 00:14:07.410
such or something on being
on Google, and you mean

193
00:14:07.860 --> 00:14:11.430
being an, a Google has
the social networking information, and

194
00:14:11.670 --> 00:14:13.830
then, you know, the search
and you would like to

195
00:14:13.830 --> 00:14:17.310
use the information of your
friends, your friends, friends, and

196
00:14:17.310 --> 00:14:23.010
friends, friends, friends, to sort
of provide relevance cruise to,

197
00:14:23.040 --> 00:14:26.580
to the, to the search.
So this operation has to

198
00:14:26.580 --> 00:14:29.700
be done in a very,
very small amount of time

199
00:14:29.880 --> 00:14:32.790
so that the search engine
will, can take that into

200
00:14:32.790 --> 00:14:37.320
consideration in, you know, providing
answers to the user. So

201
00:14:37.320 --> 00:14:40.440
currently Trinity can do that
as you mean, the data

202
00:14:40.440 --> 00:14:44.340
is in, you know, same
distribution as the Facebook data.

203
00:14:44.580 --> 00:14:47.280
So Trinity can do this
three hops search within a

204
00:14:47.280 --> 00:14:52.220
hundred milliseconds. And if you
use I'll keep at Opez

205
00:14:52.220 --> 00:14:56.870
or any other approach, I
think the time is actually

206
00:14:57.230 --> 00:15:00.890
at least a hundred times,
or even more than what

207
00:15:00.890 --> 00:15:06.670
we can do on Trinity.
Hi, this is Scott coming

208
00:15:06.670 --> 00:15:09.100
to you from another place
in time. Are you using

209
00:15:09.100 --> 00:15:12.190
agile practices to manage your
software development? There's lots of

210
00:15:12.190 --> 00:15:14.050
tools in the market that
manage the steps of a

211
00:15:14.050 --> 00:15:17.500
project, but most of them
focus on individual roles, get

212
00:15:17.500 --> 00:15:19.510
ready for a solution that
caters for the success of

213
00:15:19.510 --> 00:15:23.140
the whole team. Guys at
Tellerik introduced team pulse. It's

214
00:15:23.150 --> 00:15:26.200
an agile project management tool.
That'll help you gather ideas,

215
00:15:26.380 --> 00:15:30.970
estimate plan, track progress in
a common workspace. Finally, companies,

216
00:15:30.970 --> 00:15:33.250
regardless of their size can
use a lightweight and convenient

217
00:15:33.250 --> 00:15:35.500
tool that makes all the
stakeholders work as a United

218
00:15:35.500 --> 00:15:39.730
team. Even if they're in
different countries by combining intuitive

219
00:15:39.730 --> 00:15:42.610
user interface and the power
server light team poles removes

220
00:15:42.610 --> 00:15:45.250
the roadblocks that you typically
face and applying agile in

221
00:15:45.250 --> 00:15:48.610
an effective manner, no more
lost data, no disparate systems,

222
00:15:49.240 --> 00:15:52.500
no lack of critical analytics
regarding the health and philosophy

223
00:15:52.520 --> 00:15:55.960
project. See if yourself get
a free copy for five

224
00:15:55.960 --> 00:16:02.470
users in one project at
tellerik.com/team pulse. And please do

225
00:16:02.470 --> 00:16:05.260
thank tolerant for supporting Hansel
minutes on their Facebook fan

226
00:16:05.260 --> 00:16:11.680
page, facebook.com/t L E R
I K Keller. We do

227
00:16:11.680 --> 00:16:13.570
appreciate it. They wouldn't be
a Hansel minutes if there

228
00:16:13.570 --> 00:16:17.980
wasn't, Tellerik helping us. Now,
a lot of times people

229
00:16:18.400 --> 00:16:23.350
accused Microsoft of, of reinventing
the wheel, although less. So

230
00:16:23.350 --> 00:16:28.090
with Microsoft research, sometimes Microsoft
people say, why don't you

231
00:16:28.090 --> 00:16:29.800
use this open source project?
Or why don't you use

232
00:16:29.800 --> 00:16:31.450
that open source project? I
know that there are other

233
00:16:31.450 --> 00:16:35.590
graph databases like Neo for
J and Google has a

234
00:16:35.650 --> 00:16:39.760
pre, is it pre goal
or pre jail prideful prideful.

235
00:16:40.150 --> 00:16:42.580
So there are other large
scale graph systems out there.

236
00:16:42.580 --> 00:16:46.210
What's what is unique about,
about Trinity visa VI? The

237
00:16:46.210 --> 00:16:50.830
other examples? Yeah, so like
I mentioned, the Trinity is

238
00:16:50.830 --> 00:16:55.470
both sides, a online quarter
processing system and also an

239
00:16:55.480 --> 00:16:59.920
offline, you know, a batch
processing or analytics system. So

240
00:17:00.190 --> 00:17:03.970
in this sense, you can
think of Trinity as a

241
00:17:03.970 --> 00:17:10.090
combination of <inaudible> and the
project. So prejudi is for

242
00:17:10.100 --> 00:17:15.670
offline quarter processing and UJ
is for online quarter processing,

243
00:17:15.940 --> 00:17:21.190
but Trinity can provide both
capabilities using a single platform.

244
00:17:21.730 --> 00:17:25.840
So that's basically the major
difference. And, and also there's

245
00:17:25.840 --> 00:17:29.500
another thing which is about
the scalability. So we actually

246
00:17:29.500 --> 00:17:32.620
have a compared with you
for Jay when we started

247
00:17:32.620 --> 00:17:40.150
this project and new Fuji
is, is because, I mean,

248
00:17:40.180 --> 00:17:42.820
they have a lot of
versions and we have tried

249
00:17:42.910 --> 00:17:45.430
a few of them and
it seems to me, they

250
00:17:45.430 --> 00:17:49.320
are, first of all, this
credit isn't and on the

251
00:17:49.320 --> 00:17:54.990
second of all, they are
not really very easy to

252
00:17:54.990 --> 00:17:58.860
distribute among a set of
plasters. I'm a set on

253
00:17:58.860 --> 00:18:03.120
machines in a cluster. So
mainly people are using new

254
00:18:03.120 --> 00:18:08.700
Fuji for our smaller graph
applications that can be hosted

255
00:18:09.270 --> 00:18:12.540
in one machine, but new
footage, it does provide a

256
00:18:12.540 --> 00:18:17.640
very, very nice user interface
and a programming interface to

257
00:18:17.640 --> 00:18:22.800
support a user application. It's
just the scalability that we

258
00:18:22.800 --> 00:18:27.170
are trying to improve over
new forgings, that aspect. I

259
00:18:27.170 --> 00:18:29.270
see. I see. And I
know that the way that

260
00:18:29.270 --> 00:18:32.420
you currently access the data
that is inside of Trinity

261
00:18:32.420 --> 00:18:35.810
is with a sharp API
and most of the samples

262
00:18:35.810 --> 00:18:40.490
around a synchrony use that
API along with the task

263
00:18:40.490 --> 00:18:44.990
parallel library, that.net uses for
things like parallel for each.

264
00:18:45.230 --> 00:18:49.670
So it seems like you
get some, some free multithreaded

265
00:18:49.670 --> 00:18:52.880
newness with the parallel libraries.
Do you do additional things

266
00:18:52.880 --> 00:18:56.240
within your own libraries to
utilize the processors as efficiently

267
00:18:56.240 --> 00:19:00.260
as possible? Oh yes. We
actually did a lot of

268
00:19:00.470 --> 00:19:04.910
low level, you know, hacking
into, in order to support

269
00:19:04.910 --> 00:19:08.360
more parallel, you know, in
order to have more parallel

270
00:19:08.360 --> 00:19:17.660
capabilities, but, you know, latest
release, we actually wrap everything,

271
00:19:17.900 --> 00:19:21.770
all those, you know, parallel
computing capabilities, we'll wrap it

272
00:19:21.860 --> 00:19:25.880
into the API APIs. So
the user actually does not

273
00:19:25.880 --> 00:19:29.960
have to deal with, you
know, this express it, they

274
00:19:29.960 --> 00:19:35.330
deal with those parallel constructs.
He can just submit it.

275
00:19:35.910 --> 00:19:39.530
His Quora is as if
we are just running on

276
00:19:39.530 --> 00:19:42.620
a single machine with a
single thread and the system

277
00:19:42.620 --> 00:19:46.700
will automatically take care of
that. And, you know, parallel

278
00:19:46.910 --> 00:19:52.400
a parallel rise. It's a
computation. Interesting. So the data

279
00:19:52.400 --> 00:19:54.800
could be across one machine
or hundreds and hundreds of

280
00:19:54.800 --> 00:19:59.510
machines. It could be across
400 processors or 400 times

281
00:19:59.960 --> 00:20:01.910
24 processes. And they don't
have to think about it

282
00:20:01.910 --> 00:20:05.150
it's as if they're dealing
with an in-memory structure themselves.

283
00:20:06.200 --> 00:20:10.430
Yes, exactly. Well, that's a,
that's a very comfortable, comfortable

284
00:20:10.430 --> 00:20:13.700
interface. That's that's that seems
very pleasant. Is it always

285
00:20:13.700 --> 00:20:18.110
going to be C sharp
though? Yes. Currently we only

286
00:20:18.110 --> 00:20:22.340
have, we only, we only
provide a CCRPI interface, but

287
00:20:22.430 --> 00:20:25.110
of course, I mean the
future, we can look into

288
00:20:26.090 --> 00:20:30.170
possibilities of providing another kind
of another interface, like for

289
00:20:30.680 --> 00:20:33.470
as a, as a, as
a programming languages and other

290
00:20:33.470 --> 00:20:36.890
interface. Yeah. What about a
DSL? What about a domain

291
00:20:36.890 --> 00:20:40.070
specific language or query language?
Is there a standard around

292
00:20:40.070 --> 00:20:45.080
graph databases as there is
around object relational days? That's

293
00:20:45.080 --> 00:20:48.460
a very good question. Actually,
we don't anything like that

294
00:20:48.460 --> 00:20:52.480
right now. Although we have
a side project, which is,

295
00:20:52.810 --> 00:20:56.080
you know, using Trinity as
a platform and we are

296
00:20:56.080 --> 00:21:00.790
building now RDF data store,
uptown Trinity. And for that

297
00:21:00.820 --> 00:21:05.470
project, we have the traditional
sparkle as a query language

298
00:21:05.830 --> 00:21:09.430
to query the, the RDF
data. But of course, I

299
00:21:09.430 --> 00:21:14.410
mean, sparkle is highly limited.
They express expressive power. Sparkle

300
00:21:14.420 --> 00:21:19.330
is either eliminated it's okay
for various standard RDF chorus,

301
00:21:19.360 --> 00:21:24.340
but a lot of RAF
operations cannot be expressed using

302
00:21:24.340 --> 00:21:28.240
sparkles. But at this moment,
we actually don't have a

303
00:21:28.240 --> 00:21:34.510
domain specific language for quarrying
graph data. And, and it

304
00:21:34.510 --> 00:21:38.170
is actually one of our
research focus and the were

305
00:21:38.590 --> 00:21:46.810
thinking about designing more flexible
Cory press form programming platform

306
00:21:46.810 --> 00:21:51.670
for, for graph data. But
on the other hand, we

307
00:21:51.670 --> 00:22:00.610
do have programming module, which
is close to project implemented

308
00:22:00.610 --> 00:22:04.650
in Google. So for example,
the users will, are just

309
00:22:04.660 --> 00:22:10.810
to write a very, very
simple script for specifying what

310
00:22:10.810 --> 00:22:14.770
kind of things and single
node will do in each

311
00:22:14.770 --> 00:22:18.490
round of computation. Like, you
know, it will accept some

312
00:22:18.490 --> 00:22:23.020
messages from its neighbors and
perform some action science messages

313
00:22:23.020 --> 00:22:27.250
and then send out messages
to its neighbors. So the

314
00:22:27.250 --> 00:22:30.550
user will just provide a
script to describe this kind

315
00:22:30.550 --> 00:22:34.840
of actions and the system
would take care of their

316
00:22:34.870 --> 00:22:40.210
parallel execution. So this is
how the offline analytics is

317
00:22:40.210 --> 00:22:44.830
being implemented. Trinity, of course,
this is just the one

318
00:22:44.830 --> 00:22:47.740
scenario and the other scenario,
for example, we also provide

319
00:22:48.460 --> 00:22:54.520
breathless such and as we,
you know, going to every

320
00:22:54.520 --> 00:22:59.240
node I don't in the
breastfed search and the, and

321
00:22:59.320 --> 00:23:03.490
then we will execute a
script specified by the user

322
00:23:03.520 --> 00:23:09.720
on each node. That's another
programming model. Do, do you

323
00:23:09.720 --> 00:23:14.520
see graph databases being something
that the average person's going

324
00:23:14.520 --> 00:23:17.040
to know about? Like, I,
I wouldn't have said five

325
00:23:17.040 --> 00:23:18.600
years ago or 10 years
ago that there would be

326
00:23:18.600 --> 00:23:21.900
much interest in, in document
databases, but they seem to

327
00:23:21.900 --> 00:23:24.750
have really come of age.
The last few years we've

328
00:23:24.750 --> 00:23:28.050
got object relational databases. There
were in fact, a lot

329
00:23:28.050 --> 00:23:31.560
of object oriented databases over
the last 20 years. Although

330
00:23:31.560 --> 00:23:34.570
I don't think they've necessarily
broken into the mainstream is,

331
00:23:34.570 --> 00:23:37.620
is graph data something that
will be kind of obscure

332
00:23:37.620 --> 00:23:39.450
and on the, on the
edge, or do you think

333
00:23:39.450 --> 00:23:41.760
it'll be something that the
average programmer will be using

334
00:23:41.760 --> 00:23:47.900
in, in five or 10
years? Think there's a Possibility

335
00:23:47.900 --> 00:23:50.750
that the graph is going
to be adopted as a

336
00:23:50.750 --> 00:23:58.360
major, even most important data
structuring our future applications. So

337
00:23:58.370 --> 00:24:00.890
if you think about it,
I mean, the data is

338
00:24:00.890 --> 00:24:03.830
getting more and more complex.
And if the data, the

339
00:24:03.830 --> 00:24:07.970
complexity of data is, you
know, it's very limited and

340
00:24:07.970 --> 00:24:11.000
the size of the data
is also limited. Then we

341
00:24:11.000 --> 00:24:16.610
can comfortably use a relational
database like SQL server to

342
00:24:16.610 --> 00:24:20.780
provide, you know, support for
these kinds of applications. But

343
00:24:20.810 --> 00:24:25.730
the reality is beta is
getting more and more complex

344
00:24:25.730 --> 00:24:30.980
in almost every domain in
search in, in, in scientific

345
00:24:31.010 --> 00:24:35.330
computing, for example, bioinformatics and
the UN you know, social

346
00:24:35.330 --> 00:24:38.480
networks and everything. Data is
getting more in a more

347
00:24:38.480 --> 00:24:44.090
complex and you can use,
you know, tables to represent

348
00:24:44.090 --> 00:24:47.930
those data and hope you
will have, you know, model

349
00:24:47.930 --> 00:24:50.480
the data very, very nicely.
And on the other hand,

350
00:24:50.480 --> 00:24:53.600
of course, the size of
the data is getting bigger

351
00:24:53.600 --> 00:24:56.720
and bigger. So this is
extra opens up a huge

352
00:24:56.720 --> 00:25:01.790
space, which traditional database cannot
solve because they are only

353
00:25:01.790 --> 00:25:06.830
good for small data. And,
you know, not that complex

354
00:25:06.830 --> 00:25:12.320
data and the graph data
will be, you know, a

355
00:25:12.320 --> 00:25:17.330
very important player in this
better, better, big space. A

356
00:25:17.330 --> 00:25:22.640
lot of applications will rely
on graph data and the,

357
00:25:22.640 --> 00:25:27.020
we actually have got a
risk sensitive, many minute requests

358
00:25:27.440 --> 00:25:32.000
the, about, you know, what
Trinity can do for, you

359
00:25:32.000 --> 00:25:37.790
know, some specific applications in
gain domain in scientific computing,

360
00:25:37.820 --> 00:25:41.900
bio applications and things like
that. So I can't foresee

361
00:25:42.080 --> 00:25:48.500
many, many interesting applications that
will require a very, very

362
00:25:48.500 --> 00:25:54.370
flexible system that can support
graph data. What do you

363
00:25:54.370 --> 00:25:58.870
think about some of the
newer graph data? I wouldn't

364
00:25:58.870 --> 00:26:02.770
say necessarily formal databases, but
implementations of graph like databases

365
00:26:02.770 --> 00:26:07.570
using distributed memory structures, like
for example, a Reddis graph

366
00:26:07.630 --> 00:26:10.900
and some naive implementations of
a social graph using Reddis

367
00:26:11.170 --> 00:26:15.940
flock DB, what Twitter used
for, for their graph database.

368
00:26:16.930 --> 00:26:18.910
As do you think that
these are, you know, fully

369
00:26:18.910 --> 00:26:21.910
fledged graph databases that could
compete, or these are, are

370
00:26:21.910 --> 00:26:26.050
these just naive implementations over
a standard distributed in memory

371
00:26:26.050 --> 00:26:30.880
data structure? I think they
can support certain kinds of

372
00:26:30.880 --> 00:26:35.260
graph operations, but definitely not
all range of graph operations.

373
00:26:36.070 --> 00:26:43.000
So for example, many social
networks, including Facebook, really you,

374
00:26:43.770 --> 00:26:49.710
the users does not have
the power to actually go

375
00:26:49.710 --> 00:26:55.140
through the huge social network
to find information of his

376
00:26:55.140 --> 00:26:57.510
neighbors and the neighbors, neighbors,
and so on and so

377
00:26:57.510 --> 00:27:03.300
forth. What social network, what
Facebook provides on their website

378
00:27:03.480 --> 00:27:07.560
is basically when I use
a logging, it provides information

379
00:27:07.560 --> 00:27:11.070
about, you know, his friends,
his direct friends. So there's

380
00:27:11.070 --> 00:27:18.120
really just a one step
multiple hops on this huge

381
00:27:18.120 --> 00:27:21.600
graph. So if this is
the case, then Kibera, pear

382
00:27:21.990 --> 00:27:24.270
is done very in a
very nice solution. So the

383
00:27:24.270 --> 00:27:27.750
key value pairs will provide
the information of four. You

384
00:27:27.750 --> 00:27:31.050
can think of it as
providing information of it for

385
00:27:31.050 --> 00:27:36.090
its director neighbors, but as
graph operations get more complex.

386
00:27:36.450 --> 00:27:41.280
And the, you know, some
applications usually, you know, analytics

387
00:27:41.280 --> 00:27:48.540
applications that require exploring this
graph database, exploring this huge

388
00:27:48.570 --> 00:27:53.160
graphs around those passes and,
you know, a very large

389
00:27:53.160 --> 00:27:58.410
scale, then those key Vero
pesto will not, you know,

390
00:27:58.410 --> 00:28:02.130
function with better wealth. So
because fundamentally, they still require

391
00:28:02.490 --> 00:28:06.000
a lot of joins, a
lot of index to, for

392
00:28:06.000 --> 00:28:09.360
the, for, for exploration for,
for going from one note

393
00:28:09.450 --> 00:28:13.560
to the other notes. So
that's the fundamental problem with

394
00:28:13.560 --> 00:28:18.080
those kinds of approach. And
then in conclusion, where do

395
00:28:18.080 --> 00:28:21.110
you see your project going?
Is it always the goal

396
00:28:21.110 --> 00:28:24.050
of a researcher to get
a project to become a

397
00:28:24.050 --> 00:28:28.160
product, or is it simply
your goal to, to expand

398
00:28:28.160 --> 00:28:29.780
the knowledge in the space
and leave it up to

399
00:28:29.780 --> 00:28:31.760
the product people to figure
out if they'll sell it

400
00:28:31.760 --> 00:28:35.120
or not? Oh, so, well,
of course we are still

401
00:28:35.120 --> 00:28:39.620
a research prototype, but we
are actually working with a

402
00:28:39.620 --> 00:28:47.030
few product teams within Microsoft
to support their applications. So

403
00:28:47.030 --> 00:28:50.420
for example, we have within
Microsoft. So we dealing with

404
00:28:50.450 --> 00:28:54.500
the web graph where dealing
with the, you know, the,

405
00:28:54.590 --> 00:28:58.280
the search, the search log
end of the graph and

406
00:28:58.280 --> 00:29:01.430
were dealing with the social
graph. So we are using

407
00:29:02.120 --> 00:29:05.300
well working with the product
team to use Trinity to

408
00:29:05.300 --> 00:29:09.710
support those kinds of applications.
And as our, you know,

409
00:29:10.220 --> 00:29:14.720
our vision is to provide
a general purpose graph computation

410
00:29:14.720 --> 00:29:22.730
platform. So using these applications
where basically trying to see

411
00:29:22.730 --> 00:29:27.530
what is the most, what
is the priority for improving

412
00:29:27.530 --> 00:29:31.100
our system? And then eventually
we try, we would like

413
00:29:31.100 --> 00:29:34.670
to provide this system, you
know, as a general purpose

414
00:29:35.120 --> 00:29:37.550
system for a new kind
of data, which is the

415
00:29:37.550 --> 00:29:40.730
graph data, Actually one last
question, just to get a

416
00:29:40.730 --> 00:29:43.540
sense size. So the, so
the listeners who are going

417
00:29:43.540 --> 00:29:45.790
to go off and research
this themselves and learn more

418
00:29:45.790 --> 00:29:48.850
about your stuff can understand.
I know that as of

419
00:29:48.850 --> 00:29:55.510
a mid, mid 2010 Twitters
graph data called flock DB

420
00:29:55.900 --> 00:30:00.670
had about 13, 13 billion edges,
and they were doing traffic

421
00:30:00.670 --> 00:30:04.390
of about 20,000, writes a
second, and 100,000 reads a

422
00:30:04.390 --> 00:30:07.630
second. So about 13 billion edges.
And I'm sure they've increased

423
00:30:07.630 --> 00:30:10.180
since that. Do you have
a sense of how big

424
00:30:10.210 --> 00:30:16.920
Trinity can get? So, you
know, we haven't tried well,

425
00:30:16.950 --> 00:30:19.890
we're still working with the
product team to try, you

426
00:30:19.890 --> 00:30:23.460
know, to, to use Chinetti
for the web graph. So

427
00:30:23.460 --> 00:30:27.360
we're still skewing the process
of it, but certain billing

428
00:30:27.420 --> 00:30:33.150
edge is actually not that
big. So, because for example,

429
00:30:33.150 --> 00:30:36.810
we are dealing with the
web graph, which has, for

430
00:30:36.810 --> 00:30:42.660
example, 200 billion nodes. And for
each node is basically a

431
00:30:42.660 --> 00:30:46.680
webpage and each node on
average, we'll have 42 50

432
00:30:47.550 --> 00:30:51.030
ads. So if you times
the two together, then it

433
00:30:51.060 --> 00:30:55.770
is much bigger than a
social graph. So basically web

434
00:30:55.800 --> 00:30:59.910
graph is still the largest
graph on the earth. I

435
00:30:59.910 --> 00:31:03.300
mean, may, may the graph
on the earth it's much,

436
00:31:03.300 --> 00:31:06.360
much larger than the social
graph. So we are trying

437
00:31:06.360 --> 00:31:10.680
to use Trinity to support
that. Wow, that's really, that's

438
00:31:10.680 --> 00:31:14.340
really comforting to know that
you can think about edges

439
00:31:14.340 --> 00:31:16.500
in the terms of billions
and billions and not think

440
00:31:16.500 --> 00:31:18.750
of it as being too
large, that, that speaks really

441
00:31:18.750 --> 00:31:22.320
well for the work that
you guys are doing well,

442
00:31:22.320 --> 00:31:24.360
thanks so much for chatting
with me today. I really

443
00:31:24.360 --> 00:31:27.630
appreciate it. And, you know,
giving people outside the research

444
00:31:27.630 --> 00:31:30.780
community, an opportunity to learn
more about what you're doing

445
00:31:30.780 --> 00:31:36.180
in, in Microsoft research. Thanks
for having me. This has

446
00:31:36.180 --> 00:31:39.060
been another episode of Hansel
minutes, big thanks to high

447
00:31:39.060 --> 00:31:42.270
Shang Wong and the folks
at Microsoft research Asia, we

448
00:31:42.270 --> 00:31:47.730
will see you again next
week. <inaudible>.

