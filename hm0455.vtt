WEBVTT FILE

1
00:00:00.570 --> 00:00:03.750
Hi, this is Scott. I
really appreciate our sponsors because

2
00:00:03.750 --> 00:00:06.690
they make the show possible.
Today's show is sponsored by

3
00:00:06.690 --> 00:00:10.890
developer express, become a UI
superhero with dev express controls

4
00:00:10.890 --> 00:00:15.420
and libraries. Deliver elegant.net solutions
that address customer needs today

5
00:00:15.780 --> 00:00:19.860
by leveraging your existing knowledge,
you can build next generation

6
00:00:19.890 --> 00:00:24.000
touch enabled solutions for tomorrow,
you can download your free

7
00:00:24.090 --> 00:00:48.800
30 day trial@dxdothanselminutes.com. That's dx.hanselminutes.com
From hanselminutes.com. It's Hanselman. It's

8
00:00:49.070 --> 00:00:53.030
a weekly discussion with web
developer and technologist Scott Hanselman.

9
00:00:53.690 --> 00:00:57.860
This is Lawrence Ryan announcing show
number four 58. In this

10
00:00:57.860 --> 00:01:01.160
episode, Scott talks with Matt
Warren about how to make

11
00:01:01.160 --> 00:01:07.460
performance a feature of your
application. Hi, this is Scott

12
00:01:07.460 --> 00:01:10.250
Hanselman. This is another episode
of Hansel minutes, and I'm

13
00:01:10.250 --> 00:01:13.400
talking with Matt Warren, who
is a performance expert. How

14
00:01:13.400 --> 00:01:16.100
are you all? Good. Thanks
Scott. Yes. All good. Thanks.

15
00:01:16.730 --> 00:01:20.120
And you just came off
a talk at NDC London

16
00:01:20.420 --> 00:01:23.090
talking about performance as a
feature. How did that go?

17
00:01:23.570 --> 00:01:25.400
Yeah, I think it went
well. I was, as in

18
00:01:25.400 --> 00:01:28.370
the, maybe call it the
graveyard slot a Friday off

19
00:01:28.370 --> 00:01:30.650
name, but nights that seemed
to be decent of people

20
00:01:30.650 --> 00:01:33.620
there. And it's, I think
there's other people who want

21
00:01:33.620 --> 00:01:36.710
to find out about before
once. Like I've been trying

22
00:01:36.710 --> 00:01:38.330
to do myself, so yeah,
I think he's a good

23
00:01:38.720 --> 00:01:41.360
seems to be a popular
topic anyway. And you've made

24
00:01:41.360 --> 00:01:44.390
this kind of like your,
your, your, your favorite thing,

25
00:01:44.390 --> 00:01:47.000
like performance is now what
you do, you focused on

26
00:01:47.000 --> 00:01:49.580
performance and decided that you
would dig into it as

27
00:01:49.580 --> 00:01:53.270
deeply as you could. Yeah.
Certain in terms of what

28
00:01:53.270 --> 00:01:56.030
I blog about and what
I spend my free time

29
00:01:56.030 --> 00:01:57.860
looking into if you like
and things like that. So,

30
00:01:57.860 --> 00:02:01.700
yeah. Yeah. It's definitely my,
my focus, my, my pet

31
00:02:01.700 --> 00:02:04.460
hobby, maybe as a way
of saying it. Yeah. And

32
00:02:04.460 --> 00:02:09.470
on your, on your blog@mattwarren.org,
you have dug into a

33
00:02:09.470 --> 00:02:13.400
number of interesting things, particularly
stack overflow, even though you're

34
00:02:13.400 --> 00:02:16.520
not a, an employee of
stack overflow, you've dug into

35
00:02:16.520 --> 00:02:19.310
how they deal with performance.
And then also the interestingly,

36
00:02:19.310 --> 00:02:22.370
the Roslyn code base, the
code base of the open

37
00:02:22.370 --> 00:02:29.210
source C-sharp compilers. Yeah. Yeah.
So I think, I think

38
00:02:29.660 --> 00:02:31.810
I started with the Roslyn
when I commented by that

39
00:02:31.820 --> 00:02:36.200
the idea of looking into
these public code codebases or

40
00:02:36.230 --> 00:02:38.690
public projects or public companies,
if you like, who are

41
00:02:38.690 --> 00:02:43.280
open about what they're doing,
particularly around performance and in

42
00:02:43.280 --> 00:02:46.460
the case of Roslyn, I'm
thinking that it's going to

43
00:02:46.460 --> 00:02:49.400
be a good example of
how best practices for C

44
00:02:49.400 --> 00:02:53.030
sharp has. It's the C
sharp compiler team writing it

45
00:02:53.150 --> 00:02:56.360
and Microsoft C sharp dates.
And then obviously stack overflow

46
00:02:56.360 --> 00:03:01.090
is a, is a very
high profile. They're very big

47
00:03:01.090 --> 00:03:05.200
on performance because you know,
the top 50 website and

48
00:03:05.230 --> 00:03:08.590
they, their basic thing is
they run on a fairly

49
00:03:08.590 --> 00:03:10.840
high profile, fairly high spec
machines, but they run with

50
00:03:11.290 --> 00:03:14.380
very little CPU usage. So
they really care about performance

51
00:03:14.380 --> 00:03:16.150
and that's their way that
they can get scaling from

52
00:03:16.150 --> 00:03:18.880
my understanding looking in. So
yeah, I thought of, I

53
00:03:18.910 --> 00:03:22.120
thought that I'd take a
look at the code base

54
00:03:22.120 --> 00:03:25.030
in particular, but also some
of the projects they might

55
00:03:25.030 --> 00:03:28.420
release or the Roslyn as
all the discussions on copex

56
00:03:28.420 --> 00:03:30.700
that go into some of
the things they're doing, there's

57
00:03:30.700 --> 00:03:32.590
been a few talks and
stuff by some of the

58
00:03:32.590 --> 00:03:34.750
people in the Roslyn team
have gone into this as

59
00:03:34.750 --> 00:03:36.940
well. So yeah, it's a
lot to take a chance

60
00:03:36.940 --> 00:03:39.130
to see what was around
and what, from the performance

61
00:03:39.130 --> 00:03:41.820
side of things, Doesn't it
seem like, kind of, when

62
00:03:41.820 --> 00:03:44.640
you talk to your, your
friends at other companies that

63
00:03:44.640 --> 00:03:46.500
are working on things, I
know this is the case

64
00:03:46.500 --> 00:03:49.530
with my friends is that
they almost feel like they're

65
00:03:49.530 --> 00:03:53.010
taking performance as an afterthought
and when it becomes a

66
00:03:53.010 --> 00:03:56.640
problem, then it's a big,
let's all freak out and

67
00:03:56.640 --> 00:04:01.410
try to make the system
performance. Yeah. Yeah. I mean,

68
00:04:01.410 --> 00:04:03.900
I think that there's always
this thing, I we'll, we'll,

69
00:04:03.900 --> 00:04:06.180
we'll fix a performance before
the site goes live, but

70
00:04:06.180 --> 00:04:08.130
we'll do it, you know,
one of the sprints, you

71
00:04:08.130 --> 00:04:09.360
know, at the end and
we kind of know what

72
00:04:09.360 --> 00:04:11.670
happens to those sprints at
the end, they get there's

73
00:04:11.670 --> 00:04:13.620
all the other stuff that,
that didn't quite get done

74
00:04:13.620 --> 00:04:16.470
in the previous ones. So,
yeah, I think there's definitely

75
00:04:16.470 --> 00:04:18.870
that you can be a,
if not an afterthought, at

76
00:04:18.870 --> 00:04:22.440
least maybe not the priority.
And yeah, I think we'd

77
00:04:22.440 --> 00:04:24.780
all prefer to be able
to fix a performance feature

78
00:04:24.780 --> 00:04:26.820
before our customers told us
about it. That's probably the

79
00:04:26.820 --> 00:04:29.550
other part of it is,
you know, if the first

80
00:04:29.550 --> 00:04:31.260
time we find we've got
performance issues is when the

81
00:04:31.260 --> 00:04:34.110
site goes down, that's not
a great time to be

82
00:04:34.680 --> 00:04:37.440
fixing performance or trying to
recreate performance or things like

83
00:04:37.440 --> 00:04:40.620
that. So it's yeah, the,
the, the idea behind the

84
00:04:40.620 --> 00:04:44.100
performance is a feature is,
is the kind of tagline

85
00:04:44.100 --> 00:04:48.180
of given certain it's something
I shamelessly borrowed from Jeff

86
00:04:48.180 --> 00:04:50.070
Atwood's. He came up with
it in terms of stack

87
00:04:50.070 --> 00:04:52.440
overflow. But the idea is
that we give it the

88
00:04:52.440 --> 00:04:56.640
same priorities that we might
give security in our website,

89
00:04:56.640 --> 00:04:59.670
or we might give functional
features or things like that.

90
00:04:59.670 --> 00:05:01.590
And then trying to see
what that looks like at

91
00:05:01.650 --> 00:05:04.380
places at that's done, which
I believe stack overflow is

92
00:05:04.380 --> 00:05:07.380
one. And then the Roslyn
K base is another. Yeah,

93
00:05:07.380 --> 00:05:10.680
it's always so surprising to
me how, how tolerant big

94
00:05:10.680 --> 00:05:14.190
enterprises and the kind of
the internal projects will people

95
00:05:14.190 --> 00:05:16.590
will be like, they will
be tolerant of five and

96
00:05:16.590 --> 00:05:20.880
10, second long, you know,
page loads. And I just

97
00:05:20.880 --> 00:05:25.260
can't imagine that that is
okay. It's almost like the

98
00:05:25.260 --> 00:05:28.140
old adage of, you know,
how do you boil a

99
00:05:28.140 --> 00:05:31.740
frog and you boil a
frog slowly. So the clock

100
00:05:31.750 --> 00:05:34.260
doesn't actually know it's being
boiled and then bring a

101
00:05:34.260 --> 00:05:36.660
new employee in and say,
Hey, look at the performance

102
00:05:36.660 --> 00:05:38.280
in this site, it's sucks.
They're going to be like,

103
00:05:38.670 --> 00:05:40.920
this water is hot and
jump right out. Like, why

104
00:05:40.920 --> 00:05:42.570
would you let it get
this bad? Well, I don't

105
00:05:42.570 --> 00:05:46.390
know. The water kind of
got hot slowly. Yeah, well,

106
00:05:47.070 --> 00:05:49.500
yeah. I mean, cause there's,
there's, there's quite a famous

107
00:05:49.500 --> 00:05:52.470
stat about Google in terms
of they shave, you know,

108
00:05:52.470 --> 00:05:55.280
they artificially made their web
pages go some bit slower

109
00:05:55.280 --> 00:05:57.380
and I lost laser customers.
And then like say the

110
00:05:57.380 --> 00:05:59.780
other extreme is, tends to
be the internal apps or

111
00:06:00.110 --> 00:06:02.060
line of business apps, or,
you know, where you say,

112
00:06:02.120 --> 00:06:04.370
like you say, they might
get slower and slower over

113
00:06:04.370 --> 00:06:06.530
time. But even though, as
you could probably argue, you

114
00:06:06.530 --> 00:06:09.080
know, if the, if the
internal app is being used

115
00:06:09.080 --> 00:06:11.960
by signing your company, and
they're wasting 10 minutes a

116
00:06:11.960 --> 00:06:14.270
day, half an hour a
week, you know, that soon

117
00:06:14.330 --> 00:06:15.980
adds up over a year,
what could they be doing

118
00:06:15.980 --> 00:06:18.080
with that time? So whilst
they've got, in some ways

119
00:06:18.080 --> 00:06:20.120
they've got no choice, they
can't leave you as a

120
00:06:20.120 --> 00:06:23.150
customer because it's an internal
app. I still think even

121
00:06:23.150 --> 00:06:25.970
in there, you have to
always justify the time to

122
00:06:26.240 --> 00:06:28.100
fix it versus the time
it saves. But I think

123
00:06:28.100 --> 00:06:30.920
there's even an argument sometimes
to not get into the

124
00:06:30.920 --> 00:06:33.200
situation you're talking about, where
these apps just get slower

125
00:06:33.200 --> 00:06:34.850
and slower over time. And
then before you know, it,

126
00:06:34.850 --> 00:06:37.370
someone's spending half an hour
a day to do something

127
00:06:37.370 --> 00:06:40.150
that should take five minutes.
Yeah. If you, if you

128
00:06:40.150 --> 00:06:42.490
have the problem that your
site is too fast and

129
00:06:42.490 --> 00:06:44.440
you have to slow it
down artificially, that's a pretty

130
00:06:44.440 --> 00:06:47.740
good problem to have. I
know that Troy hunt famously

131
00:06:47.740 --> 00:06:50.590
did that on his, have
I been poned website, he

132
00:06:50.590 --> 00:06:54.490
added a little sleep because
it was too fast because

133
00:06:54.490 --> 00:06:55.750
you know, you have to
have the sense of work

134
00:06:55.750 --> 00:06:59.140
being done. Work does 10
milliseconds. Yeah. I think people

135
00:06:59.140 --> 00:07:01.510
have this expectation that if
this happens instantly, it's not

136
00:07:01.510 --> 00:07:05.110
really done it. Yeah. Yeah.
Yeah. I think from my

137
00:07:05.110 --> 00:07:06.610
own son to that test
with Google, I did like

138
00:07:06.610 --> 00:07:08.800
an AB testing type thing.
And they saw, you know,

139
00:07:09.370 --> 00:07:11.320
we don't all operate at
a Google scale of things,

140
00:07:11.320 --> 00:07:13.630
but, you know, there's, there's
probably some scale for, for

141
00:07:13.630 --> 00:07:15.490
all of us where people
are going to get annoyed

142
00:07:15.490 --> 00:07:18.850
or leave our site or
refuse to buy our product

143
00:07:18.850 --> 00:07:20.860
again, all those sorts of
things and where that comes.

144
00:07:20.860 --> 00:07:23.020
You know, I'm not saying
we would have to shave

145
00:07:23.450 --> 00:07:26.650
half a second off our
page load times that's maybe

146
00:07:26.650 --> 00:07:29.400
an extreme, but there's, there's
some level of it. And

147
00:07:29.410 --> 00:07:32.110
maybe, yeah. Not, not continuously
letting things like you say,

148
00:07:32.140 --> 00:07:34.180
boiling the frog over and
over until it's so bad.

149
00:07:35.200 --> 00:07:39.280
It's unusable, Google. Actually, interestingly
just last week is testing

150
00:07:39.280 --> 00:07:43.060
a new feature on their
Android devices where the check

151
00:07:43.060 --> 00:07:45.010
this out you'll, you'll, you'll
want to interested in what

152
00:07:45.010 --> 00:07:51.220
you think about this, their
search results contain hints to

153
00:07:51.220 --> 00:07:55.870
what the most heavy thing,
the most heavy resource is

154
00:07:55.870 --> 00:07:58.360
on that particular page. You're
about to go to so

155
00:07:58.360 --> 00:08:01.690
that when you click on
a result on mobile, they

156
00:08:01.690 --> 00:08:04.630
will start, prefetching like a
large CSS file or a

157
00:08:04.630 --> 00:08:08.200
bait JavaScript file in anticipation
of you heading over to

158
00:08:08.200 --> 00:08:11.230
that page. And apparently they're
saying it's shaved a hundred

159
00:08:11.230 --> 00:08:15.760
milliseconds off the average search
result within that browser. Oh,

160
00:08:15.760 --> 00:08:18.610
nice. Nice. Yeah, because I
know that I know before

161
00:08:18.610 --> 00:08:21.940
they've done certainly in Chrome
anyway, they do pre-loading of

162
00:08:21.940 --> 00:08:23.830
links. I think you might
go see to do that

163
00:08:23.830 --> 00:08:25.960
sort of idea and it's
yeah. I think it's the

164
00:08:25.960 --> 00:08:28.270
way things are going. Isn't
it, everyone, everyone, the bar's

165
00:08:28.270 --> 00:08:31.870
being raised constantly, isn't it
in Gmail or whoever came

166
00:08:31.870 --> 00:08:35.140
along and showed what a
fast JavaScript application looked like.

167
00:08:35.140 --> 00:08:37.390
And now the old style
applications that people were happy

168
00:08:37.390 --> 00:08:39.370
with, I don't know, 10
years ago, or whenever it

169
00:08:39.370 --> 00:08:42.310
was people aren't happy with
anymore. Yeah. Like you say,

170
00:08:42.540 --> 00:08:45.700
these things are going up
and up and pulling out

171
00:08:45.700 --> 00:08:48.160
all the tricks, I guess
once you've done, you know,

172
00:08:48.190 --> 00:08:51.370
you've minified your page and
your GS apps and all

173
00:08:51.370 --> 00:08:52.720
that sort of stuff, you
have to look at these

174
00:08:52.720 --> 00:08:55.740
things like prefetching. But yeah,
it sounds a nice, nice

175
00:08:55.740 --> 00:08:58.580
technique all, and let's, let's
do Into this from a

176
00:08:58.580 --> 00:09:00.650
low, much lower level. The
goal of course, is to

177
00:09:00.650 --> 00:09:04.460
make things feel fast for
the user, but taking performance

178
00:09:04.460 --> 00:09:07.460
seriously is kind of the
most important thing. I noticed

179
00:09:07.490 --> 00:09:10.040
that on your analysis of
the Roslyn code base, which

180
00:09:10.040 --> 00:09:12.290
is a really big code
base, we're talking about 2 million

181
00:09:12.290 --> 00:09:15.920
plus lines of code. It
seemed like they were measuring

182
00:09:16.310 --> 00:09:20.560
performance against a number of
scenarios. Yeah. They had, they

183
00:09:20.570 --> 00:09:22.460
had a couple of things.
So, so one thing they

184
00:09:22.460 --> 00:09:26.030
do is like you say,
they look at small, medium

185
00:09:26.030 --> 00:09:29.180
and large solutions. I mean,
my understanding again, from looking

186
00:09:29.180 --> 00:09:30.830
on the outside in is
that the Roslyn is a

187
00:09:30.830 --> 00:09:34.220
compiler. Can't be slower than
the previous competitors because us,

188
00:09:34.220 --> 00:09:36.530
as you know, that's using
visual studio, not, we're not

189
00:09:36.530 --> 00:09:40.250
going to like that. And
also Roslyn has a, a

190
00:09:40.310 --> 00:09:42.950
slightly unique thing and it's
doing something on every key

191
00:09:42.950 --> 00:09:45.170
press as the kind of
big full build, but there's

192
00:09:45.170 --> 00:09:47.900
also the stuff it does
to power IntelliSense and all

193
00:09:47.900 --> 00:09:49.760
that sort of stuff going
on. So there's, there's quite

194
00:09:50.270 --> 00:09:53.930
tight things as, as, and
from what I understand is

195
00:09:53.930 --> 00:09:56.330
that they basically categorized it.
So this is something that

196
00:09:56.330 --> 00:09:58.220
happens on a key press.
So we have one level

197
00:09:58.220 --> 00:10:01.460
of performance. This is something
that happens in line with

198
00:10:01.460 --> 00:10:03.530
a build. So we have
another type of thing, you

199
00:10:03.530 --> 00:10:06.860
know, so there's that kind
of categorization. And then they

200
00:10:06.860 --> 00:10:10.820
took that and did that
as a continuous build. So

201
00:10:10.820 --> 00:10:13.850
every time they built, they
run all this stuff and

202
00:10:13.850 --> 00:10:17.060
see that if they are
very least daily, I think

203
00:10:17.060 --> 00:10:19.370
in possibly even more than
that in the same way

204
00:10:19.370 --> 00:10:21.800
that we run unit tests
regularly to see if the

205
00:10:21.800 --> 00:10:24.020
vary a bit of code
of just tucked in as,

206
00:10:24.040 --> 00:10:27.650
as broken something, the same
idea that we run performance

207
00:10:27.650 --> 00:10:30.380
tests and say that we
know straight away that some

208
00:10:30.380 --> 00:10:32.990
bit of code that might
be fixing something has also

209
00:10:33.950 --> 00:10:36.740
harmed the performance and they
have that idea and they

210
00:10:36.740 --> 00:10:41.450
look at a lapsed time,
average time percentile, that sort

211
00:10:41.450 --> 00:10:43.460
of things like digging quite
deeply. And then the making

212
00:10:43.460 --> 00:10:46.880
sure that they cover at
the very least the hot

213
00:10:46.880 --> 00:10:48.770
path and these things that
happen on every key press.

214
00:10:48.770 --> 00:10:50.510
But I'm sure they've got
in the background, this idea

215
00:10:50.510 --> 00:10:53.000
of, well, what does this
performance look like? If someone

216
00:10:53.000 --> 00:10:56.120
opens up a solution with
a thousand CS project files

217
00:10:56.120 --> 00:10:59.780
in it, and then what's
going to happen then, And

218
00:10:59.780 --> 00:11:03.530
they did that with, you
know, with, for lack of

219
00:11:03.530 --> 00:11:06.620
a better word, manage your
sponsorship, right? This isn't a

220
00:11:06.620 --> 00:11:08.990
hobby, this isn't someone doing
this in their spare time.

221
00:11:08.990 --> 00:11:11.750
Like this is important. It's
baked into the team that,

222
00:11:11.800 --> 00:11:17.270
that these performance numbers matter.
Yeah. That's interesting. There's a

223
00:11:17.270 --> 00:11:20.600
little pit. So I picked
up from, from, from some

224
00:11:20.600 --> 00:11:22.760
of the stuff on discussions,
my understanding is that there's

225
00:11:22.760 --> 00:11:26.240
a, at least one engineer
or maybe others who deal

226
00:11:26.240 --> 00:11:29.570
with performance. And so they
would, might take a look

227
00:11:29.570 --> 00:11:32.900
at the basis cause you
don't want to necessarily prioritize

228
00:11:32.900 --> 00:11:37.160
performance in everything you do,
because sometimes there's a whole

229
00:11:37.160 --> 00:11:41.090
thing about premiere chair optimization
and you don't want to

230
00:11:41.840 --> 00:11:43.670
optimize stuff for the sake
of it, or you don't

231
00:11:43.670 --> 00:11:47.660
want to optimize something that
the, the, the time it

232
00:11:47.660 --> 00:11:50.810
takes to optimize is not
worth the payback you get

233
00:11:50.810 --> 00:11:54.460
from the faster code. So
from my understanding, the sounds

234
00:11:54.520 --> 00:11:56.470
come in at some point
in the, in a development,

235
00:11:56.470 --> 00:11:59.350
obviously they're smart dads and
they've had this tried to

236
00:11:59.350 --> 00:12:01.330
write the best code they
can while they're doing it

237
00:12:01.330 --> 00:12:03.490
going through. But then someone
stepped in and looked at

238
00:12:03.490 --> 00:12:06.670
the particular hot pass, profile
it and tried to understand

239
00:12:06.670 --> 00:12:08.470
what no, this part is
going slowly. What can we

240
00:12:08.470 --> 00:12:11.740
do here? Or this part
is not performing as quickly

241
00:12:11.740 --> 00:12:13.930
as we need it to,
we can take a look

242
00:12:13.930 --> 00:12:15.530
here. So yeah, like you
say, it's, I think there's

243
00:12:15.820 --> 00:12:18.640
something structured. It's not a,
it's not an accident. I

244
00:12:18.640 --> 00:12:20.800
think that's, that's part of
it as well. You, you,

245
00:12:21.360 --> 00:12:23.560
you have to take some
steps to do this stuff.

246
00:12:23.560 --> 00:12:27.520
You can't like, you can't
necessarily rely on just finding

247
00:12:27.520 --> 00:12:31.120
fluence issues in development by
accident because you don't test

248
00:12:31.120 --> 00:12:32.800
in the same way. You
don't have the same setup

249
00:12:32.800 --> 00:12:36.010
as production. So you there's
some possibly some deliberate steps

250
00:12:36.010 --> 00:12:38.560
you have to take to
say, look, this is our

251
00:12:38.590 --> 00:12:40.810
common part of our page,
or this is a common

252
00:12:40.810 --> 00:12:42.550
part of our product. Let's
see what this is, how

253
00:12:42.550 --> 00:12:44.920
this behaves, when we have
10,000 users or we run

254
00:12:44.920 --> 00:12:47.950
it 20 times a second
or whatever the scenario might

255
00:12:47.950 --> 00:12:50.330
be, as opposed to just
running it once and see,

256
00:12:50.330 --> 00:12:52.590
see how it works out.
Yeah. I think that one

257
00:12:52.590 --> 00:12:56.010
of the things that beginners
fall into is this idea

258
00:12:56.010 --> 00:12:59.670
of, of micro benchmarks, right?
You know, they think performance

259
00:12:59.670 --> 00:13:01.500
is a unit test that
they put it a little

260
00:13:01.500 --> 00:13:04.470
timer around and they may
be shove a thousand of

261
00:13:04.470 --> 00:13:07.140
something into a, into a
bundle or a list of

262
00:13:07.140 --> 00:13:09.090
some kind and do some
operation. They go, yeah, that's

263
00:13:09.090 --> 00:13:11.850
performance. But that may not
be reflective of how the

264
00:13:11.850 --> 00:13:15.450
product is ultimately used. And
in the Rosalind examples you

265
00:13:15.450 --> 00:13:19.110
gave, those are all real
world things like this is

266
00:13:19.110 --> 00:13:22.140
when a normal person types
and IntelliSense pops up and

267
00:13:22.140 --> 00:13:25.110
a normal person types at
this speed. This is reflective

268
00:13:25.110 --> 00:13:28.830
of an end to end
performance test. Yeah. Yeah. I

269
00:13:28.830 --> 00:13:32.580
definitely the idea that you,
you first look at something

270
00:13:32.580 --> 00:13:34.410
end to end, and then
yeah, you may, you may

271
00:13:34.410 --> 00:13:37.530
end up writing a, some
micro benchmark at the end

272
00:13:37.890 --> 00:13:40.560
because you've identified one bit
of code that, you know,

273
00:13:40.560 --> 00:13:44.190
should always perform under one
millisecond or which should always

274
00:13:44.190 --> 00:13:46.950
perform. It should never slow
down build to build that

275
00:13:46.950 --> 00:13:48.750
sort of thing. But yeah,
you're right. You should never

276
00:13:49.530 --> 00:13:52.230
start in just micro benchmarks
because it's too easy to

277
00:13:52.230 --> 00:13:55.440
get into details. That bit
of code might be called

278
00:13:55.440 --> 00:13:59.580
once in the entire runtime
of your application. So anything

279
00:13:59.580 --> 00:14:02.520
you do there is not
gonna make the difference. Whereas

280
00:14:02.790 --> 00:14:04.500
there's not be another bit
of code that is called

281
00:14:04.500 --> 00:14:06.660
a thousand times a second
or a thousand times a

282
00:14:06.660 --> 00:14:09.180
minute, or whatever that you
don't, you haven't looked into.

283
00:14:09.180 --> 00:14:11.700
So I think there is
a place for micro benchmarks.

284
00:14:12.930 --> 00:14:15.780
If you can start with
the higher level stuff and

285
00:14:15.780 --> 00:14:17.970
then drill down, if you
determined that there's one bit

286
00:14:17.970 --> 00:14:20.730
of code that needs to
always be very quick, that

287
00:14:20.730 --> 00:14:22.980
is justified. But yeah, as
you say, it's, and, and

288
00:14:23.040 --> 00:14:26.310
there's a, there's this tricky
stuff with, you know, benchmarks

289
00:14:26.310 --> 00:14:29.760
as you go on stack
overflow the site and you'll

290
00:14:29.760 --> 00:14:32.010
see the ways people can
get benchmarks wrong and you

291
00:14:32.010 --> 00:14:35.190
can measure things incorrectly. You
can not take account of

292
00:14:35.190 --> 00:14:37.920
the.net jitter that there's stuff
that needs to consider. Once

293
00:14:37.920 --> 00:14:40.410
you get into level of
micro benchmarks, to be sure

294
00:14:40.410 --> 00:14:43.980
that you really are measuring
the, the application, the sorry,

295
00:14:43.980 --> 00:14:45.570
the bit of code you
think you're measuring, you need

296
00:14:45.570 --> 00:14:48.060
to run stuff. Like you
mentioned several times to get

297
00:14:48.330 --> 00:14:51.710
an accurate representation of how
long it really and things

298
00:14:51.710 --> 00:14:54.230
like that. So he has
a bit of an art

299
00:14:55.100 --> 00:14:58.280
to doing it. And it's,
I think it's saying that

300
00:14:58.580 --> 00:15:01.150
you can't get wrong if
you're not careful, How important

301
00:15:01.150 --> 00:15:04.060
do you think it is
for performance metrics to be

302
00:15:04.060 --> 00:15:06.790
kind of up front and
center? Sometimes they're buried off

303
00:15:06.790 --> 00:15:10.240
in some operations dashboard or
even worse in someone's text

304
00:15:10.240 --> 00:15:12.730
file, somewhere in a log
that no one looks at.

305
00:15:14.170 --> 00:15:16.000
Yeah. I mean, it goes
back to what you're talking

306
00:15:16.000 --> 00:15:18.250
about. Mini guide, the idea
that you kind of really

307
00:15:18.250 --> 00:15:20.470
liked to know about your
performance issues before your customers

308
00:15:20.470 --> 00:15:23.380
are telling you about it,
or before the CEO who

309
00:15:23.380 --> 00:15:27.130
runs the site and behaves
badly. So the yeah. Where

310
00:15:27.130 --> 00:15:29.230
wherever, whatever you can do
to get them, whether that's

311
00:15:29.230 --> 00:15:31.780
alerts. I mean, one of
the problems with alerts you

312
00:15:31.780 --> 00:15:33.130
have to find is that
there's so many of them

313
00:15:33.670 --> 00:15:36.220
having more alerts isn't necessarily
a good thing sometimes. Cause

314
00:15:36.220 --> 00:15:40.240
people just learn to ignore
them. So meaningful alerts have

315
00:15:40.240 --> 00:15:41.860
them in a place that
you can find them easily.

316
00:15:41.860 --> 00:15:43.960
Like you say, don't have
to dig into them. I

317
00:15:43.960 --> 00:15:48.100
really like the example from
stack overflow, they, they released

318
00:15:48.100 --> 00:15:50.620
a tool called mini profiler
and it has other ones

319
00:15:50.620 --> 00:15:54.100
available, like glimpse glimpse, probably
maybe more fully featured, but

320
00:15:54.880 --> 00:15:56.860
many profiles. It was one
of the early ones maybe

321
00:15:57.340 --> 00:16:00.460
that sits in the corner
of your webpage, or it

322
00:16:00.460 --> 00:16:02.650
can work in other scenarios,
but it was mostly tailored

323
00:16:02.650 --> 00:16:05.530
for that and gives you
a drill down of where

324
00:16:05.530 --> 00:16:09.190
the times taken to render
that page, database time a

325
00:16:09.190 --> 00:16:11.740
time. And you control that
time in your front end

326
00:16:11.740 --> 00:16:14.260
and you're rendering your view,
these sorts of things and

327
00:16:14.320 --> 00:16:17.560
having that. Yeah, I think
that's something that's very valuable

328
00:16:17.560 --> 00:16:19.750
having that in development. So
your dad's can get an

329
00:16:19.750 --> 00:16:23.920
idea of, you know, if,
if you're hitting a development

330
00:16:23.920 --> 00:16:26.290
page five times a day
and you see suddenly something

331
00:16:26.300 --> 00:16:28.570
go, go a lot slower,
you're going to investigate it

332
00:16:28.570 --> 00:16:31.660
then as opposed to, to
wait till later. But yeah.

333
00:16:32.500 --> 00:16:34.810
So you think it's important
to put those things like,

334
00:16:34.830 --> 00:16:37.960
like if you're a developer,
not in production or even

335
00:16:37.960 --> 00:16:40.060
if you're maybe in production,
but you're logged in with

336
00:16:40.060 --> 00:16:42.670
some magic powers as a
developer, you should see perf

337
00:16:42.790 --> 00:16:46.330
like right there. Yeah. I
think apparently there's, I think

338
00:16:46.330 --> 00:16:48.490
there's been times where they
found per fishes in stack

339
00:16:48.490 --> 00:16:51.640
overflow because that dad saw
the, yeah, they don't, they

340
00:16:51.640 --> 00:16:53.980
don't expose it to users
the site, but whoever the

341
00:16:53.980 --> 00:16:55.630
dads and others get to
see it and they've, you

342
00:16:55.630 --> 00:16:58.060
know, someone's sitting in and
suddenly a page takes 400

343
00:16:58.060 --> 00:17:00.280
milliseconds when they expect their
page to take less than

344
00:17:00.280 --> 00:17:02.440
a hundred and you know,
that's enough. And I'm sure

345
00:17:02.440 --> 00:17:04.210
they have metrics that would
flag that up as well.

346
00:17:04.210 --> 00:17:07.600
But having that, yeah. If,
if nothing else I think

347
00:17:07.600 --> 00:17:09.310
having that sort of the
first step is, is a

348
00:17:09.310 --> 00:17:12.340
great way to go to
stops the thing of like,

349
00:17:12.370 --> 00:17:13.960
Oh, I didn't realize the
page was behaving slowly. It

350
00:17:13.960 --> 00:17:15.370
kind of makes it a
bit harder for that in

351
00:17:15.370 --> 00:17:16.990
some way. Cause they, you
know, they've got no excuse,

352
00:17:16.990 --> 00:17:20.080
but it does at any,
anytime I've been working on

353
00:17:20.080 --> 00:17:22.180
a site or this or
some code and we've turned

354
00:17:22.180 --> 00:17:25.390
that on we've we've always
been slightly surprised about what

355
00:17:25.390 --> 00:17:27.970
we've found and we've gone
away to fix something straight

356
00:17:27.970 --> 00:17:30.250
away. If nothing else it'll
tell you, if you're hammering

357
00:17:30.250 --> 00:17:33.190
the database with lots of
calls and that's, that's normally

358
00:17:33.190 --> 00:17:36.280
a bad sign of performance.
If you select 10 plus

359
00:17:36.280 --> 00:17:38.320
ones, it will flag things
up like that for you.

360
00:17:38.320 --> 00:17:43.120
But it's always hard to
figure out where time is

361
00:17:43.120 --> 00:17:45.910
being taken. So having something
that tells you that as

362
00:17:45.910 --> 00:17:48.100
soon as you can see
that is, is definitely a

363
00:17:48.100 --> 00:17:51.360
benefit. Yeah. Yeah. I'm a
big fan Of, of glimpse.

364
00:17:51.480 --> 00:17:55.410
And before that mini profiler,
I think glimpse does most

365
00:17:55.410 --> 00:17:58.920
of what many profiler does
now. Yeah. The idea that

366
00:17:58.950 --> 00:18:01.440
in, you know, in the
browser on the page, see

367
00:18:01.440 --> 00:18:03.240
that something went wrong and
I would even go so

368
00:18:03.240 --> 00:18:05.820
far as to, as to
like, if I were in

369
00:18:05.820 --> 00:18:08.610
development, you know, change the
background, color of the page,

370
00:18:08.640 --> 00:18:10.620
make it red. If it,
you know, if it didn't

371
00:18:10.920 --> 00:18:13.500
come back in a certain
number of seconds, really put

372
00:18:13.500 --> 00:18:16.590
it up front. If, if,
if things are, are not

373
00:18:16.590 --> 00:18:20.750
performance in a deeply unperformed
way, everyone should know. Yeah.

374
00:18:20.840 --> 00:18:23.150
That's a nice idea actually.
Yeah. Yeah, definitely. Yeah. Yeah.

375
00:18:23.150 --> 00:18:26.480
You want something, whether it's
dashboards or something. Yeah. Cause,

376
00:18:26.750 --> 00:18:31.550
cause if generally you nice
stuff starts performing badly. There's

377
00:18:31.730 --> 00:18:33.290
a very high chance that
your customers are going to

378
00:18:33.290 --> 00:18:35.480
see that it's unlikely that
you're only seeing that as

379
00:18:35.480 --> 00:18:37.640
a Def looking at the
site as opposed to customers.

380
00:18:37.640 --> 00:18:40.040
So yeah. You want to
know as soon as possible.

381
00:18:41.000 --> 00:18:43.760
I think it's funny that
people are really willing to

382
00:18:43.760 --> 00:18:48.050
put in, you know, lights
and traffic lights, traffic, robots,

383
00:18:48.130 --> 00:18:50.600
to tell you whether or
not the build is failing,

384
00:18:51.140 --> 00:18:54.060
but you don't see that
as much if performances is

385
00:18:54.080 --> 00:18:58.360
not up to snuff. Yeah.
It's it's yeah. I, I,

386
00:18:58.400 --> 00:19:00.200
when I, when I was
looking around at this particular

387
00:19:00.200 --> 00:19:03.410
thing, now there's a few,
there's a few places I

388
00:19:03.410 --> 00:19:05.150
found it, but it's, there's
not so many, I don't

389
00:19:05.150 --> 00:19:08.840
think it's whether it's a
tooling thing or a thing.

390
00:19:08.840 --> 00:19:12.740
I mean like this whole
parameter optimization, you don't want

391
00:19:12.740 --> 00:19:14.300
to get down to the
point where everything, you know,

392
00:19:14.300 --> 00:19:16.500
if any slight bit of
your code runs slower, you,

393
00:19:16.500 --> 00:19:18.230
you completely fail it. But
yeah, I think there's a

394
00:19:18.230 --> 00:19:20.690
sort of middle ground and
one library. I did see

395
00:19:20.690 --> 00:19:22.780
it in his, his no
to time from John skeet,

396
00:19:22.790 --> 00:19:26.000
his library way, it's, it's
kind of a system level

397
00:19:26.000 --> 00:19:29.120
libraries in effect. Writing are
a replacement for date, time

398
00:19:29.120 --> 00:19:32.870
and date, time offset and
all the international international relations

399
00:19:32.870 --> 00:19:35.480
and stuff that goes on
with, with dates and times

400
00:19:35.480 --> 00:19:39.890
and say that you are
using that library and you're

401
00:19:39.890 --> 00:19:42.650
not expecting that library to
be slow in any way.

402
00:19:42.650 --> 00:19:45.380
So I think that's a
definite place where there's no

403
00:19:45.380 --> 00:19:48.290
real premature optimization because it's
something you want to be

404
00:19:48.290 --> 00:19:51.710
quick. So he has on
every build, he has performance

405
00:19:51.710 --> 00:19:54.500
tests that run them all
say this bit, this particular

406
00:19:55.670 --> 00:19:58.490
performance test is running slower
than last built. Is this

407
00:19:58.490 --> 00:20:00.260
something you wanna, you want
to sort out and then

408
00:20:00.650 --> 00:20:02.270
yeah, but I think that's
a nice site. They probably

409
00:20:02.270 --> 00:20:04.520
all, I think that, I
think in the Roslyn any

410
00:20:04.520 --> 00:20:07.040
way, I would imagine that
they, if, if not breaks

411
00:20:07.040 --> 00:20:09.110
the build, it certainly flex
it up. If things get

412
00:20:09.110 --> 00:20:12.080
slower build to build. Cause
you know, if they've gone

413
00:20:12.080 --> 00:20:13.940
to the effort of putting
all this in places, it

414
00:20:13.940 --> 00:20:16.370
would be strange to not
be acting on it. Well,

415
00:20:16.370 --> 00:20:19.250
that brings up another interesting
point. There's the, there's the

416
00:20:19.460 --> 00:20:22.490
performance as it is now,
but then there's that historical

417
00:20:22.490 --> 00:20:25.490
performance, right? I mean, it's
one thing to say this

418
00:20:25.490 --> 00:20:28.130
page is red or whatever,
because it's less than two

419
00:20:28.130 --> 00:20:30.710
seconds or it's more than
two seconds in the time

420
00:20:30.710 --> 00:20:33.680
it took to load, but
that doesn't put anything in

421
00:20:33.680 --> 00:20:36.500
context. There's no graph there
to express that, you know

422
00:20:36.500 --> 00:20:38.990
what we did double performance
from before, it's still not

423
00:20:38.990 --> 00:20:41.570
correct, but we are moving
in a certain direction. So

424
00:20:42.110 --> 00:20:45.230
what do we do to
collect those, those statistics and

425
00:20:45.320 --> 00:20:49.600
look at performance over time?
Yeah. That's something I've been

426
00:20:49.600 --> 00:20:51.160
wondering. It was how I
was trying to look around

427
00:20:51.160 --> 00:20:53.590
and see what's around. I
mean, I think a lot

428
00:20:53.620 --> 00:20:58.460
of tools or tools that
will run on builds and

429
00:20:58.690 --> 00:21:01.150
do unit tests and show
graphs of their past and

430
00:21:01.150 --> 00:21:03.250
failures. I think a lot
of those have an option

431
00:21:03.430 --> 00:21:06.160
for you to output some
other metric. So if, if

432
00:21:06.160 --> 00:21:08.410
the tool offers that, then
that's one way I think

433
00:21:08.410 --> 00:21:11.590
is so they generate automatically
pick up the number of

434
00:21:11.590 --> 00:21:13.540
parts and files of tasks
and you can see those

435
00:21:13.540 --> 00:21:16.660
graphs. But from my understanding,
some of those tools offer

436
00:21:16.660 --> 00:21:18.850
a way to say, you
know, all right, we'll have

437
00:21:18.850 --> 00:21:20.770
one particular bit of code
that runs on every build

438
00:21:20.770 --> 00:21:22.990
and it outputs a metric
that represents the time that

439
00:21:22.990 --> 00:21:26.350
we care about. And then
we can graph that. Other

440
00:21:26.350 --> 00:21:28.480
than that, it may be
a case of pushing those

441
00:21:28.480 --> 00:21:30.970
graphs into some other third
party tool that just does

442
00:21:30.970 --> 00:21:34.600
graphs in general, there's online
tools or graphite or things

443
00:21:34.600 --> 00:21:37.480
like that, that run that
can just basically have rest

444
00:21:37.480 --> 00:21:39.130
end points and you can
push data in. So that

445
00:21:39.130 --> 00:21:41.860
might be an option. So
yeah, I think it's, I

446
00:21:41.860 --> 00:21:44.200
think it's something that when
I seen it, they seem

447
00:21:44.200 --> 00:21:46.870
to be hand-rolled solutions from
the ones I've seen so

448
00:21:46.870 --> 00:21:49.810
far. So I don't know
if it's a, not a

449
00:21:49.810 --> 00:21:52.810
solved problem or, or I'm
just missing the ones. Maybe

450
00:21:52.810 --> 00:21:54.250
it could be that I'm
just missing the ones that

451
00:21:54.430 --> 00:21:57.750
do for you. Well, certainly
there's tools like, like stack

452
00:21:57.750 --> 00:22:02.580
Overflow's ops server. That is
absolutely amazing piece of work

453
00:22:02.730 --> 00:22:05.610
that the complete dashboard, they
use it for CQL performance

454
00:22:05.610 --> 00:22:09.030
for Reddis for their elastic
search. And they can look

455
00:22:09.030 --> 00:22:12.120
at things like CPU utilization
in L you know, live

456
00:22:12.120 --> 00:22:15.300
over time, which, and it's
pretty extraordinary and it's all

457
00:22:15.300 --> 00:22:17.370
open source. So certainly we
could build on top of

458
00:22:17.370 --> 00:22:20.900
things like that. Yeah, yeah,
yeah, no, sorry. I said,

459
00:22:20.900 --> 00:22:23.280
yeah, no, I'd seen that
pretty, that's a nice tool

460
00:22:23.280 --> 00:22:26.040
actually. Yeah. Yeah. And, and
like the other stuff they

461
00:22:26.040 --> 00:22:28.110
do, it's nice that they,
they make it freely available

462
00:22:28.110 --> 00:22:32.250
for, for like, from my
understanding that the tools, they

463
00:22:32.250 --> 00:22:34.380
couldn't either find tools that
were tailored to their need

464
00:22:34.380 --> 00:22:36.210
or, you know, I don't,
I don't think they write

465
00:22:36.210 --> 00:22:38.550
tools themselves on a whim,
you know, that they haven't

466
00:22:38.550 --> 00:22:40.020
got the time to just
be always doing their own

467
00:22:40.020 --> 00:22:42.570
tools. You know, I trusted,
they had a good reason

468
00:22:42.570 --> 00:22:45.300
for writing that cause the
commercially available ones weren't doing

469
00:22:45.350 --> 00:22:47.490
what they're doing, but yeah.
It's nice that they spun

470
00:22:47.490 --> 00:22:50.760
that out and made that
available. Yeah. Yeah. And, and

471
00:22:50.760 --> 00:22:52.740
I think that, that, that
is a good thing in

472
00:22:52.740 --> 00:22:54.960
terms of this single dashboard,
one place where you can

473
00:22:54.960 --> 00:22:57.330
get this stuff and yes,
you might drill down further,

474
00:22:57.330 --> 00:22:59.550
but not having to look
at some logs that are

475
00:22:59.550 --> 00:23:02.490
on one machine and correlate
those with something else that's

476
00:23:02.490 --> 00:23:04.770
going on another machine. And
then, you know, and then

477
00:23:04.770 --> 00:23:06.990
hope the machine hasn't recycled
in the cloud and you've

478
00:23:06.990 --> 00:23:10.770
lost those logs over. So
having something central that deliberately

479
00:23:10.800 --> 00:23:13.050
collects this stuff in a
way that not on your

480
00:23:13.050 --> 00:23:15.390
alert sheet, but gives you
a way of going back

481
00:23:15.420 --> 00:23:19.950
to look over, look over
time or, or, yeah, it's

482
00:23:19.950 --> 00:23:23.130
a spot. These issues Important
that that not be a

483
00:23:23.130 --> 00:23:27.530
toy or someone's spare time
project. Like you need an,

484
00:23:27.530 --> 00:23:30.870
a manager or a boss
to, to accept that this

485
00:23:30.870 --> 00:23:32.940
is important. This is a
thing that someone really needs

486
00:23:32.940 --> 00:23:35.130
to work on. I mean,
I don't think ops server

487
00:23:35.130 --> 00:23:37.140
was w I hope not.
And we have to ask

488
00:23:37.140 --> 00:23:39.480
the stack overflow folks. I
certainly hope that wasn't written,

489
00:23:39.810 --> 00:23:44.700
you know, in someone's on
someone's weekend. Yeah, yeah, exactly.

490
00:23:44.700 --> 00:23:46.970
Now you're yeah. Going back
to the Rodney thing, making

491
00:23:47.000 --> 00:23:50.960
a deliberate thing. Yeah, yeah.
From all my, from the

492
00:23:50.960 --> 00:23:53.630
outside, looking at stack overflow,
they, they do this stuff

493
00:23:53.630 --> 00:23:56.960
cause they're serious about it.
They, they, they blog about

494
00:23:57.290 --> 00:23:59.630
the times when they weren't
as fast as they wanted

495
00:23:59.630 --> 00:24:03.050
to be. They, they, they
write tools. Yeah. I think

496
00:24:03.160 --> 00:24:05.270
it's a, it's a, it's
a culture there's maybe a

497
00:24:05.270 --> 00:24:07.910
better way of describing it
in terms of, we deeply

498
00:24:07.910 --> 00:24:10.520
care about performance, you know,
not, not that they're sacrificing

499
00:24:10.520 --> 00:24:12.950
other things security or whatever
that's going on as well,

500
00:24:12.950 --> 00:24:16.670
but they, they care about
performance because in their world,

501
00:24:16.670 --> 00:24:19.160
in terms of page render
times and stuff like that,

502
00:24:19.160 --> 00:24:21.950
that matters for Google results
or that matters for a

503
00:24:21.950 --> 00:24:24.320
good experience for the thousands
of deaths or using the

504
00:24:24.320 --> 00:24:28.310
sites or it matters. Cause
they can run on the

505
00:24:28.310 --> 00:24:30.650
hardware they have and not
have to, you know, they

506
00:24:30.650 --> 00:24:32.420
can cope with burst loads
and things like that, I

507
00:24:32.420 --> 00:24:36.070
think is a combination of
those things. What about benchmarking?

508
00:24:36.070 --> 00:24:38.350
You've said that there's an
art to benchmarking. I think

509
00:24:38.350 --> 00:24:40.960
people sit down and they
start measuring things and then

510
00:24:40.960 --> 00:24:43.030
they realized that they weren't
really measuring at all what

511
00:24:43.030 --> 00:24:47.050
they thought they were. Yeah.
So there was there's that

512
00:24:47.080 --> 00:24:51.070
there's a lot of it
comes down to when you

513
00:24:51.070 --> 00:24:54.730
get to a certain level
there's categories. So mainly benchmarks,

514
00:24:54.760 --> 00:24:58.210
micro benchmarks. So some of
these things apply to, once

515
00:24:58.210 --> 00:24:59.590
you get down to a
low level, you really have

516
00:24:59.590 --> 00:25:02.080
to worry about, or one
of the main things is

517
00:25:02.080 --> 00:25:05.320
the dotnet jitters. So they'll
be doing a whole tutorial

518
00:25:05.320 --> 00:25:08.740
on that. Basically we, we
write C-sharp code or vb.net

519
00:25:08.740 --> 00:25:12.100
or whatever we write that
gets turned into IO and

520
00:25:12.100 --> 00:25:15.130
then compile it into ion.
And then it runs on

521
00:25:15.130 --> 00:25:17.110
the jitter kicks in and
turns that into code that

522
00:25:17.110 --> 00:25:19.390
runs on the machine and
there's other scenarios. But generally

523
00:25:19.390 --> 00:25:22.900
that's the main way that
happens. Budgets are, can basically

524
00:25:22.930 --> 00:25:26.290
optimize in any way. It
sees fit that doesn't change

525
00:25:26.290 --> 00:25:28.450
the behavior of your program.
And often when you're writing

526
00:25:28.450 --> 00:25:30.460
a micro benchmark, you're calling
a bit of code in

527
00:25:30.460 --> 00:25:32.650
a loop and the jitter
might just say, Hey, you're

528
00:25:32.650 --> 00:25:34.750
not using the value. You're
just coding this code. You're

529
00:25:34.750 --> 00:25:36.640
not doing anything with the
value at returns or you're

530
00:25:36.640 --> 00:25:39.340
not even returning a value.
So one of the, one

531
00:25:39.340 --> 00:25:41.620
of the scenarios I've found
that you have to be

532
00:25:41.620 --> 00:25:44.020
careful is that when you
get down to a certain

533
00:25:44.020 --> 00:25:46.360
level, if you're benchmarking things
at quite a low level,

534
00:25:46.360 --> 00:25:48.910
there's a chance at digital,
we'll just optimize it out.

535
00:25:49.450 --> 00:25:50.770
And on the other side
of that is you have

536
00:25:50.770 --> 00:25:53.770
to make sure that you
are running in release mode.

537
00:25:53.770 --> 00:25:56.230
You're not running inside of
the bugger. You know, when

538
00:25:56.230 --> 00:25:58.390
visual studio, when you run
inside of deBaca, it doesn't

539
00:25:58.390 --> 00:26:00.190
optimize the code in the
same way. As when you

540
00:26:01.180 --> 00:26:03.880
launched the executable outside of
visual studio. For instance, there's

541
00:26:03.880 --> 00:26:05.680
a few things that you
have to worry about because

542
00:26:06.190 --> 00:26:08.500
the debug mode is useful
for debugging, but it's slower

543
00:26:08.950 --> 00:26:11.260
by definition because it puts
in things to help make

544
00:26:11.260 --> 00:26:14.920
the debugging experience. Nice. And
another one is you want

545
00:26:14.920 --> 00:26:16.600
to try and isolate as
much as you can, that

546
00:26:16.600 --> 00:26:18.760
garbage collection, if you're running
something in the loop for

547
00:26:19.120 --> 00:26:20.830
a long period of time,
there may be a point

548
00:26:20.830 --> 00:26:23.920
where the garbage collection kicks
in and a lot of

549
00:26:24.100 --> 00:26:26.890
benchmarks will in effect called
GC collect the thing we

550
00:26:26.890 --> 00:26:29.650
never told to call for
real in production, but in

551
00:26:29.650 --> 00:26:32.710
a benchmark, that's one thing
we're talking about.net. Anyway, we

552
00:26:32.710 --> 00:26:35.380
want to make sure that
we do what we can

553
00:26:35.380 --> 00:26:37.120
to get the garbage collection
out of the way, because

554
00:26:37.120 --> 00:26:40.090
it will, it will artificially
change the speed of your

555
00:26:40.090 --> 00:26:42.760
benchmark ineffective. If the garbage
collection kicks in, in the

556
00:26:42.760 --> 00:26:46.380
middle, How often do you
think people are overthinking these

557
00:26:46.380 --> 00:26:49.080
things? They're, they're, you know,
they're, they're doing pretty basic

558
00:26:49.080 --> 00:26:51.870
work. They're going to the
database, they're pulling stuff back,

559
00:26:51.870 --> 00:26:56.490
spinning through collections, and then
suddenly they're off tweaking dotnet

560
00:26:56.490 --> 00:26:59.280
GC settings because they convinced
that they are a unique

561
00:26:59.280 --> 00:27:03.230
snowflake. Yeah, no, there, there,
there definitely is that when

562
00:27:03.230 --> 00:27:05.570
I, when I do a
talk and I say some

563
00:27:05.570 --> 00:27:08.220
of these things I've seen
in Rosner, other places, I

564
00:27:08.240 --> 00:27:10.850
put a big warning saying,
please do not go back

565
00:27:10.850 --> 00:27:13.040
and change your code to
match any of these scenarios.

566
00:27:13.600 --> 00:27:16.760
You have to be measuring
this stuff first to work

567
00:27:16.760 --> 00:27:19.310
out, visiting valid is quite
nice as engineers, we call

568
00:27:19.310 --> 00:27:22.070
it. You know, maybe if
you like to look at

569
00:27:22.070 --> 00:27:23.840
low level stuff or whatever,
it's quite nice to go

570
00:27:23.840 --> 00:27:26.570
in and say, Oh, I
tweaked the GC or I

571
00:27:26.990 --> 00:27:29.960
made something that will run
one millisecond faster, over a

572
00:27:29.960 --> 00:27:32.450
thousand ones or whatever, but,
you know, yeah. We need

573
00:27:32.450 --> 00:27:36.050
to kind of see the,
the wood for the trees,

574
00:27:36.050 --> 00:27:38.690
if you're lucky. That's the
analogy that, that, yeah, we're

575
00:27:38.690 --> 00:27:40.400
not just doing this for
the, for the sake of

576
00:27:40.400 --> 00:27:43.610
it. There is, there is
some times when it's valid,

577
00:27:43.610 --> 00:27:45.890
whether it's say something like
no to time where you're

578
00:27:45.890 --> 00:27:48.650
a system level library or
it's stack overflow where you're

579
00:27:49.100 --> 00:27:51.200
running at that performance level,
or even a regular app,

580
00:27:51.200 --> 00:27:53.660
if you identify what your
hot path is and you

581
00:27:53.660 --> 00:27:56.750
know, if it's running 20
times a second, then you

582
00:27:56.750 --> 00:28:00.540
know, shading a millisecond off
can help there. So there

583
00:28:00.540 --> 00:28:02.510
is, there are scenarios where
it's valid, but yeah, it's

584
00:28:02.510 --> 00:28:04.700
definitely a very easy trap
to fall into say, you

585
00:28:04.700 --> 00:28:07.340
know, I've seen this nice
trick. I'm going to rewrite

586
00:28:07.340 --> 00:28:08.960
all my code. I mean,
one of the things that

587
00:28:09.020 --> 00:28:12.020
in Roslyn and hot pass
is they disallow link. They

588
00:28:12.020 --> 00:28:13.970
say, we're not going to
use link. Cause that's when

589
00:28:13.970 --> 00:28:17.360
you run link the, the
query language or the, you

590
00:28:17.360 --> 00:28:20.270
know, the nice functional way
of doing stuff in.net. It's

591
00:28:20.270 --> 00:28:22.940
fantastic. But behind the scenes
to give you that nice

592
00:28:22.940 --> 00:28:24.950
experience as a developer, it
does a bit of extra

593
00:28:24.950 --> 00:28:28.880
work than the old for
each loop way in certain

594
00:28:28.880 --> 00:28:32.330
scenarios. So they, they there's
been times where they rewrote

595
00:28:32.330 --> 00:28:34.640
some link queries into the
old style queries to just

596
00:28:35.150 --> 00:28:38.090
minimize the extra work that
was going on that would

597
00:28:38.300 --> 00:28:40.790
eventually turn into extra work
for the garbage collector. And

598
00:28:40.790 --> 00:28:42.980
they identified that as a
hot path, they identified that

599
00:28:42.980 --> 00:28:45.320
there was extra work being
done there and they identified

600
00:28:45.320 --> 00:28:48.410
that getting rid of link
in that scenario was a

601
00:28:48.410 --> 00:28:50.510
good thing to do, but
definitely don't think getting rid

602
00:28:50.510 --> 00:28:52.400
of link as a common
thing is, is, you know,

603
00:28:52.430 --> 00:28:55.940
link is fantastic. That writes
more readable code. People can

604
00:28:55.940 --> 00:29:01.070
understand it. Yeah. So yeah,
there's definitely stuff that's this

605
00:29:01.070 --> 00:29:04.020
is a good, good example
for, if you care about

606
00:29:04.040 --> 00:29:06.140
forcing this bit of Cobra,
don't do this elsewhere in

607
00:29:06.140 --> 00:29:10.160
the code base because more
often than not performance Coda

608
00:29:10.160 --> 00:29:12.740
is good from Ford's point
of view is less readable

609
00:29:12.740 --> 00:29:14.960
code. Cause it's, it's not
the code song would have

610
00:29:14.960 --> 00:29:18.230
written the first time around.
So there's this one term,

611
00:29:18.230 --> 00:29:20.210
I think you might be
saying it quickly and not

612
00:29:20.210 --> 00:29:23.660
everyone who listens will have
heard that the term you're

613
00:29:23.660 --> 00:29:28.190
saying is, is hot pack,
Hot paths. Yes. Sorry. It

614
00:29:28.190 --> 00:29:32.090
says the code execution has
that the compiler we're kind

615
00:29:32.090 --> 00:29:34.940
of, most of the execution
time is spent. It's kind

616
00:29:34.940 --> 00:29:37.400
of like the 80 20
rule, right? 20% of the

617
00:29:37.400 --> 00:29:40.580
code is being used 80%
of the time. Yeah, exactly.

618
00:29:40.580 --> 00:29:43.410
That thing you, you know,
it's different. So on, on,

619
00:29:43.430 --> 00:29:46.300
on a website, it may
be the, the bit that

620
00:29:46.300 --> 00:29:48.790
does the validation of the
user on every request that's

621
00:29:48.790 --> 00:29:50.980
shared across every request on
every page on the site

622
00:29:51.040 --> 00:29:53.800
or on, on Rosalind, it's
the bit that's done on

623
00:29:53.800 --> 00:29:56.230
every, every time we hit
a key in visual studio

624
00:29:56.230 --> 00:29:58.540
and Rosalind does something in
the background to reprocess that

625
00:29:58.720 --> 00:30:01.210
that would be considered Rosalind
hot path. So that, that

626
00:30:01.240 --> 00:30:06.250
varies across applications. I've previously
worked in applications that run

627
00:30:06.250 --> 00:30:09.700
in factories and the constantly
taking images of things going

628
00:30:09.700 --> 00:30:12.550
under, along a conveyor belt.
And so our hot path

629
00:30:12.550 --> 00:30:14.950
is we have to make
sure where we're processing the

630
00:30:14.950 --> 00:30:17.050
image before the next image
comes along. We've got a

631
00:30:17.050 --> 00:30:21.340
fairly constraints thing. So it
varies, you know, whatever your

632
00:30:21.340 --> 00:30:24.130
application might be is the
bit that's done more often

633
00:30:24.130 --> 00:30:26.110
than not, like you say,
the 80, the 80 20

634
00:30:26.110 --> 00:30:28.900
rule. And certainly in Roslyn,
I think there's more of

635
00:30:28.900 --> 00:30:30.910
a general term it's referred
to as a hot path.

636
00:30:31.630 --> 00:30:34.660
And this is, this is
a more, this is useful

637
00:30:34.660 --> 00:30:37.570
for more than just performance
also for testing and things

638
00:30:37.570 --> 00:30:42.160
like test coverage. People often
talk about how I want

639
00:30:42.160 --> 00:30:44.440
to get a hundred percent
test coverage, but you know,

640
00:30:44.680 --> 00:30:47.110
that doesn't necessarily mean that
the piece that you're deciding

641
00:30:47.110 --> 00:30:49.570
to do test coverage of
is, is even happening very

642
00:30:49.570 --> 00:30:52.480
often. Really I'd rather have
a hundred percent test coverage

643
00:30:52.930 --> 00:30:55.150
on the 20% of the
code that everyone is in

644
00:30:55.150 --> 00:30:58.000
all the time. Yeah. Yeah.
That's definitely true as well,

645
00:30:58.000 --> 00:30:59.770
actually. Yeah. Yeah. You're right.
Yeah. I mean, if, if,

646
00:30:59.770 --> 00:31:02.320
if in an ideal world,
like you say, you know,

647
00:31:02.440 --> 00:31:04.420
if we could get a
hundred percent test coverage, maybe

648
00:31:04.420 --> 00:31:06.760
that's what or something, although
even that sometimes people argue

649
00:31:06.760 --> 00:31:09.670
about whether that's something worth
aiming for, but yeah. If

650
00:31:09.670 --> 00:31:12.190
you're constrained with time. Yeah.
Certainly looking at the bits

651
00:31:13.000 --> 00:31:16.210
that every user's using versus
the bit of the site

652
00:31:16.210 --> 00:31:18.790
that gets used once a
week or something. Yeah. I

653
00:31:18.790 --> 00:31:20.830
mean, it's, there's always priorities
in there. It could be

654
00:31:22.060 --> 00:31:24.340
often comes down to business
or something like that, or

655
00:31:24.340 --> 00:31:28.070
whatever's driving where the developers
spend their time, but yeah.

656
00:31:28.070 --> 00:31:31.540
Yeah. We can sometimes concentrate
our time on the wrong

657
00:31:31.540 --> 00:31:33.550
parts. Maybe the parts that
are more interesting to us,

658
00:31:33.550 --> 00:31:37.150
but, but not, not what
our users use. Well, you

659
00:31:37.150 --> 00:31:43.090
have a wealth of great
information@mattwarren.org underneath the recent pages.

660
00:31:43.090 --> 00:31:45.880
You go into the Dunnet
garbage collector, the Roslyn code

661
00:31:45.880 --> 00:31:50.530
base, Raven DB. Reddis the
art of benchmarking. And I

662
00:31:50.530 --> 00:31:52.510
really appreciate you taking the
time to chat with me

663
00:31:52.510 --> 00:31:55.960
today. No problem. Thank you
very much, Scott. This has

664
00:31:55.960 --> 00:31:58.510
been another episode of Hanselminutes
and we'll see you again

665
00:31:58.510 --> 00:31:59.020
next week.

