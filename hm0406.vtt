WEBVTT FILE

1
00:00:12.030 --> 00:00:17.460
From hanselminutes.com. It's Hansel minutes.
Oh, weekly discussion with web

2
00:00:17.460 --> 00:00:21.750
developer and technologist and Scott
Hanselman. This is Lawrence Ryan announcing

3
00:00:21.750 --> 00:00:27.900
show number four Oh nine.
Recorded live Thursday, January 30th, 2014. This

4
00:00:27.900 --> 00:00:30.570
episode of Hansel minutes is
brought to you by Tellerik

5
00:00:30.690 --> 00:00:39.480
offering the best in developer
tools and support online@telerikdotcomandbyfranklin.net makers

6
00:00:39.480 --> 00:00:43.080
of gesture pack a powerful
gesture, recording and recognition system

7
00:00:43.080 --> 00:00:50.910
for Microsoft connect for windows
developers details@gesturepak.com. In this episode,

8
00:00:50.910 --> 00:00:54.690
Scott talks with Amelia Greenhall
and Shanley Kane about the

9
00:00:54.690 --> 00:01:00.180
launch of their new media
company model view culture. Hi,

10
00:01:00.180 --> 00:01:02.270
this is Scott Hanselman. This
is another episode of Hansel

11
00:01:02.270 --> 00:01:04.880
minutes and on Skype right
now, I've got Shanley Kane

12
00:01:04.880 --> 00:01:07.910
and Amelia Greenhall, and they've
just started a new media

13
00:01:07.910 --> 00:01:10.670
company called model view culture.
You can check it out

14
00:01:10.670 --> 00:01:14.540
at model view, culture.com. Thanks
you all for coming on

15
00:01:14.540 --> 00:01:17.030
the show today. Yeah, thank
you. We're excited to be

16
00:01:17.030 --> 00:01:21.440
here. Thanks. Got So, so
why create a media company

17
00:01:21.440 --> 00:01:25.970
on diversity in technology? Yeah.
So when you, we looked

18
00:01:25.970 --> 00:01:30.710
at the tech media landscape
in general, we noticed that

19
00:01:30.740 --> 00:01:35.600
there's a major market for
a company that focuses more

20
00:01:35.600 --> 00:01:41.270
on the interests, achievement, and
perspectives of diverse communities in

21
00:01:41.270 --> 00:01:45.050
tech. And that is able
to take a critical stance

22
00:01:45.050 --> 00:01:49.610
towards issues with tech culture,
produce social and cultural tech

23
00:01:50.300 --> 00:01:54.890
critique, and also explore the
relationship between technology and social

24
00:01:54.890 --> 00:01:59.540
justice. So there has been
a major uptake in activity

25
00:01:59.930 --> 00:02:03.740
in writing and community interests
around these topics, but no

26
00:02:03.740 --> 00:02:07.640
tech media company that was
focused specifically in those areas.

27
00:02:08.270 --> 00:02:12.470
So we really see this
as serving a market. That's

28
00:02:12.470 --> 00:02:16.460
currently underserved by the tech
community today. And it seems

29
00:02:16.460 --> 00:02:19.040
like this is more than
just an issue of, of,

30
00:02:19.100 --> 00:02:21.260
of women in technology. I
mean, you happen to be

31
00:02:21.260 --> 00:02:22.940
two women that have started
it, but looking at your

32
00:02:22.940 --> 00:02:26.180
list of authors, you have
a pretty diverse group. It

33
00:02:26.180 --> 00:02:28.400
doesn't appear that you are
thinking about this in terms

34
00:02:28.400 --> 00:02:32.600
of women in tech, which
would be just another, I

35
00:02:32.600 --> 00:02:37.430
guess, overly narrow view. Like
in the sense of there's

36
00:02:37.430 --> 00:02:40.580
a lot of tech writing
around men in tech, they're

37
00:02:40.580 --> 00:02:42.260
not going out of their
way to make it about

38
00:02:42.260 --> 00:02:44.450
men in tech. They're just
kind of writing about, you

39
00:02:44.450 --> 00:02:47.000
know what I mean? It's
not like tech crunch is

40
00:02:47.240 --> 00:02:50.780
welcome to tech crunch, white
men in technology, but inevitably

41
00:02:50.780 --> 00:02:55.100
that kind of is what
happened. Are you writing about

42
00:02:55.730 --> 00:02:57.500
kind of the opposite of
that? Are you trying to

43
00:02:57.500 --> 00:02:59.530
say this is about everything
that is not men in

44
00:02:59.530 --> 00:03:03.030
tech or is it, is
it even So I think

45
00:03:03.030 --> 00:03:07.410
it's, it's that there's just
so much writing and organization

46
00:03:07.470 --> 00:03:11.820
and community coming together. So
we're seeing and more a

47
00:03:11.820 --> 00:03:15.810
part of, and then other
satellite communities that we really

48
00:03:15.810 --> 00:03:18.840
appreciate their voices that we
just aren't and haven't been

49
00:03:18.840 --> 00:03:25.260
seeing be published in the
mainstream media. And so, you

50
00:03:25.260 --> 00:03:28.230
know, we we've been publishing
short and long original pieces

51
00:03:28.260 --> 00:03:34.710
like news pieces, columns, and
all this stuff is hovering.

52
00:03:35.820 --> 00:03:37.890
Just like issues that haven't
been able to get out

53
00:03:37.890 --> 00:03:41.430
there or get covered in
traditional media right now. Yeah.

54
00:03:41.430 --> 00:03:44.370
I think there's a lot
of focus on women in

55
00:03:44.370 --> 00:03:47.370
tech right now, which is
really great and really important.

56
00:03:47.370 --> 00:03:52.290
And that ultimately agenda is
only one aspect of diversity.

57
00:03:52.860 --> 00:03:56.460
You also have to look
at gender identity and presentation,

58
00:03:56.460 --> 00:04:06.270
sexuality, race, ethnicity, disabilities, different
different aspects of the community

59
00:04:06.840 --> 00:04:11.070
and not just focus on,
on one specific group. So

60
00:04:11.070 --> 00:04:16.770
we're hoping to do that
with our publication. Yeah. As

61
00:04:16.950 --> 00:04:18.990
a myself, I mean, I'm
a, you know, a kind

62
00:04:18.990 --> 00:04:24.510
of a generic, a cisgendered
straight white guy. And as

63
00:04:24.510 --> 00:04:28.470
I started to explore these
other kind of either marginalized

64
00:04:28.470 --> 00:04:32.340
or smaller groups of, of
people I've gone to different

65
00:04:32.340 --> 00:04:35.910
hackathons that are focused on,
you know, black women hackathons,

66
00:04:35.940 --> 00:04:39.960
or there was one called
trans hack for transgendered individuals,

67
00:04:40.940 --> 00:04:43.920
I find myself thinking like,
why is this, why is

68
00:04:43.920 --> 00:04:47.370
this needed? But when I
go to these hackathons and

69
00:04:47.370 --> 00:04:50.760
these groups and these conferences,
the people who are there

70
00:04:50.760 --> 00:04:54.690
are just so excited to
be coding or hacking or

71
00:04:54.870 --> 00:04:58.710
talking to, or presenting with
people that are within their

72
00:04:58.710 --> 00:05:01.470
group. And they're just so
jazzed about that. Why, why

73
00:05:01.470 --> 00:05:04.800
is that, why is that,
why are these things needed

74
00:05:04.800 --> 00:05:08.070
and why are they so
appreciate? Well, I mean, speaking

75
00:05:08.070 --> 00:05:11.310
from a personal experience, I
got a degree in electrical

76
00:05:11.310 --> 00:05:14.010
engineering and I was often
the only woman in class.

77
00:05:14.040 --> 00:05:18.960
And it's just a constant
feeling of being, you know,

78
00:05:19.410 --> 00:05:22.500
like a little bit like
you don't belong, even if

79
00:05:22.530 --> 00:05:26.940
nothing over is happening at
the time. And there are

80
00:05:26.940 --> 00:05:32.340
also issues of safety, like
physical safety and like all

81
00:05:32.340 --> 00:05:35.460
of that just weighs on
you as like a, you

82
00:05:35.460 --> 00:05:40.230
know, I am often harassed
like most tech events, I

83
00:05:40.230 --> 00:05:42.360
would say like pretty much
everyone I go to, I

84
00:05:42.360 --> 00:05:49.560
get some form of mild
harassment. And so when we're

85
00:05:49.560 --> 00:05:53.100
able to make our own
groups that suit us and

86
00:05:53.100 --> 00:05:57.410
are specifically inclusive in forest,
like just not having to

87
00:05:57.440 --> 00:06:01.100
like armor up or feel
like that's an issue that

88
00:06:01.100 --> 00:06:04.340
we have to be thinking
about it, like it's very

89
00:06:04.340 --> 00:06:08.800
freeing and like, it does
feel really exciting That that

90
00:06:08.800 --> 00:06:10.780
phrase that you just used
armor up. I think that's,

91
00:06:10.810 --> 00:06:13.720
that's a really interesting one
because I think that that's,

92
00:06:13.780 --> 00:06:18.100
that's true. I think that
the, the, the superpower that

93
00:06:18.100 --> 00:06:20.320
I get as a kind
of a regular straight white

94
00:06:20.320 --> 00:06:24.250
guy is that I rarely
have to armor up. And

95
00:06:24.670 --> 00:06:28.330
that is, is freeing in
a, in a background process

96
00:06:28.330 --> 00:06:31.180
that I'm not even realizing
is happening. But I remember

97
00:06:31.180 --> 00:06:35.470
I was in, in Zimbabwe,
my wife is from Zimbabwe.

98
00:06:35.920 --> 00:06:39.730
And when, when I'm walking
around, I was walking around

99
00:06:39.730 --> 00:06:42.400
the streets of Bulawayo, which
is a small town in

100
00:06:42.400 --> 00:06:45.670
Zimbabwe. And I wasn't really
thinking about it, but I,

101
00:06:45.730 --> 00:06:49.450
I, I realized that I
was tense and I was

102
00:06:49.450 --> 00:06:51.100
trying to figure out like,
why am I so tense?

103
00:06:51.160 --> 00:06:53.110
Why am I so tense?
And I looked around and

104
00:06:53.110 --> 00:06:56.830
I realized that I was
the only white person, probably

105
00:06:56.830 --> 00:07:01.330
within a couple of hundred
kilometers. And my wife was

106
00:07:01.330 --> 00:07:02.950
really tense too. And I
was like, why are you

107
00:07:02.950 --> 00:07:07.180
so tense? And she was
like, well, you're here. Your

108
00:07:07.180 --> 00:07:09.460
presence is making me tense
because we are now a

109
00:07:09.460 --> 00:07:12.160
unit. And we are now
a mixed couple in a,

110
00:07:12.370 --> 00:07:15.340
in a, in a city
that doesn't like mixed couples.

111
00:07:15.400 --> 00:07:17.080
And we started to look
around and we could just

112
00:07:17.080 --> 00:07:19.030
notice the, kind of the
furtive glances and all of

113
00:07:19.030 --> 00:07:20.830
those kinds of things. So
we tried a couple of

114
00:07:20.830 --> 00:07:24.700
experiments where she would basically
step away, she'd go a

115
00:07:24.700 --> 00:07:27.790
block away. And when she
went a block away, she

116
00:07:27.790 --> 00:07:31.090
realized that everything changed. She
became invisible because she looked

117
00:07:31.090 --> 00:07:34.330
like everyone else. And I
became more tense because suddenly

118
00:07:34.330 --> 00:07:38.200
my advocate was gone and
we kind of explored these,

119
00:07:38.740 --> 00:07:41.320
these spaces in ice. We
spent a month there. I

120
00:07:41.320 --> 00:07:44.470
mean, I lived in for
a month in Zimbabwe and

121
00:07:44.800 --> 00:07:49.000
realized that when you are
the only something, the only

122
00:07:49.000 --> 00:07:53.470
whatever in a space, there's
a, there's a background tension

123
00:07:53.500 --> 00:07:56.590
that is there all the
time. And it's, it's freeing

124
00:07:56.590 --> 00:08:00.850
when that goes away. Yeah,
absolutely. And I think, you

125
00:08:00.850 --> 00:08:05.560
know, the other aspect of
that is by creating spaces

126
00:08:05.590 --> 00:08:10.000
that are focused on diverse
communities and their needs, we're

127
00:08:10.000 --> 00:08:14.770
able to address problems and
create solutions and build technology

128
00:08:15.580 --> 00:08:19.000
that there's really not a
space for in the mainstream

129
00:08:19.000 --> 00:08:22.180
tech industry or that the
mainstream tech industry isn't focused

130
00:08:22.180 --> 00:08:26.890
on. So with trans hack,
you know, building software and

131
00:08:26.890 --> 00:08:31.570
building technology that can improve
the lives of trans people

132
00:08:32.170 --> 00:08:36.790
and with women's hackathons and,
and diversity of focus, hackathons,

133
00:08:36.820 --> 00:08:42.040
building technology and resources that
really help our communities that

134
00:08:42.040 --> 00:08:46.000
can address, you know, social,
social, and cultural issues in

135
00:08:46.000 --> 00:08:49.420
our community and creating the
space to do that. A

136
00:08:49.420 --> 00:08:51.880
lot of the mainstream tech
industry has focused on like

137
00:08:52.270 --> 00:08:55.920
the next big social application
I'm in is kind of

138
00:08:55.920 --> 00:08:58.770
out of touch with the
needs of, of local communities

139
00:08:58.780 --> 00:09:03.000
and diverse communities. So we
give ourselves a space to,

140
00:09:03.570 --> 00:09:06.360
you know, make technology part
of the solution in those

141
00:09:06.360 --> 00:09:10.130
spaces. Do you think that
these spaces, these kind of

142
00:09:10.130 --> 00:09:13.730
like sub sub spaces or
subgroups are always going to

143
00:09:13.730 --> 00:09:15.830
be necessary, or do you
think that we're moving towards

144
00:09:15.830 --> 00:09:20.780
some utopic future where a
regular run of the mill

145
00:09:20.780 --> 00:09:24.350
tech conference would be safe
for, You know, I think

146
00:09:24.350 --> 00:09:27.530
there, there will always be
a need for, you know,

147
00:09:27.530 --> 00:09:33.440
smaller communities and to have
groups with more affinities and

148
00:09:33.440 --> 00:09:38.540
more specific focuses, but it's,
it's obviously all of our

149
00:09:38.540 --> 00:09:43.310
sincere hope that more mainstream
tech conferences and tech events

150
00:09:43.310 --> 00:09:46.820
in tech spaces can be
more inclusive and can be

151
00:09:46.820 --> 00:09:50.540
more diverse. And there's a
number of steps that, you

152
00:09:50.540 --> 00:09:54.500
know, people can take to
help forward that. But I

153
00:09:54.500 --> 00:09:57.650
don't think it's an either
or question. I think we

154
00:09:57.650 --> 00:10:04.100
really need both mainstream spaces
and, you know, more private

155
00:10:04.100 --> 00:10:09.620
or smaller or local spaces.
Where do you all see

156
00:10:09.620 --> 00:10:13.220
the diff the defensiveness come
from? I think that when

157
00:10:13.220 --> 00:10:15.920
you, when, when working with
someone who's part of the

158
00:10:15.920 --> 00:10:19.970
majority system, you know, other
white men or other men,

159
00:10:20.930 --> 00:10:24.620
there's often a defensiveness. I
found this defensiveness in myself

160
00:10:24.620 --> 00:10:26.570
as well. Like, why do
you all need this? Like,

161
00:10:26.600 --> 00:10:28.700
really you needed to make
your own space. Now I'm

162
00:10:28.700 --> 00:10:31.340
excluded. Now, why can't I
go to women's hack or

163
00:10:31.340 --> 00:10:34.520
trans panic? W w where
inside of us as the

164
00:10:34.520 --> 00:10:37.910
majority is that, is that,
that defensiveness coming from, do

165
00:10:37.910 --> 00:10:43.340
you think, I mean, it's,
it's really difficult to confront

166
00:10:43.340 --> 00:10:49.160
your own privilege and sit
with being uncomfortable. I think

167
00:10:49.160 --> 00:10:55.400
everybody faces that to some
extent or another, and especially

168
00:10:55.400 --> 00:10:59.900
if it's the first time
that you're realizing, you know,

169
00:10:59.900 --> 00:11:04.850
like I still catch myself
doing it all the time.

170
00:11:06.020 --> 00:11:10.100
And then just like actively
try to like, read more,

171
00:11:10.160 --> 00:11:14.210
read books, read blogs, like
read other communities writing so

172
00:11:14.210 --> 00:11:18.530
that I can like, understand
what it's like to be,

173
00:11:18.530 --> 00:11:22.520
not me, That's it. I
like that to understand how

174
00:11:22.520 --> 00:11:25.850
it's like to be not
you sometimes though, I think

175
00:11:25.850 --> 00:11:29.120
that when one can find
themselves getting into a, a,

176
00:11:29.260 --> 00:11:31.660
a privilege kind of pecking
order, you know, and it,

177
00:11:31.660 --> 00:11:33.200
and it shouldn't be that
way. Should it, I mean,

178
00:11:33.200 --> 00:11:35.000
there shouldn't be like, well,
I'm more privileged than you,

179
00:11:35.000 --> 00:11:37.070
but you're more privileged than
this person. And then, you

180
00:11:37.070 --> 00:11:41.480
know, who's the least privileged.
It's not a contest. Yeah.

181
00:11:42.680 --> 00:11:46.250
Yeah. Going back to your
earlier question around, you know,

182
00:11:46.250 --> 00:11:49.970
why do we sort of
feel that sense of defensiveness?

183
00:11:49.970 --> 00:11:52.790
I think, especially when, you
know, you're a member of

184
00:11:52.790 --> 00:11:57.340
the group you've been raised
in a social structure where

185
00:11:57.340 --> 00:12:01.030
you feel entitled to be
a part of everything and

186
00:12:01.030 --> 00:12:04.690
go into any space and
have no, no part of

187
00:12:04.690 --> 00:12:08.650
the tech community, that's not
immediately available to you. So

188
00:12:08.650 --> 00:12:11.920
I think part of it,
you know, is dealing with

189
00:12:12.340 --> 00:12:16.660
boundaries and dealing with, you
know, that sort of sense

190
00:12:16.660 --> 00:12:21.970
of entitlement that, you know,
we are, or you know,

191
00:12:21.970 --> 00:12:26.100
that some groups are raised
to have. Yeah, that's a,

192
00:12:26.100 --> 00:12:27.780
that's a, that's an interesting
way to think about it.

193
00:12:28.290 --> 00:12:31.140
It's, it's not fun to
not be a part of

194
00:12:31.140 --> 00:12:34.410
the club and to not
necessarily be, I don't say

195
00:12:34.410 --> 00:12:36.870
welcome isn't necessarily the word,
but you know, it just

196
00:12:36.870 --> 00:12:39.480
not to be needed, you
know, there can be women's

197
00:12:39.480 --> 00:12:41.940
hackathons and there's just really
no reason for me to

198
00:12:41.940 --> 00:12:44.070
be there. And if I
did go to a women's

199
00:12:44.070 --> 00:12:48.900
hackathon, I could get really,
I could fall into, I

200
00:12:48.900 --> 00:12:53.490
think the term is mansplaining.
Maybe you could say, explain

201
00:12:53.490 --> 00:12:56.370
to the listeners what it
means to be a mansplainer.

202
00:12:57.820 --> 00:13:00.690
So one pattern we see
a lot now, and I'll

203
00:13:00.690 --> 00:13:05.040
talk about it specifically in
technology that you will see

204
00:13:05.040 --> 00:13:09.690
a lot of men in
tech explaining, explaining things to

205
00:13:09.690 --> 00:13:16.260
women in tech, in overly
simplified patronizing terms that make

206
00:13:16.260 --> 00:13:21.840
a lot of assumptions about
the woman's skillset. And that

207
00:13:21.840 --> 00:13:28.620
sort of construct her as
being less technical, less intelligent,

208
00:13:28.620 --> 00:13:34.260
less mature, less worldly. So
it's basically a one on

209
00:13:34.590 --> 00:13:39.450
one type of microaggression and
is a site of sort

210
00:13:39.450 --> 00:13:45.570
of how men sort of
demonstrate their power over women,

211
00:13:45.570 --> 00:13:51.270
but also a way that
their stereotypical perceptions of women

212
00:13:51.300 --> 00:13:55.620
play out in, in personal
interactions. What's a, what's a

213
00:13:55.620 --> 00:13:59.580
way for me when I'm
in an environment. And, and

214
00:13:59.580 --> 00:14:01.440
I, and I don't know
where the technical levels of

215
00:14:01.440 --> 00:14:04.140
people are to, to level
set. Like what's, what's the

216
00:14:04.140 --> 00:14:06.480
right way to phrase that
like, okay, well, I don't

217
00:14:06.480 --> 00:14:07.980
really know what level you
want me to come in

218
00:14:07.980 --> 00:14:10.140
at, but I, you know,
I want to basically find

219
00:14:10.140 --> 00:14:12.690
out how technical someone is.
So then I can tailor

220
00:14:12.690 --> 00:14:15.270
it to their level of
tech, not their gender. I

221
00:14:15.270 --> 00:14:18.570
would say, just ask. I
mean like, Hey, what's your

222
00:14:18.570 --> 00:14:21.750
background? What do you do?
You know, another thing that

223
00:14:21.750 --> 00:14:24.960
happens a lot in tech
spaces is that people make

224
00:14:24.960 --> 00:14:28.920
a lot of assumptions about
the roles and experience levels

225
00:14:28.920 --> 00:14:33.030
of women around them. So
often, you know, minimal assume

226
00:14:33.030 --> 00:14:38.070
that women are in HR
or in marketing or something

227
00:14:38.070 --> 00:14:41.730
like that, instead of, you
know, starting off the conversation

228
00:14:41.730 --> 00:14:46.020
like, Hey, what do you
do? Do you like, where

229
00:14:46.020 --> 00:14:48.090
do you work? What are
you interested in? What do

230
00:14:48.090 --> 00:14:50.580
you hack on? Stuff like
that. So I think just,

231
00:14:50.910 --> 00:14:55.150
you get getting to know
the people around you and,

232
00:14:55.150 --> 00:14:58.970
and making that the basis
of how you interact rather

233
00:14:58.970 --> 00:15:02.810
than stereotypes and assumptions is
how, how you can address

234
00:15:02.810 --> 00:15:05.500
that. Yeah. Yeah. I definitely
have found in my experience

235
00:15:05.500 --> 00:15:08.260
that this is a process
and not a destination, like

236
00:15:08.260 --> 00:15:11.320
I've, I was in a
meeting once in New York actually

237
00:15:11.320 --> 00:15:13.450
recently. And it was a
bunch of people from out

238
00:15:13.450 --> 00:15:16.840
of town. I think they
were from Brazil and their

239
00:15:16.840 --> 00:15:19.690
English was kind of off.
And I was trying to

240
00:15:19.690 --> 00:15:22.540
be rec I was trying
to recognize that their English

241
00:15:22.540 --> 00:15:24.760
was not necessarily there. So
I brought my, my English

242
00:15:24.760 --> 00:15:27.100
down to a, to a
more simplistic level. But at

243
00:15:27.100 --> 00:15:28.990
the same time, it was
a man and a woman.

244
00:15:29.500 --> 00:15:32.170
And I, even though I
think of myself as someone

245
00:15:32.170 --> 00:15:34.480
who is aware of these
issues, I still kind of

246
00:15:34.480 --> 00:15:38.050
instinctively gazed at the man
and looked at the man

247
00:15:38.050 --> 00:15:40.090
and deferred to the man
when it turned out, I

248
00:15:40.090 --> 00:15:42.820
learned about 10 minutes into
it that the man was

249
00:15:43.210 --> 00:15:47.140
the assistant and the woman
was the vice president. And

250
00:15:47.140 --> 00:15:48.760
I was kicking myself in
turn. I was like, Oh

251
00:15:48.790 --> 00:15:50.290
man, what am I doing?
You know what I mean?

252
00:15:50.290 --> 00:15:52.480
Like I kicked myself. I
was like, well, where's this

253
00:15:52.480 --> 00:15:54.250
coming from? I was like,
well, it's coming from 40

254
00:15:54.250 --> 00:15:56.770
years of of systems that
have set me up to

255
00:15:56.770 --> 00:15:59.260
just assume that the big
giant six foot tall man

256
00:15:59.260 --> 00:16:02.230
is probably the vice president.
And it was exactly inverted.

257
00:16:02.230 --> 00:16:04.960
It was almost like a
movie where the little tiny,

258
00:16:04.960 --> 00:16:07.000
petite woman was the VP
and the man was her

259
00:16:07.000 --> 00:16:10.930
assistant. And I just didn't
assume that, and I was

260
00:16:10.930 --> 00:16:14.380
kicking myself after that. Yeah.
I think, you know, it's

261
00:16:14.380 --> 00:16:20.560
absolutely a process of, you
know, continually evaluating, you know,

262
00:16:20.560 --> 00:16:24.100
the systems around us, how
we participate in them, how

263
00:16:24.100 --> 00:16:27.820
we can sort of be
better members of the community

264
00:16:27.820 --> 00:16:33.640
and confront, confront our own
biases and our own privilege

265
00:16:34.330 --> 00:16:38.170
and just be better members
of the community. And I

266
00:16:38.170 --> 00:16:43.210
think that's a lifelong process
for everybody. And like a

267
00:16:43.210 --> 00:16:46.630
lot of the times that
means owning up to something

268
00:16:46.630 --> 00:16:53.140
like, like you just said,
or, you know, listening for

269
00:16:53.140 --> 00:16:56.590
a long time when you
would normally speak, like recognizing

270
00:16:56.590 --> 00:17:00.190
you're in a situation where,
you know, you're probably gonna

271
00:17:00.190 --> 00:17:02.800
talk too much. Or, you
know, typically this is a

272
00:17:02.800 --> 00:17:06.730
place where people get talked
over and, and just listening

273
00:17:06.730 --> 00:17:10.660
or, you know, checking yourself
before you give a compliment.

274
00:17:10.660 --> 00:17:13.030
And like, is this actually
a compliment? Like I get

275
00:17:13.330 --> 00:17:17.650
complimented on the fact that
I code and like, So

276
00:17:17.650 --> 00:17:20.710
wait a second, you're a
professional developer and they're complimentary

277
00:17:20.890 --> 00:17:24.460
complimenting you on that URL
coder. Yeah. Or that it's,

278
00:17:24.730 --> 00:17:26.890
I've been told that it's
cute a lot, which is

279
00:17:27.820 --> 00:17:31.540
not a compliment. Is that
an example of what you,

280
00:17:31.720 --> 00:17:34.150
you used the word channeling,
you said that a microaggression,

281
00:17:34.150 --> 00:17:36.160
so Emilia, if I compliment
you on, Oh, you're a

282
00:17:36.160 --> 00:17:39.780
coder. Oh, that's great. That's
a microgrid. It definitely is

283
00:17:39.790 --> 00:17:46.420
in, in a sense that
men, I, it's not considered

284
00:17:46.420 --> 00:17:54.690
surprising or mold breaking or
like cute or special when

285
00:17:54.690 --> 00:17:58.440
men have technical abilities, but
when women have technical abilities,

286
00:17:58.440 --> 00:18:03.390
it's like, wow, I'm surprised
that you're technical. I'm going

287
00:18:03.390 --> 00:18:08.900
to demean your technical abilities
by calling them cute or,

288
00:18:08.900 --> 00:18:12.270
or turning it into an
aspect of your personality rather

289
00:18:12.270 --> 00:18:15.540
than, you know, your profession
and something that you've been

290
00:18:15.540 --> 00:18:18.240
doing for years, or just
feeling that you're in a

291
00:18:18.690 --> 00:18:24.960
place that you can bestow
a compliment or like approval

292
00:18:24.960 --> 00:18:29.720
on to this person for
what they're doing. Okay. So

293
00:18:29.720 --> 00:18:31.310
let me, let me ask
this and let me, let

294
00:18:31.310 --> 00:18:33.560
me kind of push a
little bit, because I want

295
00:18:33.560 --> 00:18:39.590
to understand that I respect
where you're coming from. And

296
00:18:39.590 --> 00:18:41.360
I think that people who
are listening, they want to

297
00:18:41.360 --> 00:18:43.610
respect that we, if we
assume that most people come

298
00:18:43.610 --> 00:18:47.930
into a personal interaction, not
intending to be aggressive, not

299
00:18:47.930 --> 00:18:52.910
intending to offend, how can
we have interactions with women

300
00:18:52.940 --> 00:18:57.740
or trans people or disabled
people or whatever, without feeling

301
00:18:57.740 --> 00:19:02.450
like we, as the dominant
system are, are walking through

302
00:19:02.450 --> 00:19:04.160
a minefield. You know what
I mean? Like I could

303
00:19:04.160 --> 00:19:06.950
see someone maybe listening to
this show going, gosh, I

304
00:19:06.950 --> 00:19:08.840
don't know what to say
anymore. Like, your shoes are

305
00:19:08.840 --> 00:19:10.970
awesome. Am I allowed to
compliment you on your shoes?

306
00:19:11.250 --> 00:19:15.350
You see what I'm saying?
Yeah. So, you know, I

307
00:19:15.350 --> 00:19:23.450
would characterize that reaction by,
by people in, especially in

308
00:19:23.450 --> 00:19:29.570
dominant groups, as you know,
irrelevant, mild discomfort. Like it's

309
00:19:29.570 --> 00:19:33.890
not too much to ask
that you are considerate of

310
00:19:34.460 --> 00:19:37.040
the people around you and
that you try not to

311
00:19:37.040 --> 00:19:42.500
produce oppressive structures. And the
way that you communicate underrepresented

312
00:19:42.500 --> 00:19:48.350
and marginalized groups in technology
face a number of challenges

313
00:19:48.380 --> 00:19:52.700
from being paid substantially less,
not being able to get

314
00:19:52.700 --> 00:19:57.680
work, being harassed on the
job in the workplace, in

315
00:19:57.680 --> 00:20:05.000
the mainstream tech community, having
to protect themselves from online

316
00:20:05.000 --> 00:20:09.530
harassment or having to experience
it or go through it

317
00:20:09.860 --> 00:20:14.150
and not being able to
achieve, you know, or have

318
00:20:14.150 --> 00:20:18.020
access to a lot of
the opportunities that mainstream groups

319
00:20:18.950 --> 00:20:22.370
have. So, you know, I
find one thing that does

320
00:20:22.370 --> 00:20:26.360
happen, particularly with the dominant
group in technology, which is

321
00:20:26.360 --> 00:20:29.210
white men, is that they
try to turn all of

322
00:20:29.210 --> 00:20:33.950
these conversations into about them
and about their comfort and

323
00:20:33.950 --> 00:20:38.090
about their discomfort or how
they're feeling about it when

324
00:20:38.090 --> 00:20:44.660
really that's not the relevant
part of the conversation. Eh,

325
00:20:45.770 --> 00:20:50.650
yeah, that's what I would
about that. It's difficult when

326
00:20:50.650 --> 00:20:53.650
you're trying to talk about
systemic inequality is within the

327
00:20:53.650 --> 00:20:58.900
tech industry and, you know,
you have to comfort someone

328
00:20:59.560 --> 00:21:03.100
so that they don't feel
like a bad person when

329
00:21:03.100 --> 00:21:06.040
really we all need to
be doing, doing the work

330
00:21:06.190 --> 00:21:09.850
and, you know, getting more
educated and doing a better

331
00:21:09.850 --> 00:21:14.340
job. Interesting. I, I think
you're, you're definitely getting to

332
00:21:14.340 --> 00:21:16.500
the heart of kind of
like the feelings that I

333
00:21:16.500 --> 00:21:20.310
have around this. Like there's
feelings of helplessness, there's feelings

334
00:21:20.310 --> 00:21:24.510
of defensiveness, you know, it's
like, well, I'm thinking about

335
00:21:24.510 --> 00:21:26.250
all the tapes that are
running through my head. Right.

336
00:21:26.250 --> 00:21:28.320
And you just said like,
the point is not to

337
00:21:28.320 --> 00:21:30.990
comfort me. Right. But at
the same time, I need

338
00:21:30.990 --> 00:21:32.340
to figure out where to
do what to do with

339
00:21:32.340 --> 00:21:35.760
that. Like where do I
put those feelings? You know,

340
00:21:35.790 --> 00:21:38.640
I mean, I should, presumably
I should channel them into

341
00:21:39.060 --> 00:21:43.560
a dismantling systems. Yeah, absolutely.
I mean, I think that,

342
00:21:43.950 --> 00:21:47.520
I think at the end
of the day, it's really

343
00:21:47.520 --> 00:21:54.090
about moving from a narcissistic
focus on, on individuals and

344
00:21:54.090 --> 00:21:58.590
towards community work and how,
and how we can start

345
00:21:58.590 --> 00:22:04.110
to dismantle these structures and
that ultimately getting stuck in,

346
00:22:04.380 --> 00:22:10.710
in personal guilt or, you
know, introspective feelings while it's

347
00:22:10.710 --> 00:22:13.470
an important part of the
process, we need to be

348
00:22:13.470 --> 00:22:16.680
able to move past that
in order to actually work

349
00:22:16.710 --> 00:22:20.970
on the systemic issues. So
I think that's sort of

350
00:22:20.970 --> 00:22:24.900
the ultimate, that's part of
the goal of sort of

351
00:22:24.900 --> 00:22:28.110
personal awakening around these issues.
I mean, a good place

352
00:22:28.110 --> 00:22:31.710
to start in that is,
you know, like model view

353
00:22:31.710 --> 00:22:36.030
culture. One of the things
why I think it's so

354
00:22:36.030 --> 00:22:40.650
important to publish is, and
like what, what brought us

355
00:22:40.650 --> 00:22:42.660
to doing this is because
we wanted more of those

356
00:22:42.660 --> 00:22:47.250
voices out there in a
more mainstream tech publication so

357
00:22:47.250 --> 00:22:52.260
that, you know, it wasn't
shocking that these perspectives of

358
00:22:52.260 --> 00:22:55.530
all these other people existed
and that, you know, it

359
00:22:55.530 --> 00:22:57.930
was something that you could
read and kind of like

360
00:22:57.930 --> 00:23:03.510
start to mentally model and
understand Is it, is it

361
00:23:03.510 --> 00:23:06.870
appropriate for me to, to,
to be as a member

362
00:23:06.870 --> 00:23:10.890
of the, the kind of
the, the majority to be

363
00:23:10.890 --> 00:23:13.230
trying to think about ways
that I can help. Like

364
00:23:13.230 --> 00:23:16.080
I I've noticed in the
last four or five years

365
00:23:16.590 --> 00:23:18.660
when I go to conferences
and I'm on a panel,

366
00:23:18.840 --> 00:23:21.060
if the panel is only
men or only white men,

367
00:23:21.060 --> 00:23:23.370
I've in the last five
years, I've started speaking up.

368
00:23:23.370 --> 00:23:26.340
I actually don't speak on
panels that are only white

369
00:23:26.340 --> 00:23:29.580
men anymore. Is that an
appropriate, is that an appropriate,

370
00:23:29.640 --> 00:23:31.860
but you know, albeit small
thing for me to do.

371
00:23:32.790 --> 00:23:37.110
Yeah, absolutely. I think, you
know, thinking about ways that

372
00:23:37.110 --> 00:23:44.550
we can use our, our
power, our influence, you know,

373
00:23:44.550 --> 00:23:48.770
our in ways that are
useful to the community is

374
00:23:48.770 --> 00:23:52.670
really important. So, you know,
as a speaker, I'm in

375
00:23:52.670 --> 00:23:55.760
a lot of industry events,
how can you advocate for

376
00:23:55.760 --> 00:24:00.920
more diversity? How can you
make sure that, you know,

377
00:24:00.920 --> 00:24:08.570
you're helping under represented and
marginalized voices get the exposure

378
00:24:08.840 --> 00:24:11.840
that they originally deserve in
the workplace, either as an

379
00:24:11.840 --> 00:24:16.850
employee or as a manager,
how can you help build

380
00:24:16.850 --> 00:24:19.880
more diverse teams? How can
you help make sure that

381
00:24:19.910 --> 00:24:25.370
the environment is one that's
healthy and conducive to the,

382
00:24:25.490 --> 00:24:30.110
to their success. And even
in, in online spaces, you

383
00:24:30.110 --> 00:24:34.310
know, how can you help
give more attention to diverse

384
00:24:34.910 --> 00:24:39.860
groups and diverse issues? How
can you demonstrate social consciousness

385
00:24:39.860 --> 00:24:42.080
to the people around you?
And if you're a member

386
00:24:42.080 --> 00:24:44.990
of the dominant group, how
can you work with other

387
00:24:44.990 --> 00:24:50.720
people that share your privilege
on education and knowledge? I

388
00:24:50.720 --> 00:24:53.210
think it's really important that
men work with other men

389
00:24:53.210 --> 00:24:56.990
on, on sexism and that
white people work with other

390
00:24:56.990 --> 00:25:00.550
white people on racism and,
and stuff like that. So

391
00:25:00.550 --> 00:25:02.980
what has been the reaction
since you launched the company?

392
00:25:03.490 --> 00:25:07.240
Oh, it's been really great
so far. Yeah. Where I'm

393
00:25:07.240 --> 00:25:11.380
incredibly excited about the community
response. So far, a lot

394
00:25:11.380 --> 00:25:15.610
of people have been in
touch with us saying that,

395
00:25:16.180 --> 00:25:20.230
you know, they feel that
this company really helps to

396
00:25:20.230 --> 00:25:24.610
address a market. That's not
being addressed in the existing

397
00:25:24.610 --> 00:25:28.510
media. We've had tons of
writers get in touch with

398
00:25:28.510 --> 00:25:32.680
us about writing for the
publication. One interesting thing that

399
00:25:32.680 --> 00:25:35.200
we do is that we
pay all of our writers.

400
00:25:35.200 --> 00:25:39.520
So something that tends to
happen in, in sort of

401
00:25:39.520 --> 00:25:43.720
the mainstream tech media is
that people, especially people from

402
00:25:43.870 --> 00:25:48.760
underrepresented marginalized groups are expect
to expected to produce content

403
00:25:48.760 --> 00:25:51.550
for free. So we want
to make sure that, you

404
00:25:51.550 --> 00:25:54.280
know, we pay all of
our authors. So that's been

405
00:25:54.580 --> 00:25:58.120
incredibly exciting and we have
our launch event coming up

406
00:25:58.210 --> 00:26:01.090
as well in San Francisco.
And we plan on doing

407
00:26:01.360 --> 00:26:04.420
more community events that are
sort of focused around these

408
00:26:04.420 --> 00:26:07.780
topics first in the West
coast, but then expanding out.

409
00:26:08.620 --> 00:26:10.270
And then how is this
different from, is this an

410
00:26:10.270 --> 00:26:13.030
online magazine? But you said
specifically it's a media company.

411
00:26:13.030 --> 00:26:16.030
So I'm what, what other
things other than authorship are

412
00:26:16.030 --> 00:26:21.520
you providing to the community?
So we are, we think

413
00:26:21.520 --> 00:26:25.030
that print media is very
important. And so we've been

414
00:26:25.030 --> 00:26:28.570
selling when we launch, we
are also selling these print

415
00:26:28.570 --> 00:26:34.510
subscriptions. So small books that
will print quarterly with exclusive

416
00:26:34.510 --> 00:26:36.940
content for them. And then
maybe some of the best

417
00:26:36.940 --> 00:26:42.220
of kind of reprints added
in Like a scene. Like

418
00:26:42.220 --> 00:26:45.390
if you remember the Xen.
Yeah. It definitely is super

419
00:26:45.390 --> 00:26:49.800
inspired by seeing culture. We've
both, especially done quite a

420
00:26:49.800 --> 00:26:52.890
bit of publishing of scenes
in literary journals in the

421
00:26:52.890 --> 00:26:58.740
past. And there's just something
about actually, you know, having

422
00:26:58.740 --> 00:27:02.760
your community have a, have
like books and have publications.

423
00:27:02.760 --> 00:27:05.790
And, you know, we have
a conference we'd like to

424
00:27:05.850 --> 00:27:09.750
put on a conference later
in the year. It's definitely

425
00:27:09.750 --> 00:27:12.960
part of our plans. Yeah.
We're getting set up with

426
00:27:12.960 --> 00:27:18.030
podcast equipment. So we'll be
doing a podcast shortly, and

427
00:27:18.030 --> 00:27:22.440
we're also hoping to do
some video production as well

428
00:27:22.440 --> 00:27:26.940
as news, more news coverage.
Like you would see from

429
00:27:27.390 --> 00:27:31.230
a larger and more mainstream
tech publication. We also have

430
00:27:31.230 --> 00:27:36.330
a weekly newsletter that covers
kind of like the events

431
00:27:36.360 --> 00:27:39.180
that had happened in the
past week, in the, in

432
00:27:39.180 --> 00:27:42.660
the tech world with like
a somewhat of a critical

433
00:27:42.660 --> 00:27:46.080
eye. And then also just
like, what's interesting, that's coming

434
00:27:46.080 --> 00:27:49.520
up next. So there's, there's
the website, which is the

435
00:27:49.550 --> 00:27:53.420
ongoing regular content by paid
authors in the community. Then

436
00:27:53.420 --> 00:27:57.590
there's the four kind of
quarterly books. So actual physical

437
00:27:57.590 --> 00:27:59.500
books that you get. So
if you click with subscribed

438
00:27:59.500 --> 00:28:01.310
right now, I can go
and subscribe and I'll get

439
00:28:01.310 --> 00:28:04.880
these quarterly zenes for lack
of a better word. Then

440
00:28:05.120 --> 00:28:06.950
it sounds like you're going
to build a series of

441
00:28:07.010 --> 00:28:09.980
events. I'll be able to
go. And I'm like, you've

442
00:28:09.980 --> 00:28:12.470
got your launch party coming
up on the 30th in

443
00:28:12.470 --> 00:28:16.220
San Francisco. Do you anticipate
that the conferences will be

444
00:28:16.490 --> 00:28:19.670
tech conferences that we'll talk
about issues of tech or

445
00:28:19.670 --> 00:28:21.740
will it be just what,
what will be the focus

446
00:28:21.740 --> 00:28:26.630
of your events? Yeah, so
we're still in development for

447
00:28:26.630 --> 00:28:30.380
that, but you know, our
company is very much focused

448
00:28:30.410 --> 00:28:37.910
on specifically the tech community.
So as we develop conference

449
00:28:37.910 --> 00:28:41.150
ideas, we'll be exploring things
that are sort of at

450
00:28:41.150 --> 00:28:45.230
the intersection of tech and
social justice in diversity. So

451
00:28:45.230 --> 00:28:50.090
everything from software that benefits
a diverse community is to

452
00:28:50.090 --> 00:28:55.910
how software does impact our
communities and other sort of

453
00:28:55.910 --> 00:28:58.910
things in that vein Of
the, of the articles that

454
00:28:58.910 --> 00:29:01.340
you initially launched, which ones
do you think maybe like

455
00:29:01.340 --> 00:29:02.900
got the most coverage or
you think that are the

456
00:29:02.900 --> 00:29:07.730
most controversial that people got
excited about? So we had

457
00:29:07.730 --> 00:29:14.150
a wonderful piece by Kate
loss who wrote she's the

458
00:29:14.150 --> 00:29:17.300
author of the boy Kings,
which was a book about

459
00:29:17.300 --> 00:29:21.410
the early years of Facebook.
And she wrote an amazing

460
00:29:21.410 --> 00:29:26.960
essay that looked at how
surveillance on social networks has

461
00:29:26.960 --> 00:29:30.860
been gender. So for example,
people looking at photos of

462
00:29:30.860 --> 00:29:35.030
women drives the vast majority
of sight activity on social

463
00:29:35.030 --> 00:29:38.270
networks and has for years.
So she talked about this

464
00:29:38.270 --> 00:29:44.140
idea of the surveillance that
has happened on new sites

465
00:29:44.140 --> 00:29:48.520
for years, but how with
the, with the revelations around

466
00:29:48.520 --> 00:29:52.660
the NSA surveillance, sort of
the power dynamics that are

467
00:29:52.660 --> 00:29:56.580
there and some of the
political dynamics as well, That

468
00:29:56.580 --> 00:29:58.680
was a really excellent piece
that she put together. And

469
00:29:58.680 --> 00:30:01.200
she explored some of the
things that the NSA were

470
00:30:01.320 --> 00:30:05.640
doing that were completely inappropriate
uses of power. Yeah, absolutely.

471
00:30:05.640 --> 00:30:11.310
And drawing parallels to how
early startup employees have abused

472
00:30:11.310 --> 00:30:14.310
technology in the, in similar
ways. We also had a

473
00:30:14.310 --> 00:30:19.590
great piece that collected interviews
from many professionals in the

474
00:30:19.590 --> 00:30:24.600
community that was advice for
people from diverse backgrounds that

475
00:30:24.600 --> 00:30:29.100
are just getting into tech,
which was a really incredibly

476
00:30:29.100 --> 00:30:32.970
well received. And we also
had some great pieces that

477
00:30:32.970 --> 00:30:36.030
looked at the search for
the next sucker Berg, which

478
00:30:36.030 --> 00:30:39.630
is a really popular sort
of construct in tech yet

479
00:30:40.110 --> 00:30:43.200
in a variety of different
places, as well as some

480
00:30:43.200 --> 00:30:46.830
stuff that looked at online
harassment on the internet and

481
00:30:46.830 --> 00:30:51.690
the, in the intersection of
platform features with harassing and

482
00:30:51.690 --> 00:30:56.310
abusing behavior. So really just
a broad range of topics

483
00:30:56.790 --> 00:31:00.330
that are relevant to diverse
communities, but also look at

484
00:31:00.330 --> 00:31:05.100
things from sort of a
cultural and social perspective. Yeah.

485
00:31:05.100 --> 00:31:08.340
You've got a pretty amazing
group of, of authors. I

486
00:31:08.340 --> 00:31:11.790
know that Courtney Ziegler has
got a PhD and he

487
00:31:11.790 --> 00:31:14.490
is a, an amazing person
and a great author and

488
00:31:14.490 --> 00:31:17.580
to put together one of
those pieces as well. Yeah.

489
00:31:17.580 --> 00:31:22.110
He's great. Do you think
that you'll be putting out

490
00:31:22.110 --> 00:31:24.150
new content kind of every
week or what's your, what's

491
00:31:24.150 --> 00:31:26.910
your general? Like how often
should I come back to

492
00:31:26.910 --> 00:31:31.350
model view culture? So we're
planning on publishing full issues

493
00:31:31.680 --> 00:31:35.550
every three weeks at this
point. And then the quarterly

494
00:31:35.550 --> 00:31:38.220
is get published four times
a year, but we'll also

495
00:31:38.220 --> 00:31:43.260
have content in between issues
that look at current news

496
00:31:43.260 --> 00:31:46.800
and events in the community
that will continue news coverage

497
00:31:46.870 --> 00:31:50.460
at events. We're going to
be going to she's geeky

498
00:31:50.910 --> 00:31:54.900
this weekend. There's another event
coming up in February called

499
00:31:54.900 --> 00:31:57.810
lesbians, who tech on that
we'll have some coverage from.

500
00:31:58.050 --> 00:32:01.770
So issues will be coming
out about every three weeks,

501
00:32:01.770 --> 00:32:04.440
but we'll also hoping to
have a steady drum beat

502
00:32:04.470 --> 00:32:07.650
of other news and content.
Do you think you'll do

503
00:32:07.650 --> 00:32:09.720
apps as well? Or is
this something that I will

504
00:32:09.720 --> 00:32:11.910
just use RSS and the
mailing list and then the

505
00:32:11.910 --> 00:32:15.540
paid subscription to access So
far? That's the plan? I

506
00:32:15.540 --> 00:32:21.630
mean, I'm the only developer,
so we're, we're kind of

507
00:32:21.630 --> 00:32:24.600
growing as we need to.
And the response to this

508
00:32:24.600 --> 00:32:29.970
has been really good, you
know, like the site is

509
00:32:29.970 --> 00:32:32.580
mobile. So I don't think
that we need a specific

510
00:32:32.580 --> 00:32:36.060
app yet. Yeah. It looks
like some of these, some

511
00:32:36.060 --> 00:32:38.730
of these things like the
article by Kate loss has

512
00:32:38.730 --> 00:32:42.560
already upwards of thousands of
hundreds of shares on Twitter,

513
00:32:42.560 --> 00:32:45.950
hundreds of shares on, on
Facebook. So that basically went

514
00:32:45.950 --> 00:32:49.660
viral, which is fantastic. Yeah.
I mean, we can't really

515
00:32:49.660 --> 00:32:54.110
share like traffic numbers, but
there's a huge audience. Yeah.

516
00:32:54.110 --> 00:32:56.470
I, of course I have.
I'm only gleaning your traffic

517
00:32:56.470 --> 00:32:59.470
from looking at your number,
the number of social shares.

518
00:32:59.470 --> 00:33:01.510
And when something's in the
hundreds of shares, then you

519
00:33:01.510 --> 00:33:04.930
know, that people are reading,
which is fantastic. Yeah. That's

520
00:33:04.930 --> 00:33:07.780
something that's really exciting for
us is that sometimes when

521
00:33:07.780 --> 00:33:12.730
you look at different populations
individually, like, you know, this

522
00:33:12.730 --> 00:33:17.440
population is only, this population
is only X percent of

523
00:33:17.440 --> 00:33:21.280
people in tech. This population
is only X percent, but

524
00:33:21.280 --> 00:33:24.940
when you actually add up,
you know, all the number

525
00:33:24.940 --> 00:33:28.190
of people in those groups
and their social influence and

526
00:33:28.270 --> 00:33:31.270
their power and technology and
their influence and their ability

527
00:33:31.270 --> 00:33:35.260
is you're looking at a
massive market. That's really being

528
00:33:35.260 --> 00:33:38.710
underserved by a lot of
the mainstream infrastructure. So we're

529
00:33:38.710 --> 00:33:42.340
incredibly excited to be, you
know, one of the organizations

530
00:33:42.340 --> 00:33:46.390
that is focused on that
market. Yeah. You have this

531
00:33:46.390 --> 00:33:48.490
idea of an organizational subscription.
So I mean, I could

532
00:33:48.490 --> 00:33:51.700
see where you could make
money by having individuals subscriptions,

533
00:33:51.700 --> 00:33:54.010
but as with any media
company, you know, that people

534
00:33:54.010 --> 00:33:56.410
are struggling with the idea
of eyeballs. How do you

535
00:33:56.410 --> 00:33:59.140
think that you'll scale organizationally,
do you think that a

536
00:33:59.140 --> 00:34:02.770
company would buy a subscription
or large companies? Yeah, so

537
00:34:02.770 --> 00:34:06.520
actually the, the company's subscription
to the quarterly, which is

538
00:34:06.520 --> 00:34:08.800
that you get packs of
books, you can get, you

539
00:34:08.800 --> 00:34:11.830
know, sir, you know, bigger
numbers that are all shipped

540
00:34:11.830 --> 00:34:14.080
to you to put in
your office or distribute to

541
00:34:14.080 --> 00:34:18.790
your employees. Several companies that,
you know, friends worked at,

542
00:34:19.420 --> 00:34:21.580
or just people that we
talked to as we were

543
00:34:21.580 --> 00:34:25.180
repairing were like, actually, you
need to sell them in

544
00:34:25.180 --> 00:34:28.330
packs. Like it was something
that was actually pretty actively

545
00:34:28.330 --> 00:34:32.620
requested. I think that there
are some tech companies who

546
00:34:32.620 --> 00:34:36.520
do like take an, you
know, an active role or

547
00:34:36.520 --> 00:34:38.770
have employees who take an
active role in wanting to

548
00:34:38.770 --> 00:34:42.280
support this kind of media
and wanting to educate themselves

549
00:34:42.280 --> 00:34:46.570
and make their companies better
places. Yeah. I'm really excited

550
00:34:46.570 --> 00:34:48.220
that you guys are going
to get into podcasting as

551
00:34:48.220 --> 00:34:50.110
well. And the idea of
video, I would love to

552
00:34:50.110 --> 00:34:53.260
hear the voices of the
authors sharing after the fact,

553
00:34:53.260 --> 00:34:56.170
like if, if they, if
they break a news story

554
00:34:56.620 --> 00:34:59.410
and then like, what are
the results of that? Yeah.

555
00:34:59.410 --> 00:35:02.200
That's a great idea. We
have been reading your blog

556
00:35:02.200 --> 00:35:06.070
posts back, getting into podcasting,
and we got this mic,

557
00:35:06.100 --> 00:35:09.400
this fancy mic that you
recommended. So we're looking forward

558
00:35:09.790 --> 00:35:13.660
to getting into that too.
So I think there's tons

559
00:35:13.660 --> 00:35:17.560
of opportunities for, for media
in this space. You know,

560
00:35:17.560 --> 00:35:19.630
we'd love to do like
an art show at some

561
00:35:19.630 --> 00:35:24.010
point. So we have, we
have high ambitions, but it's

562
00:35:24.010 --> 00:35:26.470
early in the game. That's
great. Well, it's exciting to

563
00:35:26.470 --> 00:35:30.040
have, you know, fresh new
voices on the internet with

564
00:35:30.040 --> 00:35:33.460
model view, culture.com. You've got
a great lineup of authors

565
00:35:33.460 --> 00:35:35.590
that I assume is going
to continue to expand. It

566
00:35:35.590 --> 00:35:38.130
sounds like people have been
putting in submissions. How would

567
00:35:38.130 --> 00:35:39.720
someone get in contact with
you if they felt that

568
00:35:39.720 --> 00:35:41.700
they wanted to have something
to share on the site?

569
00:35:42.680 --> 00:35:46.190
Yeah. So just on model
view, culture.com, there's a page

570
00:35:46.190 --> 00:35:50.930
for contributors and it has
all the information that you

571
00:35:50.930 --> 00:35:53.420
need to get started, but
we usually start conversations over

572
00:35:53.420 --> 00:35:56.270
email. Okay, Cool. So people
can go to model, view

573
00:35:56.270 --> 00:35:58.700
culture. They can subscribe, learn
about events, learn about the

574
00:35:58.700 --> 00:36:00.170
authors. And then if you
make sure you scroll down

575
00:36:00.170 --> 00:36:03.500
to the bottom, you can
advertise, there's a link for

576
00:36:03.500 --> 00:36:06.590
con contribute and then they
can follow you on Facebook,

577
00:36:06.590 --> 00:36:12.260
Twitter, and Instagram. Yeah. Thank
you. Well, I appreciate you

578
00:36:12.800 --> 00:36:15.410
educating me with some of
the basics and then also

579
00:36:15.410 --> 00:36:18.440
letting us understand your new
media company, what you're trying

580
00:36:18.440 --> 00:36:20.450
to accomplish and what the
future is from all of

581
00:36:20.450 --> 00:36:23.150
you culture. So thank you
so much. Amelia Greenhall and

582
00:36:23.150 --> 00:36:25.490
Shanley Kane for chatting with
me today. Thank you for

583
00:36:25.490 --> 00:36:28.520
having us. This has been
another episode of Hanselminutes and

584
00:36:28.520 --> 00:36:29.780
we'll see you again next
week.

