WEBVTT FILE

1
00:00:00.180 --> 00:00:03.360
Hi, this is Scott. I
really appreciate our sponsors because

2
00:00:03.360 --> 00:00:06.300
they make the show possible.
Today's show is sponsored by

3
00:00:06.300 --> 00:00:10.500
developer express, become a UI
superhero with dev express controls

4
00:00:10.500 --> 00:00:15.030
and libraries. Deliver elegant.net solutions
that address customer needs today

5
00:00:15.420 --> 00:00:19.500
by leveraging your existing knowledge,
you can build next generation

6
00:00:19.500 --> 00:00:23.610
touch enabled solutions for tomorrow,
you can download your free

7
00:00:23.700 --> 00:00:45.140
30 day trial@dxdothanselminutes.com. That's dx.hanselminutes.com.
<inaudible>. Hi, this is Scott

8
00:00:45.140 --> 00:00:47.960
Hanselman. This is another episode
of Hansel minutes today. I'm

9
00:00:47.960 --> 00:00:51.590
talking with Paige Bailey. She
is a data scientist machine

10
00:00:51.590 --> 00:00:54.320
learning and AI expert, and
you've done a bunch of

11
00:00:54.320 --> 00:00:57.860
cool stuff. You've worked in
the, in the geo. What

12
00:00:57.860 --> 00:01:00.530
is it called? Geosciences and
like oil. And you worked

13
00:01:00.530 --> 00:01:03.620
at Chevron and you did
work with NASA and physics

14
00:01:03.620 --> 00:01:08.120
and the space. Absolutely. So
I'm my background is geophysics

15
00:01:08.120 --> 00:01:11.330
and carbonate geology, and that
meant that I got to

16
00:01:11.330 --> 00:01:14.840
do a lot of interesting
stuff with subsurface geoscience, and

17
00:01:14.840 --> 00:01:19.100
then also for planetary science,
which is learning how I'm

18
00:01:19.130 --> 00:01:21.170
learning, how our, our earth
can tell us a little

19
00:01:21.170 --> 00:01:25.400
bit about other planets. So,
yeah, it was a lot

20
00:01:25.400 --> 00:01:28.400
of fun. So you were
using machine learning and data

21
00:01:28.400 --> 00:01:30.950
science and things like that
to ask questions that you

22
00:01:31.010 --> 00:01:35.450
did not know the answer
to. Absolutely. So the most

23
00:01:35.450 --> 00:01:37.880
of the work that I
did at Chevron was around

24
00:01:38.030 --> 00:01:43.970
drilling optimization and completions optimization.
So drilling optimization is like,

25
00:01:44.210 --> 00:01:48.440
how fast can you drill
the well and completions optimization

26
00:01:48.470 --> 00:01:51.290
is how well can you
get the oil out of

27
00:01:51.290 --> 00:01:55.220
the ground once you've drilled
it? So how, how effectively

28
00:01:55.220 --> 00:02:00.020
can you hold open the,
the wellbore itself and facilitate

29
00:02:00.020 --> 00:02:03.170
the movement of hydrocarbons, which
is just gas and oil

30
00:02:03.440 --> 00:02:06.590
back up to the surface.
Wow. The reason that I

31
00:02:06.590 --> 00:02:08.750
bring that up and why
that's interesting is because we're

32
00:02:08.750 --> 00:02:11.150
going to talk about machine
learning kind of one Oh

33
00:02:11.150 --> 00:02:13.790
one here, but what I
like about your background is

34
00:02:13.790 --> 00:02:16.730
it's extremely practical. There's a
lot of people who talk

35
00:02:16.730 --> 00:02:20.270
about machine learning in a
very theoretical context and data

36
00:02:20.270 --> 00:02:23.840
science and all those things,
but to understand it and

37
00:02:23.840 --> 00:02:26.600
use it in a real
practical and physical way, I

38
00:02:26.600 --> 00:02:29.390
think is really interesting, Right?
Like there, there's so many

39
00:02:29.390 --> 00:02:34.310
kind of toy problems available
online with very structured data.

40
00:02:34.850 --> 00:02:37.910
And, you know, it's, it's
always very simple to see

41
00:02:37.910 --> 00:02:42.050
kind of a machine learning
problem, subset, and to 300

42
00:02:42.050 --> 00:02:45.380
records and like maybe four
or five variables and all

43
00:02:45.380 --> 00:02:47.660
of the data's nice and
friendly and you get a

44
00:02:47.660 --> 00:02:50.390
very clear result, but in
the real world, it's hardly

45
00:02:50.390 --> 00:02:53.300
ever like that. Right? The
real world is quite dirty.

46
00:02:54.530 --> 00:02:56.550
One of the things that
I have a little bit

47
00:02:56.550 --> 00:03:00.400
of trouble with is that
I tend to clump together,

48
00:03:00.400 --> 00:03:02.380
all these different technologies. I
did it. I did it

49
00:03:02.380 --> 00:03:06.340
even in your intro data
science, that's a thing, machine

50
00:03:06.340 --> 00:03:09.070
learning. That's a thing, AI,
that's a thing. But for

51
00:03:09.070 --> 00:03:11.050
someone like me that doesn't
know what any of those

52
00:03:11.050 --> 00:03:13.450
things mean. I just kind
of clump them together into

53
00:03:13.450 --> 00:03:16.210
the general family of like
data science and machine learning.

54
00:03:16.210 --> 00:03:19.680
Maybe you could tease those
apart for us. Oh, well,

55
00:03:19.710 --> 00:03:22.680
so I'm glad that you
said that. Cause everybody seems

56
00:03:22.680 --> 00:03:25.200
to have an opinion about
what data science is and

57
00:03:25.200 --> 00:03:29.010
there, none of them are
the same. So, so it's,

58
00:03:29.010 --> 00:03:31.470
so you were in, you
were in very good company,

59
00:03:31.530 --> 00:03:35.820
but data science is actually
kind of a conflation of

60
00:03:35.820 --> 00:03:40.260
something called data engineering, which
is, you know, sort of

61
00:03:40.830 --> 00:03:46.290
typical tasks that a database
engineer would do. So building

62
00:03:46.290 --> 00:03:50.790
data pipelines, getting everything into
a consistent format, doing a

63
00:03:50.790 --> 00:03:53.760
lot of data cleaning. So
making sure that everything is

64
00:03:53.760 --> 00:03:57.090
in this, all of your
data types are similar. You

65
00:03:57.090 --> 00:04:00.630
know, they're all spelled correctly,
they're all in consistent formats.

66
00:04:01.680 --> 00:04:05.820
Then there's also the additional
component of the statistical analysis.

67
00:04:06.300 --> 00:04:10.080
So looking at data and
making sure that if you

68
00:04:10.080 --> 00:04:15.750
have a certain population, those
populations are evenly represented throughout

69
00:04:15.750 --> 00:04:18.680
the data. And then machine
learning is, is more of

70
00:04:18.690 --> 00:04:23.310
the predictive modeling aspect. So
if you're doing machine learning,

71
00:04:23.370 --> 00:04:28.920
you're usually building a model.
Hopefully you have enough understanding

72
00:04:28.920 --> 00:04:32.190
of statistics to know that
the data that you're inputting

73
00:04:32.190 --> 00:04:35.130
into the model is a
representative sample of a whole.

74
00:04:36.360 --> 00:04:41.040
And then deep learning is
just doing predictive modeling on

75
00:04:41.040 --> 00:04:44.310
a whole bunch of data.
So a higher dimensional space

76
00:04:45.120 --> 00:04:48.570
and usually leveraging a GPU
or something like a spark

77
00:04:48.570 --> 00:04:54.570
cluster. Yep. So, so that's,
that's kind of, does that

78
00:04:54.570 --> 00:04:57.120
make a little bit more
sense? So data science is

79
00:04:57.120 --> 00:05:02.460
a conflation of data engineering,
statistical analysis and machine learning

80
00:05:03.630 --> 00:05:05.910
machine learning is, is something
that you do if you

81
00:05:05.910 --> 00:05:09.840
want to do predictive modeling
and deep learning is, is

82
00:05:09.840 --> 00:05:12.540
just doing predictive modeling on
a whole heck of a

83
00:05:12.540 --> 00:05:18.840
lot of data and usually
usually higher dimensional spaces and

84
00:05:18.870 --> 00:05:22.680
usually leveraging something like a
GPU. Okay. So how much

85
00:05:22.680 --> 00:05:26.190
data do I need before
I get to call myself

86
00:05:26.190 --> 00:05:28.680
a data scientist? Like I
spent a lot of time

87
00:05:28.680 --> 00:05:32.610
in tens of thousands of
records in Excel, 20, 30

88
00:05:32.610 --> 00:05:34.380
years ago. I was so
I must have been doing

89
00:05:34.380 --> 00:05:38.460
data cleaning and formatting and
structuring. And that, that sucked

90
00:05:39.570 --> 00:05:44.100
Well. Yes, it, it does
suck all the time, but,

91
00:05:44.130 --> 00:05:47.430
but I mean, there's, there's
no, there's no fun aspect

92
00:05:47.430 --> 00:05:51.150
of data cleaning like 90%
of your job as a

93
00:05:51.150 --> 00:05:55.370
data scientist is getting data
into a nicely wrangled format.

94
00:05:56.760 --> 00:05:59.690
But the, I would say
if you, if you look

95
00:05:59.690 --> 00:06:03.410
at the, the examples of
machine learning online, a lot

96
00:06:03.410 --> 00:06:07.640
of models are built using
like 500 records. So very,

97
00:06:07.640 --> 00:06:11.780
very little like 500 lines
in an Excel spreadsheet with

98
00:06:11.780 --> 00:06:16.250
like six or seven columns.
And that could build a

99
00:06:16.250 --> 00:06:19.450
predictive model. You know? So
it's not about size, like

100
00:06:19.450 --> 00:06:21.490
when I say data science
or we say machine learning,

101
00:06:21.940 --> 00:06:23.980
I don't need to have
terabytes of stuff. Like that's

102
00:06:23.980 --> 00:06:27.430
a good myth for us
to bust. Absolutely. You don't

103
00:06:27.430 --> 00:06:31.060
need terabytes of data at
all. And if you want

104
00:06:31.060 --> 00:06:35.350
to do deep learning. So
I think there was an

105
00:06:35.350 --> 00:06:39.820
example, there was an example
with something called cognitive services

106
00:06:39.850 --> 00:06:43.720
recently, where you can train
a model to recognize a

107
00:06:43.720 --> 00:06:46.630
face using just five or
six photos of that person's

108
00:06:46.630 --> 00:06:49.960
space. So it's, it's, as
long as you have kind

109
00:06:49.960 --> 00:06:54.850
of like a base that
the computer can understand. So

110
00:06:54.850 --> 00:06:57.280
like they, they know where
the eyes are. They know

111
00:06:57.280 --> 00:07:00.190
where the eyebrows are, they
know where the noses, the

112
00:07:00.190 --> 00:07:02.590
mouth and those sorts of
things. They can kind of

113
00:07:02.590 --> 00:07:06.490
suss out the characteristics of
a person's face very quickly.

114
00:07:07.090 --> 00:07:09.640
And it's also, it's also
kind of like where, when

115
00:07:09.640 --> 00:07:13.300
your surface book or your
iPhone or something recognizes your

116
00:07:13.300 --> 00:07:17.860
face and uses that to
unlock it. That's using, that's

117
00:07:17.860 --> 00:07:21.640
using a deep learning model,
but it's certainly not, you

118
00:07:21.640 --> 00:07:24.490
know, terabytes and terabytes of
data about your face. It's

119
00:07:24.490 --> 00:07:27.100
just taking a couple of
pictures of it. Okay. Now

120
00:07:27.100 --> 00:07:29.890
we've talked about and conflated
two different kinds of data.

121
00:07:29.920 --> 00:07:32.860
Like I can think about
like Excel or, you know,

122
00:07:32.860 --> 00:07:34.630
it, would it be two
dimensional data like rows and

123
00:07:34.630 --> 00:07:39.370
columns and then, or rows
and many columns. And then

124
00:07:40.210 --> 00:07:44.080
you mentioned pictures, which is
that like my system brings

125
00:07:44.080 --> 00:07:46.780
in JPEGs and bitmaps, or
is that my system thinks

126
00:07:46.780 --> 00:07:52.150
about matrices with RGB values.
So it's usually, so it

127
00:07:52.150 --> 00:07:56.980
could be either one, but
usually it's the, the latter,

128
00:07:56.980 --> 00:08:02.230
the RGB values. So if
you're, if you pull in

129
00:08:02.230 --> 00:08:06.310
a picture into a deep
learning model, the first step

130
00:08:06.640 --> 00:08:11.050
is, is usually that it
turns it into three different

131
00:08:11.050 --> 00:08:13.780
components, right? So you have
your, your red values, your

132
00:08:13.780 --> 00:08:17.830
green values and your blue
values, except they're, they're in

133
00:08:17.830 --> 00:08:23.080
a different color spectrum. And,
and then the, the model

134
00:08:23.080 --> 00:08:26.080
kind of runs on those
pixels and starts to pick

135
00:08:26.080 --> 00:08:30.520
out which components would indicate
a cap or which components

136
00:08:30.520 --> 00:08:33.850
would indicate a dog. And
the thing about deep learning.

137
00:08:34.510 --> 00:08:39.010
So machine learning, you have
things like random forests and

138
00:08:39.010 --> 00:08:42.820
decision trees and, you know,
linear aggression and all of

139
00:08:42.820 --> 00:08:46.180
those little wonderful things that
you've probably heard about. And

140
00:08:46.180 --> 00:08:49.900
for deep learning, there, there
are a lot of different,

141
00:08:50.560 --> 00:08:54.250
there are a lot of
different algorithms there as well,

142
00:08:55.530 --> 00:08:59.550
but they're, but they're less
easy to, to kind of

143
00:08:59.550 --> 00:09:02.250
audit, right? So if you
build out a, if you

144
00:09:02.250 --> 00:09:06.300
build out a, a decision
tree, it gives you a

145
00:09:06.300 --> 00:09:10.110
series of yes or no
questions. So the example I

146
00:09:10.110 --> 00:09:13.260
always like to use is
if you have a decision

147
00:09:13.260 --> 00:09:15.870
tree model that determines whether
or not a person gets

148
00:09:15.870 --> 00:09:19.770
alone, it'll probably look at
things like how much money's

149
00:09:19.770 --> 00:09:23.280
in their bank accounts and
whether or not they're employed

150
00:09:23.880 --> 00:09:27.270
and whether or not they've
defaulted on a loan before.

151
00:09:27.930 --> 00:09:31.380
And using that information, it'll
say like, Oh, well, you

152
00:09:31.380 --> 00:09:35.400
know, their bank account is
currently overdrawn and they've defaulted

153
00:09:35.400 --> 00:09:38.490
on a loan before, and
they're not employed, so let's

154
00:09:38.490 --> 00:09:42.570
not give them a loan
again, you know? And, and

155
00:09:42.570 --> 00:09:46.080
that's, that would be each
one of those questions would

156
00:09:46.080 --> 00:09:49.670
be a branch in your
machine learning decision tree. Okay.

157
00:09:50.720 --> 00:09:53.120
So deep learning is more
structured and it's part of

158
00:09:53.120 --> 00:09:58.520
that family of machine learning
things. Yes. Okay. And it's,

159
00:09:58.520 --> 00:10:00.650
and it's harder to audit.
So like I said, the

160
00:10:00.660 --> 00:10:03.530
decision tree, you would be
able to point back at

161
00:10:03.530 --> 00:10:06.800
those questions and say like,
Oh, well, you know, we

162
00:10:06.800 --> 00:10:09.140
answered no and no, and
no. And so we didn't

163
00:10:09.140 --> 00:10:12.740
give them a loan. And
that way, if somebody tried

164
00:10:12.740 --> 00:10:16.760
to Sue you, you would
have an answer. Whereas deep

165
00:10:16.760 --> 00:10:21.230
learning, you give the computer
the data and you say,

166
00:10:21.230 --> 00:10:24.290
computer, give me an answer.
And the computer gives you

167
00:10:24.290 --> 00:10:27.110
an answer and it's right.
Like 99% of the time,

168
00:10:27.320 --> 00:10:31.040
but you have no clue
what it's up to. Okay.

169
00:10:31.070 --> 00:10:34.280
That's good. That, that, that,
there's lots of different angles

170
00:10:34.280 --> 00:10:36.260
to come at the, what's
the difference between deep learning

171
00:10:36.260 --> 00:10:39.290
and machine learning question. But
that one is like, I

172
00:10:39.290 --> 00:10:42.440
put in an input, a
function ran, but the function

173
00:10:42.440 --> 00:10:45.050
is a black box and
a miracle, and the answer

174
00:10:45.050 --> 00:10:46.790
came out and it was
an amazing answer. But I

175
00:10:46.790 --> 00:10:48.170
can't tell you why. I
just know that it was

176
00:10:48.170 --> 00:10:53.930
right. Absolutely. And that's why
a lot. And that's why

177
00:10:53.930 --> 00:10:57.560
a lot of companies really,
really feel, you know, a

178
00:10:57.560 --> 00:11:01.910
bunch of misgivings about using
deep learning algorithms. Because if

179
00:11:01.910 --> 00:11:05.030
you have something that's like
very high stakes, so you're

180
00:11:05.030 --> 00:11:08.510
investing billions of dollars. You
kind of want to know

181
00:11:09.200 --> 00:11:14.120
like, okay, well, give me,
give me some rationale as

182
00:11:14.120 --> 00:11:17.760
to why I should invest
billions of dollars. It's, it's

183
00:11:17.780 --> 00:11:21.200
not very, you get a
lot of misgivings if the

184
00:11:21.200 --> 00:11:23.630
computer's giving you an answer
because you know, for all,

185
00:11:23.630 --> 00:11:27.440
you know, it could be
wrong, even though it, even

186
00:11:27.440 --> 00:11:30.620
though when you test it,
it's mostly right. I've heard,

187
00:11:30.650 --> 00:11:34.130
I've heard people refer to
like the, the, the family

188
00:11:34.130 --> 00:11:37.610
of artificial intelligence in a
number of different ways, machine

189
00:11:37.610 --> 00:11:40.130
learning, deep learning. And then
this idea of good old

190
00:11:40.130 --> 00:11:43.400
fashioned AI, like they'll sometimes
write it as a, as

191
00:11:43.400 --> 00:11:47.720
an acronym geo FAI to
like the kind of the

192
00:11:47.750 --> 00:11:51.170
more classic, straightforward, understandable things.
And then like all the

193
00:11:51.170 --> 00:11:53.530
different things you listed off
linear regression and dishes and

194
00:11:53.530 --> 00:11:56.380
razors are all different sub
sub flavors, right? So there's

195
00:11:56.380 --> 00:12:00.310
like the family of, of
creamy desserts and then there's

196
00:12:00.310 --> 00:12:03.280
ice cream and there's gelato
and there's all the different

197
00:12:03.280 --> 00:12:05.560
things. And sometimes you just
want to get back to

198
00:12:05.570 --> 00:12:10.300
the basics. And you're saying
that people are concerned about

199
00:12:10.300 --> 00:12:14.410
deep learning because it's this
leap that, that jumps over

200
00:12:14.410 --> 00:12:16.570
good old fashioned AI and
things that we understand into

201
00:12:16.570 --> 00:12:21.240
this much more complicated world.
Absolutely. It's, it's going to

202
00:12:21.240 --> 00:12:26.790
revolutionize the way people write
programs. So it, it's no

203
00:12:26.790 --> 00:12:32.040
longer the, the typical, the
typical programming where, you know,

204
00:12:32.490 --> 00:12:36.150
you have if and else
statements and, and it's very

205
00:12:36.150 --> 00:12:40.910
structured, like little Lego bricks
building out a thing it's

206
00:12:40.920 --> 00:12:45.810
suddenly, you know, the computer
is the computers creating software

207
00:12:45.810 --> 00:12:49.410
of its own. And you
know, the human is, has

208
00:12:49.410 --> 00:12:54.150
less of a hands on,
less controlling sort of role.

209
00:12:56.010 --> 00:12:58.140
Hey everyone, this is Scott.
I want to take a

210
00:12:58.140 --> 00:13:00.840
minute and talk to you
about smarty streets. You've probably

211
00:13:00.840 --> 00:13:03.930
already heard about them. They
provide API APIs for address

212
00:13:03.930 --> 00:13:07.050
validation and geocoding that cover
most, every address on the

213
00:13:07.050 --> 00:13:10.980
planet. Their fans described their
services as having dead simple

214
00:13:10.980 --> 00:13:15.060
API APIs that are blazing
fast with fantastic documentation. And

215
00:13:15.060 --> 00:13:18.810
they provide unlimited tech support
and 100% uptime. You know,

216
00:13:18.810 --> 00:13:21.330
I actually met these folks
personally a few years ago

217
00:13:21.330 --> 00:13:23.790
at an event in Las
Vegas. Not only are they

218
00:13:23.790 --> 00:13:26.160
extremely knowledgeable, they're a lot
of fun as well. They're

219
00:13:26.160 --> 00:13:28.950
definitely worth your time to
check out. So go check

220
00:13:28.950 --> 00:13:33.930
out smarty streets.com/hansel minutes today,
and try out their full

221
00:13:33.930 --> 00:13:38.580
API demos for free. So
let's pop a little bit

222
00:13:38.580 --> 00:13:41.340
off the stack here because
we got really deep, really

223
00:13:41.340 --> 00:13:43.980
fast, and I wanted to
talk machine learning one-on-one and

224
00:13:44.010 --> 00:13:46.950
I'm, I am not a
data scientist. I don't even

225
00:13:46.950 --> 00:13:49.500
play one on TV, but
you are. So let's say

226
00:13:49.500 --> 00:13:52.650
you and I are on
a team or the listeners

227
00:13:52.650 --> 00:13:54.780
who are also not data
scientists or are on the

228
00:13:54.780 --> 00:13:57.750
team with you. And they're
hearing things about doing machine

229
00:13:57.750 --> 00:14:00.150
learning and consuming it, and
they hear about Python and

230
00:14:00.150 --> 00:14:02.820
they hear about AR and
then they wonder if they

231
00:14:02.820 --> 00:14:04.320
need to learn one of
those things, if they want

232
00:14:04.320 --> 00:14:07.710
to interact with you as
a data scientist. So the

233
00:14:07.710 --> 00:14:12.810
answer is no, and which
is, which is a great

234
00:14:12.810 --> 00:14:17.220
sort of thing. Most machine
learning algorithms and most deep

235
00:14:17.220 --> 00:14:21.150
learning algorithms are implemented in
Python and R. But if

236
00:14:21.150 --> 00:14:26.010
you're a developer who's tasked
with building an application that

237
00:14:26.010 --> 00:14:28.770
just takes the input or
the output of a model,

238
00:14:29.190 --> 00:14:33.060
or sends an input to
a model, really all you

239
00:14:33.060 --> 00:14:35.940
need to know is how
to interact with the rest

240
00:14:35.940 --> 00:14:39.060
API. So what you should
all be telling your data

241
00:14:39.060 --> 00:14:43.320
scientists is if they, if
the output of their model

242
00:14:43.320 --> 00:14:45.870
is like a CSV file
with a whole bunch of

243
00:14:45.870 --> 00:14:49.140
values and they, they can't
give it back to you

244
00:14:49.140 --> 00:14:52.850
in a structured Jaison format,
or that that is not

245
00:14:52.850 --> 00:14:56.090
acceptable, you know, that they
need to, that they need

246
00:14:56.090 --> 00:14:58.490
to be giving you something
that you could incorporate into

247
00:14:58.490 --> 00:15:02.620
your application. Okay. So I
can think about this entire

248
00:15:02.620 --> 00:15:07.240
universe, this entire world of
artificial intelligence and machine learning

249
00:15:07.240 --> 00:15:12.040
as functions and puts outputs.
And I can hopefully consume

250
00:15:12.040 --> 00:15:14.470
them in a way that
will make me feel smart,

251
00:15:14.470 --> 00:15:17.860
but will be really easy
to do. Absolutely. And, and

252
00:15:17.890 --> 00:15:21.790
it's a personal opinion that
the data scientist should be

253
00:15:21.790 --> 00:15:26.140
the person who is responsible
for, for checking to make

254
00:15:26.140 --> 00:15:29.680
sure that the model continues
to operate as it should.

255
00:15:30.430 --> 00:15:34.090
So, so over time you
might end up with something

256
00:15:34.090 --> 00:15:38.470
called data drift or model
drift, which is that when

257
00:15:38.470 --> 00:15:43.510
the data scientists creates their
model, so create some model

258
00:15:43.510 --> 00:15:45.910
that predicts the number of
widgets that are going to

259
00:15:45.910 --> 00:15:50.260
be sold in July or
predicts the price of oranges

260
00:15:50.770 --> 00:15:57.040
in July. They might get
some additional information, you know,

261
00:15:57.040 --> 00:16:00.760
after their model's been created,
that would, that would change

262
00:16:00.790 --> 00:16:06.010
the model's behavior. So say,
so say if I'm predicting

263
00:16:06.010 --> 00:16:09.670
the price of oranges in
July of next year, and

264
00:16:09.670 --> 00:16:14.320
then suddenly, you know, in
January, there is a huge

265
00:16:14.350 --> 00:16:19.870
disease for every orange orchard
in the world, you know,

266
00:16:19.870 --> 00:16:23.080
that would probably cause the
price of oranges disco rocket.

267
00:16:23.440 --> 00:16:25.630
So if you had, if
you were using the model

268
00:16:25.630 --> 00:16:30.280
that had been built today,
though, you, you wouldn't have

269
00:16:30.280 --> 00:16:36.460
that information included. So as
your, as your model is

270
00:16:36.460 --> 00:16:39.610
deployed, you need to keep
refreshing it with new data.

271
00:16:39.940 --> 00:16:44.680
So kind of the DevOps
component of data science, and

272
00:16:44.680 --> 00:16:48.010
you need to make sure
that your, your accuracy stays

273
00:16:48.580 --> 00:16:50.890
to the level that it's
supposed to be. Okay. So

274
00:16:50.890 --> 00:16:52.600
that's interesting. So let me
see if I can paraphrase

275
00:16:52.600 --> 00:16:55.270
and understand what you just
said. So we could do

276
00:16:55.270 --> 00:17:02.560
something around recognizing faces, but
faces change. Although they fail,

277
00:17:02.590 --> 00:17:05.830
they change over centuries rather
than over months. If I'm

278
00:17:05.830 --> 00:17:08.470
doing something over a period
of years or seasons, like

279
00:17:08.470 --> 00:17:12.010
you described something that's more
temporal, I could use the

280
00:17:12.010 --> 00:17:14.470
last hundred years, but then
in a year or two

281
00:17:14.470 --> 00:17:17.430
or five, that's going to
become old. So then I'm

282
00:17:17.440 --> 00:17:19.840
going to need to, and
I think you had told

283
00:17:19.840 --> 00:17:23.260
me before, the word is
operationalize the model, you're going

284
00:17:23.260 --> 00:17:26.230
to, you design a model
and then you deploy it,

285
00:17:26.290 --> 00:17:28.360
put it out into the
world, wrap it up in

286
00:17:28.360 --> 00:17:31.030
a convenient web service. So
it sounds like you're telling

287
00:17:31.030 --> 00:17:33.940
me that I need a
dev ops plan for my

288
00:17:33.940 --> 00:17:36.850
machine learning department and my
models so that I can

289
00:17:37.330 --> 00:17:39.740
take those functions and deploy
them the same way that

290
00:17:40.120 --> 00:17:44.590
I deploy any code. Absolutely.
And you also need to

291
00:17:44.590 --> 00:17:47.980
be tracking the accuracy of
your models over time in

292
00:17:47.980 --> 00:17:51.960
order to understand what that
cadence should be like for

293
00:17:51.960 --> 00:17:55.110
how often you refresh your
data, because it's all based

294
00:17:55.110 --> 00:17:57.870
on business rules, right? Like,
it's, it might be like

295
00:17:57.870 --> 00:18:00.840
you said, refresh it once
a year or it might

296
00:18:00.840 --> 00:18:03.600
be refresh it every night
or every week or every

297
00:18:03.600 --> 00:18:07.520
month. Okay. So then how
do I decide? I decide

298
00:18:07.520 --> 00:18:09.980
based on the kind of
stuff that we're predicting, it

299
00:18:09.980 --> 00:18:12.410
could be predicting the price
of Bitcoin, or it could

300
00:18:12.410 --> 00:18:16.490
be predicting how a continence
shift, which are going to

301
00:18:16.490 --> 00:18:22.940
be different levels of operationalization.
Absolutely. Okay. All right. And

302
00:18:22.970 --> 00:18:25.820
this is in R or
it's in Python or whatever

303
00:18:26.090 --> 00:18:28.520
I'm done to deploy it
to a server. I've done

304
00:18:28.550 --> 00:18:32.150
some, I did some very
minor machine learning stuff. And

305
00:18:32.150 --> 00:18:35.600
the model that was generated
seemed small, like from the

306
00:18:35.600 --> 00:18:38.780
perspective of as a file
on disc, it was a

307
00:18:38.780 --> 00:18:42.530
small thing that freaked me
out because we had pulled

308
00:18:42.530 --> 00:18:45.530
from a couple of terabytes
of data and then a

309
00:18:45.530 --> 00:18:49.640
couple of megabytes popped out.
How is that possible? So

310
00:18:49.640 --> 00:18:52.190
think of your model, just
like you would think about

311
00:18:52.190 --> 00:18:58.010
an equation, right? So they're,
so the, the gentleman who

312
00:18:58.010 --> 00:19:00.980
made physics, like the very,
very bright folks who did

313
00:19:00.980 --> 00:19:05.600
all the experiments and discovered
that, you know, Oh, acceleration

314
00:19:05.600 --> 00:19:10.250
due to gravity is 9.8.
You know, they probably ran

315
00:19:10.310 --> 00:19:14.030
a ton of experiments where
they were dropping all sorts

316
00:19:14.030 --> 00:19:17.180
of things from all sorts
of Heights and writing down

317
00:19:17.180 --> 00:19:20.180
numbers over extended periods of
time before they came up

318
00:19:20.210 --> 00:19:24.500
with that, Oh, well, it's,
you know, it's 9.8 meters

319
00:19:24.500 --> 00:19:28.850
per second squared for acceleration
due to gravity. But we

320
00:19:28.850 --> 00:19:31.730
don't really care about all
the data that it took

321
00:19:31.760 --> 00:19:35.000
to generate that number. All
we care about is that

322
00:19:35.000 --> 00:19:37.610
if you drop something from
a height, now we have

323
00:19:37.610 --> 00:19:39.770
the equation that can tell
us how fast it's gonna

324
00:19:39.770 --> 00:19:42.260
fall and when it's going
to hit the ground. So

325
00:19:42.260 --> 00:19:47.330
your model is just basically
that equation, right? Like the

326
00:19:47.360 --> 00:19:50.780
ton of data was used
to generate what that equation

327
00:19:50.780 --> 00:19:53.780
should be, but now you've
got the equation and you

328
00:19:53.780 --> 00:19:56.180
can just apply it to
whatever inputs and outputs you

329
00:19:56.180 --> 00:19:59.030
have. Okay. But it's not,
it's not an equation that

330
00:19:59.030 --> 00:20:02.270
I can see. It's just
binary bits in this model.

331
00:20:02.270 --> 00:20:05.000
It's just, it's, it's, it's,
it's not an equation I

332
00:20:05.000 --> 00:20:08.510
could express and draw. Yep.
It's it won't be in

333
00:20:08.510 --> 00:20:14.000
it unless it's something like
linear regression algorithm, which would

334
00:20:14.000 --> 00:20:16.250
give you kind of like
a Y equals MX plus

335
00:20:16.250 --> 00:20:20.550
peak on the thing. Okay.
But whatever your model is,

336
00:20:20.550 --> 00:20:23.960
is doing it, it's basically
just an equation or, or

337
00:20:23.960 --> 00:20:27.170
a recipe on what output
you should be getting. If

338
00:20:27.170 --> 00:20:30.440
you, if you input a
certain thing, How do I

339
00:20:31.010 --> 00:20:33.740
debug it then if I
can't look at it. So

340
00:20:33.740 --> 00:20:37.280
debugging is, is really interesting
when it comes to machine

341
00:20:37.280 --> 00:20:39.800
learning into deep learning. So
machine learning it's a little

342
00:20:39.800 --> 00:20:43.520
bit more straight forward. So
you can, you can tweak

343
00:20:43.610 --> 00:20:48.190
these things called hyper parameters,
which are just kind of

344
00:20:48.790 --> 00:20:52.510
inputs to a function. So
an example would be there's

345
00:20:52.510 --> 00:20:56.020
this thing called a Martin
Gale, which is a wonderful

346
00:20:56.020 --> 00:20:57.880
name. If I ever get
a pet bird, I'm going

347
00:20:57.880 --> 00:21:01.000
to name it, Martin Gale,
but I'm a Martin Gale.

348
00:21:01.030 --> 00:21:03.100
Just think of it as
kind of like a window

349
00:21:03.100 --> 00:21:07.330
for running average. So you
could take the last five

350
00:21:07.330 --> 00:21:11.050
values to get your average,
or you could take the

351
00:21:11.050 --> 00:21:14.440
last 10 values to get
your average or the last

352
00:21:14.980 --> 00:21:18.250
two values to get your
average. And the number of

353
00:21:18.250 --> 00:21:23.050
values you select is, is
called a Martin Gale. Right?

354
00:21:23.050 --> 00:21:26.230
And that's one of, that's
an example of a hyper

355
00:21:26.230 --> 00:21:29.920
parameter that you could tune
for a model is how

356
00:21:29.920 --> 00:21:35.380
many values you use to
generate an average. So, yeah,

357
00:21:35.380 --> 00:21:39.640
so each one, each machine
learning model has a variety

358
00:21:39.640 --> 00:21:42.430
of those kinds of hyper
parameters that you can just

359
00:21:42.850 --> 00:21:45.760
keep shifting around until you
find one that gives you

360
00:21:45.760 --> 00:21:50.710
the highest accuracy or, or
whatever value you care about.

361
00:21:51.580 --> 00:21:57.220
And then once you, once
you've tweaked those hyper-parameters appropriately,

362
00:21:58.210 --> 00:22:01.330
that's, that's kind of how
you debugged your model, or

363
00:22:01.660 --> 00:22:05.590
it could be that. So
you have, you have this

364
00:22:05.590 --> 00:22:09.460
data set, right? So say
you have a dataset that

365
00:22:09.460 --> 00:22:12.670
predicts how long a person's
gonna live. And you have

366
00:22:12.670 --> 00:22:18.040
things like you have things
like how many, you know,

367
00:22:18.070 --> 00:22:22.390
what their weight is, what
their blood pressure is, how

368
00:22:22.390 --> 00:22:25.600
many calories they per day.
And then you might have

369
00:22:25.600 --> 00:22:29.110
a whole bunch of fields
that are like plays, soccer

370
00:22:30.370 --> 00:22:34.060
goes, jogging, goes hiking. And,
and those would all be

371
00:22:34.060 --> 00:22:37.420
yes or no values. It
could be that you could

372
00:22:37.420 --> 00:22:42.250
consolidate all of those sort
of physical activity columns into

373
00:22:42.250 --> 00:22:46.960
one column that's just like
is active. And that's some,

374
00:22:47.110 --> 00:22:53.560
so that consolidation process is
called feature engineering. So, so

375
00:22:53.560 --> 00:22:55.810
being able to look at
a data set and say

376
00:22:55.810 --> 00:22:58.780
like, Oh, well, I think
all of these are kind

377
00:22:58.780 --> 00:23:02.830
of telling me the same
thing. So let's just put

378
00:23:02.830 --> 00:23:06.250
them into one column as
opposed to six columns, and

379
00:23:06.250 --> 00:23:10.410
that could improve the accuracy
of your model. Hm. Yeah.

380
00:23:10.650 --> 00:23:15.810
That, that word Martin Gale,
my sister in law has

381
00:23:15.810 --> 00:23:19.650
horses. And the Martin Gale
is part of the reins

382
00:23:19.650 --> 00:23:22.890
of the horse that keeps
it from going too high.

383
00:23:23.490 --> 00:23:26.370
I wonder if that relates
somehow to using it in

384
00:23:26.370 --> 00:23:28.290
the context of data and
making sure that the data

385
00:23:28.320 --> 00:23:33.780
doesn't go quote unquote too
high. Awesome. That it could

386
00:23:33.780 --> 00:23:37.620
be. Yup. Yeah. Yeah. I
like, I that's another whole

387
00:23:37.620 --> 00:23:40.500
like podcast we could do
on etymology of words. Cause

388
00:23:40.500 --> 00:23:43.950
Marty, Gale has goes back
hundreds and hundreds of years.

389
00:23:44.370 --> 00:23:47.420
So then if the model,
the, the what's the different

390
00:23:47.420 --> 00:23:49.820
overfitting and under fitting, cause
you described a model that

391
00:23:49.820 --> 00:23:52.010
worked really well. But if
the model that works too

392
00:23:52.010 --> 00:23:54.790
well, that can be a
problem as well. Yes. So

393
00:23:54.820 --> 00:23:58.750
deep learning. That's another reason
why I don't like it

394
00:23:58.750 --> 00:24:02.440
as much as I should
probably, but so deep learning

395
00:24:02.920 --> 00:24:06.730
it's, it's incredibly effective, you
know, like it is, it

396
00:24:06.730 --> 00:24:11.110
is ridiculous, really effective. And
it's it's, I think it's,

397
00:24:11.110 --> 00:24:13.840
it's going to be the
way that most, that most

398
00:24:13.840 --> 00:24:17.530
machine learning goes in the
future, but there's, there's an

399
00:24:17.530 --> 00:24:23.500
issue with deep learning where,
so say you have, you

400
00:24:23.500 --> 00:24:26.830
have a picture of a
Panda. It's very obviously a

401
00:24:26.830 --> 00:24:31.330
Panda and your deep learning
model looks at it and

402
00:24:31.330 --> 00:24:34.780
is like, good job page.
I'm 72% sure. That's a

403
00:24:34.780 --> 00:24:40.870
Panda. If you add one
red pixel and a very

404
00:24:40.870 --> 00:24:45.040
specific location on that picture
dependent on the picture. So

405
00:24:45.130 --> 00:24:48.310
you just add one red
pixel or you introduce like

406
00:24:48.730 --> 00:24:53.500
0.07% noise into that picture.
So it still looks the

407
00:24:53.500 --> 00:24:56.800
same to the human. Other
than that one red dot

408
00:24:56.830 --> 00:24:59.440
or it still the same
to the human, other than

409
00:24:59.440 --> 00:25:03.730
like maybe a little bit
more greenish then that your

410
00:25:03.730 --> 00:25:07.000
deep learning model could look
at it and say, you

411
00:25:07.000 --> 00:25:13.660
know what, page 99% sure
that's a camel. Yeah. And

412
00:25:13.660 --> 00:25:16.120
it, and it still looks
almost exactly the same to

413
00:25:16.120 --> 00:25:18.820
the human, right? Like it's
still very, obviously a Panda,

414
00:25:19.000 --> 00:25:22.720
just a Panda with one
red pixel dot, but your

415
00:25:22.720 --> 00:25:26.920
deep learning model is completely
confused or you probably saw

416
00:25:26.920 --> 00:25:30.820
on hacker news recently, there
was like a turtle that

417
00:25:30.820 --> 00:25:34.900
TensorFlow thought was a gun.
And no matter which direction

418
00:25:34.900 --> 00:25:38.470
it looked at it TensorFlow
was just dang. Sure that

419
00:25:38.470 --> 00:25:44.350
that was a gun. Yeah.
That's concerning. If the thing's

420
00:25:44.350 --> 00:25:47.800
job is to recognize, you
know, guns, like if I

421
00:25:47.800 --> 00:25:50.170
brought my turtle to the
airport and the machine learning

422
00:25:50.170 --> 00:25:54.410
algorithm decided that was a
bad guy. Right. And the

423
00:25:54.460 --> 00:25:57.550
thing I worry about too,
right. Is if you have

424
00:25:57.550 --> 00:26:02.920
a company that's tasked with
determining missile locations from satellite

425
00:26:02.920 --> 00:26:06.550
imagery and they have, you
know, a bunch of satellite

426
00:26:06.550 --> 00:26:09.400
images that have been classified
as like, Oh, that's a

427
00:26:09.400 --> 00:26:12.970
location with missiles. Oh no,
that's not a location with

428
00:26:12.970 --> 00:26:18.130
missiles at all. If you
have, you know, some, some

429
00:26:18.250 --> 00:26:24.910
bad actor who introduces again,
just 0.07% random noise to

430
00:26:24.910 --> 00:26:29.230
a Corpus of images, they
would still look exactly the

431
00:26:29.230 --> 00:26:33.160
same to the company. That's
analyzing the satellite imagery, but

432
00:26:33.160 --> 00:26:36.460
suddenly none of them would
be correctly classified. So you

433
00:26:36.460 --> 00:26:39.580
would have like an area
maybe with civilians that was

434
00:26:39.580 --> 00:26:43.520
classified as probably MSL location
or a place that missile

435
00:26:43.530 --> 00:26:47.780
a location that was classified
as innocuous. Okay. So pushing,

436
00:26:47.810 --> 00:26:49.760
pushing back a little bit
on that or pushing on

437
00:26:49.760 --> 00:26:53.300
that, because that is totally
freaking me out. How does

438
00:26:53.300 --> 00:26:56.390
that kind of stuff, not
completely invalidate machine learning and

439
00:26:56.390 --> 00:26:59.840
AI and how could I
ever trust it again? So

440
00:27:00.230 --> 00:27:02.900
lucky for us, there are
a bunch of really smart

441
00:27:02.900 --> 00:27:05.810
people working on these problems.
If you have, if you

442
00:27:05.810 --> 00:27:09.110
have interest in the subject
it's called adversarial machine learning.

443
00:27:09.560 --> 00:27:13.010
So being able to yep.
So, so being able to

444
00:27:13.010 --> 00:27:17.120
spot, being able to spot
some of those issues with

445
00:27:17.120 --> 00:27:21.410
your algorithms before, before they
become issues, there's a project

446
00:27:21.410 --> 00:27:25.940
run out of Google brain
called clever hands. That, that

447
00:27:25.960 --> 00:27:31.940
is specifically focused on how
to detect, how to detect

448
00:27:31.970 --> 00:27:36.480
those like one pixel problems
and how to, how to

449
00:27:36.680 --> 00:27:41.150
prevent against them and what
they're, what they're actually doing

450
00:27:41.510 --> 00:27:45.920
for some of the research
is using deep learning to,

451
00:27:45.940 --> 00:27:49.880
to test other deep learning
algorithms. So like you're using

452
00:27:49.910 --> 00:27:52.820
deep learning algorithms against each
other to make each other

453
00:27:52.820 --> 00:27:57.860
better over and over and
over again, which is fascinating.

454
00:27:59.150 --> 00:28:00.980
And you're saying that's, it
reminds me of like making

455
00:28:00.980 --> 00:28:02.720
a copy of a copy
of a mix tape, except

456
00:28:02.720 --> 00:28:07.130
it usually gets worse. Yep.
But it's, but for, you

457
00:28:07.130 --> 00:28:10.280
know, for whatever reason, it
just, it just keeps getting

458
00:28:10.280 --> 00:28:14.360
better. It's like the, I
believe alpha go. That was

459
00:28:14.360 --> 00:28:16.400
one of the, that was
one of the methods of

460
00:28:16.400 --> 00:28:19.910
training. It was that, you
know, you, you just keep

461
00:28:19.910 --> 00:28:24.920
using smarter and smarter algorithms
against each other and Go

462
00:28:24.930 --> 00:28:28.520
is the go algorithm that
beat a human, The go

463
00:28:28.520 --> 00:28:32.300
algorithm that beat a human
and that they kind of

464
00:28:32.390 --> 00:28:38.120
trained itself very, very quickly
to, to be go there's

465
00:28:38.150 --> 00:28:41.180
there's also recently, I'm not
sure if it was AlphaGo

466
00:28:41.180 --> 00:28:44.330
or if it was something
else, it learned how to

467
00:28:44.330 --> 00:28:47.630
play chess by itself just
by looking at a number

468
00:28:47.630 --> 00:28:52.190
of games. And it learned
very, very quickly. So like,

469
00:28:52.970 --> 00:28:57.260
Yeah, so you do this
all day. This is your

470
00:28:57.260 --> 00:29:00.650
job full time. You're thinking
about this stuff. I am

471
00:29:00.650 --> 00:29:03.530
just a lowly programmer. When
I see things on the

472
00:29:03.530 --> 00:29:08.270
news where it says, you
know, Elon Musk says that

473
00:29:08.360 --> 00:29:12.200
that AI is going to
kill us all that is

474
00:29:12.200 --> 00:29:15.890
concerning to me. How do
data scientists in the community

475
00:29:15.890 --> 00:29:18.530
feel about statements like that?
Like is Skynet going to

476
00:29:18.530 --> 00:29:21.890
be a machine learning model?
I heard that Skynet was

477
00:29:21.890 --> 00:29:25.010
going to be JavaScript or
it was going to be

478
00:29:25.680 --> 00:29:29.480
written in JavaScript. But so,
so it's so funny too,

479
00:29:29.480 --> 00:29:33.110
because Elon Musk, you know,
is, is very, is very

480
00:29:33.110 --> 00:29:36.590
emphatically against AI, but he's
also including it in every

481
00:29:36.590 --> 00:29:39.830
single one of his products.
So like the self driving,

482
00:29:40.160 --> 00:29:43.900
the self driving components of
Teslas, that is definitely AI.

483
00:29:45.370 --> 00:29:50.050
But I honestly, I think
that the way that AI

484
00:29:50.050 --> 00:29:54.370
is going to be potentially
detrimental to society is if

485
00:29:54.370 --> 00:29:58.240
we don't take care to
make sure that our algorithms

486
00:29:58.240 --> 00:30:01.690
are implemented in an ethical
way. And I, I understand

487
00:30:01.690 --> 00:30:06.910
that you had a recent,
recent Hanselman it's about ethical

488
00:30:06.910 --> 00:30:12.210
algorithms as well. So, but
I honestly think that it's,

489
00:30:12.210 --> 00:30:15.910
it's not going to be,
you know, AI create Skynet.

490
00:30:16.270 --> 00:30:18.550
I think it's going to
be that there, that there

491
00:30:18.550 --> 00:30:20.980
are going to be more
and more decisions being made

492
00:30:20.980 --> 00:30:26.020
by algorithms that impact already
marginalized groups and then very

493
00:30:26.020 --> 00:30:29.290
negative way. And that's, that's
something that hurts my heart.

494
00:30:30.330 --> 00:30:33.480
Why would you think that
Elon being presumably a smart

495
00:30:33.480 --> 00:30:36.150
person would say something like
that? So in fact they

496
00:30:36.150 --> 00:30:38.430
already think that's just the
media over selling it. I

497
00:30:38.430 --> 00:30:41.640
think it's probably the media
overselling it. And then it's

498
00:30:41.640 --> 00:30:44.940
also, you know, a great
way to ensure that other

499
00:30:44.940 --> 00:30:48.780
people aren't really practicing as
much as they, as they

500
00:30:48.780 --> 00:30:53.190
could be. Right. Like, like
maybe it's a business tactic.

501
00:30:53.880 --> 00:30:59.100
So, but you know, and,
and it's also those, those

502
00:30:59.100 --> 00:31:03.570
kinds of broad statements, nobody
can really predict the future

503
00:31:03.600 --> 00:31:06.780
other than maybe Neil Stevenson.
Like he seems to be

504
00:31:06.780 --> 00:31:12.480
pretty dang good at it,
but the deal with AI

505
00:31:12.510 --> 00:31:16.760
creating something like how or
something like, you know, the,

506
00:31:16.760 --> 00:31:19.590
the crazy things that you
see in science fiction novels.

507
00:31:21.060 --> 00:31:25.710
I don't, like I said,
I, I don't think that

508
00:31:25.710 --> 00:31:30.060
that's, that's going to be
the thing that potentially harms

509
00:31:30.060 --> 00:31:32.040
humanity. I think it's going
to be a little bit

510
00:31:32.040 --> 00:31:37.560
more nuanced. Well, certainly it's
a tool, right? And it's

511
00:31:37.710 --> 00:31:43.080
feasible that someone could use
that tool or JavaScript to,

512
00:31:43.090 --> 00:31:46.200
to hurt humanity. But I
guess the idea is you

513
00:31:46.200 --> 00:31:48.300
don't think that it's going
to happen on its own.

514
00:31:48.450 --> 00:31:51.000
Like if a bad actor
or a bad guy or

515
00:31:51.000 --> 00:31:53.580
gal decides to do something
evil like that, that's one

516
00:31:53.580 --> 00:31:58.050
thing. But for them to,
for, for the, the thing,

517
00:31:58.050 --> 00:32:01.110
the AlphaGo to do it
on its own, you find

518
00:32:01.110 --> 00:32:04.710
online. Absolutely. That is a
perfect way. That's a perfect

519
00:32:04.710 --> 00:32:07.650
way to describe it. All
right. Well that will, I

520
00:32:07.650 --> 00:32:10.770
will sleep better. I will
probably never play go well

521
00:32:10.770 --> 00:32:15.420
again, but I will, I
will feel much better. Thanks

522
00:32:15.420 --> 00:32:17.610
so much for chatting with
me today. It was a

523
00:32:17.610 --> 00:32:20.280
ton of fun. I love
talking about machine learning. This

524
00:32:20.280 --> 00:32:23.070
doesn't feel like a job.
Like Can people find you

525
00:32:23.070 --> 00:32:25.710
online and learn more about
what you're doing and learn

526
00:32:25.710 --> 00:32:28.920
more about machine learning? Oh,
a ton of places. But

527
00:32:29.400 --> 00:32:32.520
my Twitter handle is probably
the best way to find

528
00:32:32.520 --> 00:32:36.540
me. It is dynamic webpage
with Paige spelled like my

529
00:32:36.540 --> 00:32:41.780
name and that's. And I'm
also dynamic with page pretty

530
00:32:41.780 --> 00:32:44.870
much everywhere on the internet.
If you want to learn

531
00:32:44.870 --> 00:32:51.110
more about AI, I sincerely
recommend either the AI school

532
00:32:51.110 --> 00:32:56.600
from Microsoft or deep learning
or machine learning from Andrew

533
00:32:56.600 --> 00:33:00.320
NG, both of those courses
are available on Coursera and

534
00:33:00.320 --> 00:33:04.880
they're both phenomenal. And there's
also a website called data

535
00:33:04.880 --> 00:33:09.860
camp. So data, camp.com that
teaches you everything that you

536
00:33:09.860 --> 00:33:13.070
would ever want to learn
about machine learning with Python

537
00:33:13.070 --> 00:33:18.650
or R. So data cleaning,
data processing, building out machine

538
00:33:18.650 --> 00:33:22.370
learning models, doing deep learning.
All of that is, is

539
00:33:23.060 --> 00:33:26.360
available for like $29 a
month on data camp. And

540
00:33:26.360 --> 00:33:30.340
it's for free if you're
a student. So Rock on.

541
00:33:30.490 --> 00:33:34.870
Awesome tips. Thanks so much.
This has been another episode

542
00:33:34.870 --> 00:33:37.570
of Hansel minutes and we'll
see you again next week.

